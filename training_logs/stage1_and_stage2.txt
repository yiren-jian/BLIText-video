(lavis) xxxx@xxxx:~/VATEX$ bash run_scripts/blip2/train/train_caption_vatex_stage1.sh
| distributed init (rank 0, world 1): env://
2023-05-10 18:36:11,127 [INFO]
=====  Running Parameters    =====
2023-05-10 18:36:11,128 [INFO] {
    "accum_grad_iters": 1,
    "amp": true,
    "batch_size_eval": 64,
    "batch_size_train": 128,
    "device": "cuda",
    "dist_backend": "nccl",
    "dist_url": "env://",
    "distributed": true,
    "evaluate": false,
    "gpu": 0,
    "init_lr": 0.0001,
    "lr_sched": "linear_warmup_cosine_lr",
    "max_epoch": 10,
    "max_len": 30,
    "min_len": 8,
    "min_lr": 1e-05,
    "num_beams": 5,
    "num_workers": 4,
    "output_dir": "output/BLIP-T/Caption_vatex_stage1",
    "rank": 0,
    "report_metric": false,
    "resume_ckpt_path": null,
    "seed": 42,
    "task": "captioning",
    "train_splits": [
        "train"
    ],
    "valid_splits": [
        "val"
    ],
    "warmup_lr": 1e-06,
    "warmup_steps": 1000,
    "weight_decay": 0.05,
    "world_size": 1
}
2023-05-10 18:36:11,128 [INFO]
======  Dataset Attributes  ======
2023-05-10 18:36:11,128 [INFO]
======== my_vatex_caption =======
2023-05-10 18:36:11,128 [INFO] {
    "build_info": {
        "annotations": {
            "train": {
                "storage": "vatex/annotations/cap_train.json",
                "url": "https://storage.googleapis.com/sfr-vision-language-research/LAVIS/datasets/vatex/cap_train.json"
            },
            "val": {
                "storage": "vatex/annotations/cap_val.json",
                "url": "https://storage.googleapis.com/sfr-vision-language-research/LAVIS/datasets/vatex/cap_val.json"
            }
        },
        "videos": {
            "storage": "vatex/images"
        }
    },
    "data_type": "videos",
    "text_processor": {
        "eval": {
            "name": "blip_caption"
        },
        "train": {
            "name": "blip_caption",
            "prompt": "a photo of "
        }
    }
}
2023-05-10 18:36:11,128 [INFO]
======  Model Attributes  ======
2023-05-10 18:36:11,128 [INFO] {
    "arch": "video_feature_opt_stage1",
    "drop_path_rate": 0,
    "finetuned": "https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP2/blip2_caption_opt2.7b.pth",
    "freeze_vit": true,
    "image_size": 364,
    "load_finetuned": false,
    "load_pretrained": true,
    "model_type": "caption_coco_opt2.7b",
    "num_query_token": 32,
    "opt_model": "facebook/opt-2.7b",
    "pretrained": "https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP2/blip2_pretrained_opt2.7b.pth",
    "pretrained_stage0": "/home/yiren/LAVIS/lavis/output/BLIP-T/Pretrain_stage0/vq/40m-noisy/checkpoint_60000.pth",
    "prompt": "a photo of",
    "use_grad_checkpoint": false,
    "vit_precision": "fp32"
}
Using downloaded and verified file: /home/yiren/lavis_datasets/vatex/annotations/cap_train.json
Using downloaded and verified file: /home/yiren/lavis_datasets/vatex/annotations/cap_val.json
2023-05-10 18:36:11,129 [INFO] Building datasets...
2023-05-10 18:37:02,013 [INFO] Missing keys ['VL_adaptor.embeddings.position_ids', 'VL_adaptor.embeddings.word_embeddings.weight', 'VL_adaptor.embeddings.position_embeddings.weight', 'VL_adaptor.embeddings.token_type_embeddings.weight', 'VL_adaptor.embeddings.LayerNorm.weight', 'VL_adaptor.embeddings.LayerNorm.bias', 'VL_adaptor.encoder.layer.0.attention.self.query.weight', 'VL_adaptor.encoder.layer.0.attention.self.query.bias', 'VL_adaptor.encoder.layer.0.attention.self.key.weight', 'VL_adaptor.encoder.layer.0.attention.self.key.bias', 'VL_adaptor.encoder.layer.0.attention.self.value.weight', 'VL_adaptor.encoder.layer.0.attention.self.value.bias', 'VL_adaptor.encoder.layer.0.attention.output.dense.weight', 'VL_adaptor.encoder.layer.0.attention.output.dense.bias', 'VL_adaptor.encoder.layer.0.attention.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.0.attention.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.0.intermediate.dense.weight', 'VL_adaptor.encoder.layer.0.intermediate.dense.bias', 'VL_adaptor.encoder.layer.0.output.dense.weight', 'VL_adaptor.encoder.layer.0.output.dense.bias', 'VL_adaptor.encoder.layer.0.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.0.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.1.attention.self.query.weight', 'VL_adaptor.encoder.layer.1.attention.self.query.bias', 'VL_adaptor.encoder.layer.1.attention.self.key.weight', 'VL_adaptor.encoder.layer.1.attention.self.key.bias', 'VL_adaptor.encoder.layer.1.attention.self.value.weight', 'VL_adaptor.encoder.layer.1.attention.self.value.bias', 'VL_adaptor.encoder.layer.1.attention.output.dense.weight', 'VL_adaptor.encoder.layer.1.attention.output.dense.bias', 'VL_adaptor.encoder.layer.1.attention.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.1.attention.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.1.intermediate.dense.weight', 'VL_adaptor.encoder.layer.1.intermediate.dense.bias', 'VL_adaptor.encoder.layer.1.output.dense.weight', 'VL_adaptor.encoder.layer.1.output.dense.bias', 'VL_adaptor.encoder.layer.1.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.1.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.2.attention.self.query.weight', 'VL_adaptor.encoder.layer.2.attention.self.query.bias', 'VL_adaptor.encoder.layer.2.attention.self.key.weight', 'VL_adaptor.encoder.layer.2.attention.self.key.bias', 'VL_adaptor.encoder.layer.2.attention.self.value.weight', 'VL_adaptor.encoder.layer.2.attention.self.value.bias', 'VL_adaptor.encoder.layer.2.attention.output.dense.weight', 'VL_adaptor.encoder.layer.2.attention.output.dense.bias', 'VL_adaptor.encoder.layer.2.attention.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.2.attention.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.2.intermediate.dense.weight', 'VL_adaptor.encoder.layer.2.intermediate.dense.bias', 'VL_adaptor.encoder.layer.2.output.dense.weight', 'VL_adaptor.encoder.layer.2.output.dense.bias', 'VL_adaptor.encoder.layer.2.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.2.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.3.attention.self.query.weight', 'VL_adaptor.encoder.layer.3.attention.self.query.bias', 'VL_adaptor.encoder.layer.3.attention.self.key.weight', 'VL_adaptor.encoder.layer.3.attention.self.key.bias', 'VL_adaptor.encoder.layer.3.attention.self.value.weight', 'VL_adaptor.encoder.layer.3.attention.self.value.bias', 'VL_adaptor.encoder.layer.3.attention.output.dense.weight', 'VL_adaptor.encoder.layer.3.attention.output.dense.bias', 'VL_adaptor.encoder.layer.3.attention.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.3.attention.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.3.intermediate.dense.weight', 'VL_adaptor.encoder.layer.3.intermediate.dense.bias', 'VL_adaptor.encoder.layer.3.output.dense.weight', 'VL_adaptor.encoder.layer.3.output.dense.bias', 'VL_adaptor.encoder.layer.3.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.3.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.4.attention.self.query.weight', 'VL_adaptor.encoder.layer.4.attention.self.query.bias', 'VL_adaptor.encoder.layer.4.attention.self.key.weight', 'VL_adaptor.encoder.layer.4.attention.self.key.bias', 'VL_adaptor.encoder.layer.4.attention.self.value.weight', 'VL_adaptor.encoder.layer.4.attention.self.value.bias', 'VL_adaptor.encoder.layer.4.attention.output.dense.weight', 'VL_adaptor.encoder.layer.4.attention.output.dense.bias', 'VL_adaptor.encoder.layer.4.attention.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.4.attention.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.4.intermediate.dense.weight', 'VL_adaptor.encoder.layer.4.intermediate.dense.bias', 'VL_adaptor.encoder.layer.4.output.dense.weight', 'VL_adaptor.encoder.layer.4.output.dense.bias', 'VL_adaptor.encoder.layer.4.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.4.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.5.attention.self.query.weight', 'VL_adaptor.encoder.layer.5.attention.self.query.bias', 'VL_adaptor.encoder.layer.5.attention.self.key.weight', 'VL_adaptor.encoder.layer.5.attention.self.key.bias', 'VL_adaptor.encoder.layer.5.attention.self.value.weight', 'VL_adaptor.encoder.layer.5.attention.self.value.bias', 'VL_adaptor.encoder.layer.5.attention.output.dense.weight', 'VL_adaptor.encoder.layer.5.attention.output.dense.bias', 'VL_adaptor.encoder.layer.5.attention.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.5.attention.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.5.intermediate.dense.weight', 'VL_adaptor.encoder.layer.5.intermediate.dense.bias', 'VL_adaptor.encoder.layer.5.output.dense.weight', 'VL_adaptor.encoder.layer.5.output.dense.bias', 'VL_adaptor.encoder.layer.5.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.5.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.6.attention.self.query.weight', 'VL_adaptor.encoder.layer.6.attention.self.query.bias', 'VL_adaptor.encoder.layer.6.attention.self.key.weight', 'VL_adaptor.encoder.layer.6.attention.self.key.bias', 'VL_adaptor.encoder.layer.6.attention.self.value.weight', 'VL_adaptor.encoder.layer.6.attention.self.value.bias', 'VL_adaptor.encoder.layer.6.attention.output.dense.weight', 'VL_adaptor.encoder.layer.6.attention.output.dense.bias', 'VL_adaptor.encoder.layer.6.attention.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.6.attention.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.6.intermediate.dense.weight', 'VL_adaptor.encoder.layer.6.intermediate.dense.bias', 'VL_adaptor.encoder.layer.6.output.dense.weight', 'VL_adaptor.encoder.layer.6.output.dense.bias', 'VL_adaptor.encoder.layer.6.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.6.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.7.attention.self.query.weight', 'VL_adaptor.encoder.layer.7.attention.self.query.bias', 'VL_adaptor.encoder.layer.7.attention.self.key.weight', 'VL_adaptor.encoder.layer.7.attention.self.key.bias', 'VL_adaptor.encoder.layer.7.attention.self.value.weight', 'VL_adaptor.encoder.layer.7.attention.self.value.bias', 'VL_adaptor.encoder.layer.7.attention.output.dense.weight', 'VL_adaptor.encoder.layer.7.attention.output.dense.bias', 'VL_adaptor.encoder.layer.7.attention.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.7.attention.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.7.intermediate.dense.weight', 'VL_adaptor.encoder.layer.7.intermediate.dense.bias', 'VL_adaptor.encoder.layer.7.output.dense.weight', 'VL_adaptor.encoder.layer.7.output.dense.bias', 'VL_adaptor.encoder.layer.7.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.7.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.8.attention.self.query.weight', 'VL_adaptor.encoder.layer.8.attention.self.query.bias', 'VL_adaptor.encoder.layer.8.attention.self.key.weight', 'VL_adaptor.encoder.layer.8.attention.self.key.bias', 'VL_adaptor.encoder.layer.8.attention.self.value.weight', 'VL_adaptor.encoder.layer.8.attention.self.value.bias', 'VL_adaptor.encoder.layer.8.attention.output.dense.weight', 'VL_adaptor.encoder.layer.8.attention.output.dense.bias', 'VL_adaptor.encoder.layer.8.attention.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.8.attention.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.8.intermediate.dense.weight', 'VL_adaptor.encoder.layer.8.intermediate.dense.bias', 'VL_adaptor.encoder.layer.8.output.dense.weight', 'VL_adaptor.encoder.layer.8.output.dense.bias', 'VL_adaptor.encoder.layer.8.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.8.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.9.attention.self.query.weight', 'VL_adaptor.encoder.layer.9.attention.self.query.bias', 'VL_adaptor.encoder.layer.9.attention.self.key.weight', 'VL_adaptor.encoder.layer.9.attention.self.key.bias', 'VL_adaptor.encoder.layer.9.attention.self.value.weight', 'VL_adaptor.encoder.layer.9.attention.self.value.bias', 'VL_adaptor.encoder.layer.9.attention.output.dense.weight', 'VL_adaptor.encoder.layer.9.attention.output.dense.bias', 'VL_adaptor.encoder.layer.9.attention.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.9.attention.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.9.intermediate.dense.weight', 'VL_adaptor.encoder.layer.9.intermediate.dense.bias', 'VL_adaptor.encoder.layer.9.output.dense.weight', 'VL_adaptor.encoder.layer.9.output.dense.bias', 'VL_adaptor.encoder.layer.9.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.9.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.10.attention.self.query.weight', 'VL_adaptor.encoder.layer.10.attention.self.query.bias', 'VL_adaptor.encoder.layer.10.attention.self.key.weight', 'VL_adaptor.encoder.layer.10.attention.self.key.bias', 'VL_adaptor.encoder.layer.10.attention.self.value.weight', 'VL_adaptor.encoder.layer.10.attention.self.value.bias', 'VL_adaptor.encoder.layer.10.attention.output.dense.weight', 'VL_adaptor.encoder.layer.10.attention.output.dense.bias', 'VL_adaptor.encoder.layer.10.attention.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.10.attention.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.10.intermediate.dense.weight', 'VL_adaptor.encoder.layer.10.intermediate.dense.bias', 'VL_adaptor.encoder.layer.10.output.dense.weight', 'VL_adaptor.encoder.layer.10.output.dense.bias', 'VL_adaptor.encoder.layer.10.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.10.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.11.attention.self.query.weight', 'VL_adaptor.encoder.layer.11.attention.self.query.bias', 'VL_adaptor.encoder.layer.11.attention.self.key.weight', 'VL_adaptor.encoder.layer.11.attention.self.key.bias', 'VL_adaptor.encoder.layer.11.attention.self.value.weight', 'VL_adaptor.encoder.layer.11.attention.self.value.bias', 'VL_adaptor.encoder.layer.11.attention.output.dense.weight', 'VL_adaptor.encoder.layer.11.attention.output.dense.bias', 'VL_adaptor.encoder.layer.11.attention.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.11.attention.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.11.intermediate.dense.weight', 'VL_adaptor.encoder.layer.11.intermediate.dense.bias', 'VL_adaptor.encoder.layer.11.output.dense.weight', 'VL_adaptor.encoder.layer.11.output.dense.bias', 'VL_adaptor.encoder.layer.11.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.11.output.LayerNorm.bias', 'VL_adaptor.feat_proj.weight', 'VL_adaptor.feat_proj.bias', 'opt_model.model.decoder.embed_tokens.weight', 'opt_model.model.decoder.embed_positions.weight', 'opt_model.model.decoder.final_layer_norm.weight', 'opt_model.model.decoder.final_layer_norm.bias', 'opt_model.model.decoder.layers.0.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.0.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.0.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.0.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.0.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.0.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.0.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.0.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.0.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.0.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.0.fc1.weight', 'opt_model.model.decoder.layers.0.fc1.bias', 'opt_model.model.decoder.layers.0.fc2.weight', 'opt_model.model.decoder.layers.0.fc2.bias', 'opt_model.model.decoder.layers.0.final_layer_norm.weight', 'opt_model.model.decoder.layers.0.final_layer_norm.bias', 'opt_model.model.decoder.layers.1.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.1.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.1.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.1.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.1.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.1.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.1.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.1.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.1.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.1.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.1.fc1.weight', 'opt_model.model.decoder.layers.1.fc1.bias', 'opt_model.model.decoder.layers.1.fc2.weight', 'opt_model.model.decoder.layers.1.fc2.bias', 'opt_model.model.decoder.layers.1.final_layer_norm.weight', 'opt_model.model.decoder.layers.1.final_layer_norm.bias', 'opt_model.model.decoder.layers.2.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.2.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.2.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.2.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.2.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.2.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.2.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.2.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.2.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.2.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.2.fc1.weight', 'opt_model.model.decoder.layers.2.fc1.bias', 'opt_model.model.decoder.layers.2.fc2.weight', 'opt_model.model.decoder.layers.2.fc2.bias', 'opt_model.model.decoder.layers.2.final_layer_norm.weight', 'opt_model.model.decoder.layers.2.final_layer_norm.bias', 'opt_model.model.decoder.layers.3.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.3.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.3.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.3.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.3.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.3.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.3.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.3.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.3.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.3.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.3.fc1.weight', 'opt_model.model.decoder.layers.3.fc1.bias', 'opt_model.model.decoder.layers.3.fc2.weight', 'opt_model.model.decoder.layers.3.fc2.bias', 'opt_model.model.decoder.layers.3.final_layer_norm.weight', 'opt_model.model.decoder.layers.3.final_layer_norm.bias', 'opt_model.model.decoder.layers.4.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.4.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.4.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.4.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.4.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.4.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.4.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.4.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.4.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.4.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.4.fc1.weight', 'opt_model.model.decoder.layers.4.fc1.bias', 'opt_model.model.decoder.layers.4.fc2.weight', 'opt_model.model.decoder.layers.4.fc2.bias', 'opt_model.model.decoder.layers.4.final_layer_norm.weight', 'opt_model.model.decoder.layers.4.final_layer_norm.bias', 'opt_model.model.decoder.layers.5.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.5.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.5.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.5.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.5.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.5.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.5.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.5.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.5.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.5.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.5.fc1.weight', 'opt_model.model.decoder.layers.5.fc1.bias', 'opt_model.model.decoder.layers.5.fc2.weight', 'opt_model.model.decoder.layers.5.fc2.bias', 'opt_model.model.decoder.layers.5.final_layer_norm.weight', 'opt_model.model.decoder.layers.5.final_layer_norm.bias', 'opt_model.model.decoder.layers.6.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.6.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.6.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.6.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.6.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.6.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.6.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.6.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.6.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.6.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.6.fc1.weight', 'opt_model.model.decoder.layers.6.fc1.bias', 'opt_model.model.decoder.layers.6.fc2.weight', 'opt_model.model.decoder.layers.6.fc2.bias', 'opt_model.model.decoder.layers.6.final_layer_norm.weight', 'opt_model.model.decoder.layers.6.final_layer_norm.bias', 'opt_model.model.decoder.layers.7.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.7.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.7.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.7.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.7.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.7.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.7.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.7.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.7.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.7.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.7.fc1.weight', 'opt_model.model.decoder.layers.7.fc1.bias', 'opt_model.model.decoder.layers.7.fc2.weight', 'opt_model.model.decoder.layers.7.fc2.bias', 'opt_model.model.decoder.layers.7.final_layer_norm.weight', 'opt_model.model.decoder.layers.7.final_layer_norm.bias', 'opt_model.model.decoder.layers.8.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.8.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.8.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.8.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.8.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.8.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.8.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.8.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.8.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.8.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.8.fc1.weight', 'opt_model.model.decoder.layers.8.fc1.bias', 'opt_model.model.decoder.layers.8.fc2.weight', 'opt_model.model.decoder.layers.8.fc2.bias', 'opt_model.model.decoder.layers.8.final_layer_norm.weight', 'opt_model.model.decoder.layers.8.final_layer_norm.bias', 'opt_model.model.decoder.layers.9.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.9.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.9.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.9.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.9.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.9.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.9.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.9.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.9.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.9.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.9.fc1.weight', 'opt_model.model.decoder.layers.9.fc1.bias', 'opt_model.model.decoder.layers.9.fc2.weight', 'opt_model.model.decoder.layers.9.fc2.bias', 'opt_model.model.decoder.layers.9.final_layer_norm.weight', 'opt_model.model.decoder.layers.9.final_layer_norm.bias', 'opt_model.model.decoder.layers.10.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.10.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.10.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.10.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.10.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.10.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.10.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.10.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.10.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.10.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.10.fc1.weight', 'opt_model.model.decoder.layers.10.fc1.bias', 'opt_model.model.decoder.layers.10.fc2.weight', 'opt_model.model.decoder.layers.10.fc2.bias', 'opt_model.model.decoder.layers.10.final_layer_norm.weight', 'opt_model.model.decoder.layers.10.final_layer_norm.bias', 'opt_model.model.decoder.layers.11.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.11.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.11.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.11.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.11.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.11.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.11.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.11.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.11.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.11.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.11.fc1.weight', 'opt_model.model.decoder.layers.11.fc1.bias', 'opt_model.model.decoder.layers.11.fc2.weight', 'opt_model.model.decoder.layers.11.fc2.bias', 'opt_model.model.decoder.layers.11.final_layer_norm.weight', 'opt_model.model.decoder.layers.11.final_layer_norm.bias', 'opt_model.model.decoder.layers.12.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.12.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.12.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.12.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.12.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.12.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.12.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.12.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.12.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.12.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.12.fc1.weight', 'opt_model.model.decoder.layers.12.fc1.bias', 'opt_model.model.decoder.layers.12.fc2.weight', 'opt_model.model.decoder.layers.12.fc2.bias', 'opt_model.model.decoder.layers.12.final_layer_norm.weight', 'opt_model.model.decoder.layers.12.final_layer_norm.bias', 'opt_model.model.decoder.layers.13.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.13.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.13.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.13.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.13.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.13.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.13.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.13.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.13.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.13.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.13.fc1.weight', 'opt_model.model.decoder.layers.13.fc1.bias', 'opt_model.model.decoder.layers.13.fc2.weight', 'opt_model.model.decoder.layers.13.fc2.bias', 'opt_model.model.decoder.layers.13.final_layer_norm.weight', 'opt_model.model.decoder.layers.13.final_layer_norm.bias', 'opt_model.model.decoder.layers.14.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.14.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.14.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.14.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.14.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.14.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.14.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.14.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.14.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.14.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.14.fc1.weight', 'opt_model.model.decoder.layers.14.fc1.bias', 'opt_model.model.decoder.layers.14.fc2.weight', 'opt_model.model.decoder.layers.14.fc2.bias', 'opt_model.model.decoder.layers.14.final_layer_norm.weight', 'opt_model.model.decoder.layers.14.final_layer_norm.bias', 'opt_model.model.decoder.layers.15.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.15.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.15.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.15.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.15.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.15.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.15.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.15.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.15.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.15.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.15.fc1.weight', 'opt_model.model.decoder.layers.15.fc1.bias', 'opt_model.model.decoder.layers.15.fc2.weight', 'opt_model.model.decoder.layers.15.fc2.bias', 'opt_model.model.decoder.layers.15.final_layer_norm.weight', 'opt_model.model.decoder.layers.15.final_layer_norm.bias', 'opt_model.model.decoder.layers.16.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.16.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.16.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.16.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.16.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.16.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.16.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.16.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.16.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.16.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.16.fc1.weight', 'opt_model.model.decoder.layers.16.fc1.bias', 'opt_model.model.decoder.layers.16.fc2.weight', 'opt_model.model.decoder.layers.16.fc2.bias', 'opt_model.model.decoder.layers.16.final_layer_norm.weight', 'opt_model.model.decoder.layers.16.final_layer_norm.bias', 'opt_model.model.decoder.layers.17.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.17.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.17.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.17.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.17.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.17.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.17.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.17.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.17.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.17.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.17.fc1.weight', 'opt_model.model.decoder.layers.17.fc1.bias', 'opt_model.model.decoder.layers.17.fc2.weight', 'opt_model.model.decoder.layers.17.fc2.bias', 'opt_model.model.decoder.layers.17.final_layer_norm.weight', 'opt_model.model.decoder.layers.17.final_layer_norm.bias', 'opt_model.model.decoder.layers.18.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.18.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.18.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.18.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.18.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.18.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.18.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.18.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.18.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.18.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.18.fc1.weight', 'opt_model.model.decoder.layers.18.fc1.bias', 'opt_model.model.decoder.layers.18.fc2.weight', 'opt_model.model.decoder.layers.18.fc2.bias', 'opt_model.model.decoder.layers.18.final_layer_norm.weight', 'opt_model.model.decoder.layers.18.final_layer_norm.bias', 'opt_model.model.decoder.layers.19.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.19.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.19.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.19.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.19.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.19.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.19.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.19.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.19.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.19.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.19.fc1.weight', 'opt_model.model.decoder.layers.19.fc1.bias', 'opt_model.model.decoder.layers.19.fc2.weight', 'opt_model.model.decoder.layers.19.fc2.bias', 'opt_model.model.decoder.layers.19.final_layer_norm.weight', 'opt_model.model.decoder.layers.19.final_layer_norm.bias', 'opt_model.model.decoder.layers.20.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.20.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.20.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.20.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.20.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.20.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.20.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.20.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.20.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.20.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.20.fc1.weight', 'opt_model.model.decoder.layers.20.fc1.bias', 'opt_model.model.decoder.layers.20.fc2.weight', 'opt_model.model.decoder.layers.20.fc2.bias', 'opt_model.model.decoder.layers.20.final_layer_norm.weight', 'opt_model.model.decoder.layers.20.final_layer_norm.bias', 'opt_model.model.decoder.layers.21.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.21.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.21.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.21.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.21.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.21.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.21.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.21.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.21.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.21.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.21.fc1.weight', 'opt_model.model.decoder.layers.21.fc1.bias', 'opt_model.model.decoder.layers.21.fc2.weight', 'opt_model.model.decoder.layers.21.fc2.bias', 'opt_model.model.decoder.layers.21.final_layer_norm.weight', 'opt_model.model.decoder.layers.21.final_layer_norm.bias', 'opt_model.model.decoder.layers.22.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.22.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.22.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.22.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.22.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.22.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.22.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.22.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.22.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.22.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.22.fc1.weight', 'opt_model.model.decoder.layers.22.fc1.bias', 'opt_model.model.decoder.layers.22.fc2.weight', 'opt_model.model.decoder.layers.22.fc2.bias', 'opt_model.model.decoder.layers.22.final_layer_norm.weight', 'opt_model.model.decoder.layers.22.final_layer_norm.bias', 'opt_model.model.decoder.layers.23.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.23.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.23.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.23.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.23.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.23.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.23.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.23.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.23.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.23.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.23.fc1.weight', 'opt_model.model.decoder.layers.23.fc1.bias', 'opt_model.model.decoder.layers.23.fc2.weight', 'opt_model.model.decoder.layers.23.fc2.bias', 'opt_model.model.decoder.layers.23.final_layer_norm.weight', 'opt_model.model.decoder.layers.23.final_layer_norm.bias', 'opt_model.model.decoder.layers.24.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.24.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.24.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.24.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.24.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.24.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.24.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.24.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.24.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.24.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.24.fc1.weight', 'opt_model.model.decoder.layers.24.fc1.bias', 'opt_model.model.decoder.layers.24.fc2.weight', 'opt_model.model.decoder.layers.24.fc2.bias', 'opt_model.model.decoder.layers.24.final_layer_norm.weight', 'opt_model.model.decoder.layers.24.final_layer_norm.bias', 'opt_model.model.decoder.layers.25.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.25.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.25.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.25.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.25.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.25.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.25.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.25.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.25.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.25.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.25.fc1.weight', 'opt_model.model.decoder.layers.25.fc1.bias', 'opt_model.model.decoder.layers.25.fc2.weight', 'opt_model.model.decoder.layers.25.fc2.bias', 'opt_model.model.decoder.layers.25.final_layer_norm.weight', 'opt_model.model.decoder.layers.25.final_layer_norm.bias', 'opt_model.model.decoder.layers.26.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.26.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.26.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.26.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.26.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.26.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.26.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.26.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.26.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.26.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.26.fc1.weight', 'opt_model.model.decoder.layers.26.fc1.bias', 'opt_model.model.decoder.layers.26.fc2.weight', 'opt_model.model.decoder.layers.26.fc2.bias', 'opt_model.model.decoder.layers.26.final_layer_norm.weight', 'opt_model.model.decoder.layers.26.final_layer_norm.bias', 'opt_model.model.decoder.layers.27.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.27.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.27.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.27.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.27.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.27.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.27.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.27.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.27.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.27.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.27.fc1.weight', 'opt_model.model.decoder.layers.27.fc1.bias', 'opt_model.model.decoder.layers.27.fc2.weight', 'opt_model.model.decoder.layers.27.fc2.bias', 'opt_model.model.decoder.layers.27.final_layer_norm.weight', 'opt_model.model.decoder.layers.27.final_layer_norm.bias', 'opt_model.model.decoder.layers.28.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.28.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.28.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.28.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.28.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.28.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.28.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.28.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.28.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.28.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.28.fc1.weight', 'opt_model.model.decoder.layers.28.fc1.bias', 'opt_model.model.decoder.layers.28.fc2.weight', 'opt_model.model.decoder.layers.28.fc2.bias', 'opt_model.model.decoder.layers.28.final_layer_norm.weight', 'opt_model.model.decoder.layers.28.final_layer_norm.bias', 'opt_model.model.decoder.layers.29.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.29.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.29.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.29.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.29.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.29.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.29.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.29.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.29.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.29.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.29.fc1.weight', 'opt_model.model.decoder.layers.29.fc1.bias', 'opt_model.model.decoder.layers.29.fc2.weight', 'opt_model.model.decoder.layers.29.fc2.bias', 'opt_model.model.decoder.layers.29.final_layer_norm.weight', 'opt_model.model.decoder.layers.29.final_layer_norm.bias', 'opt_model.model.decoder.layers.30.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.30.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.30.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.30.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.30.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.30.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.30.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.30.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.30.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.30.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.30.fc1.weight', 'opt_model.model.decoder.layers.30.fc1.bias', 'opt_model.model.decoder.layers.30.fc2.weight', 'opt_model.model.decoder.layers.30.fc2.bias', 'opt_model.model.decoder.layers.30.final_layer_norm.weight', 'opt_model.model.decoder.layers.30.final_layer_norm.bias', 'opt_model.model.decoder.layers.31.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.31.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.31.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.31.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.31.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.31.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.31.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.31.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.31.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.31.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.31.fc1.weight', 'opt_model.model.decoder.layers.31.fc1.bias', 'opt_model.model.decoder.layers.31.fc2.weight', 'opt_model.model.decoder.layers.31.fc2.bias', 'opt_model.model.decoder.layers.31.final_layer_norm.weight', 'opt_model.model.decoder.layers.31.final_layer_norm.bias', 'opt_model.lm_head.weight', 'Darkformer.embeddings.position_ids', 'Darkformer.embeddings.word_embeddings.weight', 'Darkformer.embeddings.position_embeddings.weight', 'Darkformer.embeddings.token_type_embeddings.weight', 'Darkformer.embeddings.LayerNorm.weight', 'Darkformer.embeddings.LayerNorm.bias', 'Darkformer.encoder.layer.0.attention.self.query.weight', 'Darkformer.encoder.layer.0.attention.self.query.bias', 'Darkformer.encoder.layer.0.attention.self.key.weight', 'Darkformer.encoder.layer.0.attention.self.key.bias', 'Darkformer.encoder.layer.0.attention.self.value.weight', 'Darkformer.encoder.layer.0.attention.self.value.bias', 'Darkformer.encoder.layer.0.attention.output.dense.weight', 'Darkformer.encoder.layer.0.attention.output.dense.bias', 'Darkformer.encoder.layer.0.attention.output.LayerNorm.weight', 'Darkformer.encoder.layer.0.attention.output.LayerNorm.bias', 'Darkformer.encoder.layer.0.intermediate.dense.weight', 'Darkformer.encoder.layer.0.intermediate.dense.bias', 'Darkformer.encoder.layer.0.output.dense.weight', 'Darkformer.encoder.layer.0.output.dense.bias', 'Darkformer.encoder.layer.0.output.LayerNorm.weight', 'Darkformer.encoder.layer.0.output.LayerNorm.bias', 'Darkformer.encoder.layer.1.attention.self.query.weight', 'Darkformer.encoder.layer.1.attention.self.query.bias', 'Darkformer.encoder.layer.1.attention.self.key.weight', 'Darkformer.encoder.layer.1.attention.self.key.bias', 'Darkformer.encoder.layer.1.attention.self.value.weight', 'Darkformer.encoder.layer.1.attention.self.value.bias', 'Darkformer.encoder.layer.1.attention.output.dense.weight', 'Darkformer.encoder.layer.1.attention.output.dense.bias', 'Darkformer.encoder.layer.1.attention.output.LayerNorm.weight', 'Darkformer.encoder.layer.1.attention.output.LayerNorm.bias', 'Darkformer.encoder.layer.1.intermediate.dense.weight', 'Darkformer.encoder.layer.1.intermediate.dense.bias', 'Darkformer.encoder.layer.1.output.dense.weight', 'Darkformer.encoder.layer.1.output.dense.bias', 'Darkformer.encoder.layer.1.output.LayerNorm.weight', 'Darkformer.encoder.layer.1.output.LayerNorm.bias', 'Darkformer.encoder.layer.2.attention.self.query.weight', 'Darkformer.encoder.layer.2.attention.self.query.bias', 'Darkformer.encoder.layer.2.attention.self.key.weight', 'Darkformer.encoder.layer.2.attention.self.key.bias', 'Darkformer.encoder.layer.2.attention.self.value.weight', 'Darkformer.encoder.layer.2.attention.self.value.bias', 'Darkformer.encoder.layer.2.attention.output.dense.weight', 'Darkformer.encoder.layer.2.attention.output.dense.bias', 'Darkformer.encoder.layer.2.attention.output.LayerNorm.weight', 'Darkformer.encoder.layer.2.attention.output.LayerNorm.bias', 'Darkformer.encoder.layer.2.intermediate.dense.weight', 'Darkformer.encoder.layer.2.intermediate.dense.bias', 'Darkformer.encoder.layer.2.output.dense.weight', 'Darkformer.encoder.layer.2.output.dense.bias', 'Darkformer.encoder.layer.2.output.LayerNorm.weight', 'Darkformer.encoder.layer.2.output.LayerNorm.bias', 'Darkformer.encoder.layer.3.attention.self.query.weight', 'Darkformer.encoder.layer.3.attention.self.query.bias', 'Darkformer.encoder.layer.3.attention.self.key.weight', 'Darkformer.encoder.layer.3.attention.self.key.bias', 'Darkformer.encoder.layer.3.attention.self.value.weight', 'Darkformer.encoder.layer.3.attention.self.value.bias', 'Darkformer.encoder.layer.3.attention.output.dense.weight', 'Darkformer.encoder.layer.3.attention.output.dense.bias', 'Darkformer.encoder.layer.3.attention.output.LayerNorm.weight', 'Darkformer.encoder.layer.3.attention.output.LayerNorm.bias', 'Darkformer.encoder.layer.3.intermediate.dense.weight', 'Darkformer.encoder.layer.3.intermediate.dense.bias', 'Darkformer.encoder.layer.3.output.dense.weight', 'Darkformer.encoder.layer.3.output.dense.bias', 'Darkformer.encoder.layer.3.output.LayerNorm.weight', 'Darkformer.encoder.layer.3.output.LayerNorm.bias', 'Darkformer.encoder.layer.4.attention.self.query.weight', 'Darkformer.encoder.layer.4.attention.self.query.bias', 'Darkformer.encoder.layer.4.attention.self.key.weight', 'Darkformer.encoder.layer.4.attention.self.key.bias', 'Darkformer.encoder.layer.4.attention.self.value.weight', 'Darkformer.encoder.layer.4.attention.self.value.bias', 'Darkformer.encoder.layer.4.attention.output.dense.weight', 'Darkformer.encoder.layer.4.attention.output.dense.bias', 'Darkformer.encoder.layer.4.attention.output.LayerNorm.weight', 'Darkformer.encoder.layer.4.attention.output.LayerNorm.bias', 'Darkformer.encoder.layer.4.intermediate.dense.weight', 'Darkformer.encoder.layer.4.intermediate.dense.bias', 'Darkformer.encoder.layer.4.output.dense.weight', 'Darkformer.encoder.layer.4.output.dense.bias', 'Darkformer.encoder.layer.4.output.LayerNorm.weight', 'Darkformer.encoder.layer.4.output.LayerNorm.bias', 'Darkformer.encoder.layer.5.attention.self.query.weight', 'Darkformer.encoder.layer.5.attention.self.query.bias', 'Darkformer.encoder.layer.5.attention.self.key.weight', 'Darkformer.encoder.layer.5.attention.self.key.bias', 'Darkformer.encoder.layer.5.attention.self.value.weight', 'Darkformer.encoder.layer.5.attention.self.value.bias', 'Darkformer.encoder.layer.5.attention.output.dense.weight', 'Darkformer.encoder.layer.5.attention.output.dense.bias', 'Darkformer.encoder.layer.5.attention.output.LayerNorm.weight', 'Darkformer.encoder.layer.5.attention.output.LayerNorm.bias', 'Darkformer.encoder.layer.5.intermediate.dense.weight', 'Darkformer.encoder.layer.5.intermediate.dense.bias', 'Darkformer.encoder.layer.5.output.dense.weight', 'Darkformer.encoder.layer.5.output.dense.bias', 'Darkformer.encoder.layer.5.output.LayerNorm.weight', 'Darkformer.encoder.layer.5.output.LayerNorm.bias', 'Darkformer.encoder.layer.6.attention.self.query.weight', 'Darkformer.encoder.layer.6.attention.self.query.bias', 'Darkformer.encoder.layer.6.attention.self.key.weight', 'Darkformer.encoder.layer.6.attention.self.key.bias', 'Darkformer.encoder.layer.6.attention.self.value.weight', 'Darkformer.encoder.layer.6.attention.self.value.bias', 'Darkformer.encoder.layer.6.attention.output.dense.weight', 'Darkformer.encoder.layer.6.attention.output.dense.bias', 'Darkformer.encoder.layer.6.attention.output.LayerNorm.weight', 'Darkformer.encoder.layer.6.attention.output.LayerNorm.bias', 'Darkformer.encoder.layer.6.intermediate.dense.weight', 'Darkformer.encoder.layer.6.intermediate.dense.bias', 'Darkformer.encoder.layer.6.output.dense.weight', 'Darkformer.encoder.layer.6.output.dense.bias', 'Darkformer.encoder.layer.6.output.LayerNorm.weight', 'Darkformer.encoder.layer.6.output.LayerNorm.bias', 'Darkformer.encoder.layer.7.attention.self.query.weight', 'Darkformer.encoder.layer.7.attention.self.query.bias', 'Darkformer.encoder.layer.7.attention.self.key.weight', 'Darkformer.encoder.layer.7.attention.self.key.bias', 'Darkformer.encoder.layer.7.attention.self.value.weight', 'Darkformer.encoder.layer.7.attention.self.value.bias', 'Darkformer.encoder.layer.7.attention.output.dense.weight', 'Darkformer.encoder.layer.7.attention.output.dense.bias', 'Darkformer.encoder.layer.7.attention.output.LayerNorm.weight', 'Darkformer.encoder.layer.7.attention.output.LayerNorm.bias', 'Darkformer.encoder.layer.7.intermediate.dense.weight', 'Darkformer.encoder.layer.7.intermediate.dense.bias', 'Darkformer.encoder.layer.7.output.dense.weight', 'Darkformer.encoder.layer.7.output.dense.bias', 'Darkformer.encoder.layer.7.output.LayerNorm.weight', 'Darkformer.encoder.layer.7.output.LayerNorm.bias', 'Darkformer.encoder.layer.8.attention.self.query.weight', 'Darkformer.encoder.layer.8.attention.self.query.bias', 'Darkformer.encoder.layer.8.attention.self.key.weight', 'Darkformer.encoder.layer.8.attention.self.key.bias', 'Darkformer.encoder.layer.8.attention.self.value.weight', 'Darkformer.encoder.layer.8.attention.self.value.bias', 'Darkformer.encoder.layer.8.attention.output.dense.weight', 'Darkformer.encoder.layer.8.attention.output.dense.bias', 'Darkformer.encoder.layer.8.attention.output.LayerNorm.weight', 'Darkformer.encoder.layer.8.attention.output.LayerNorm.bias', 'Darkformer.encoder.layer.8.intermediate.dense.weight', 'Darkformer.encoder.layer.8.intermediate.dense.bias', 'Darkformer.encoder.layer.8.output.dense.weight', 'Darkformer.encoder.layer.8.output.dense.bias', 'Darkformer.encoder.layer.8.output.LayerNorm.weight', 'Darkformer.encoder.layer.8.output.LayerNorm.bias', 'Darkformer.encoder.layer.9.attention.self.query.weight', 'Darkformer.encoder.layer.9.attention.self.query.bias', 'Darkformer.encoder.layer.9.attention.self.key.weight', 'Darkformer.encoder.layer.9.attention.self.key.bias', 'Darkformer.encoder.layer.9.attention.self.value.weight', 'Darkformer.encoder.layer.9.attention.self.value.bias', 'Darkformer.encoder.layer.9.attention.output.dense.weight', 'Darkformer.encoder.layer.9.attention.output.dense.bias', 'Darkformer.encoder.layer.9.attention.output.LayerNorm.weight', 'Darkformer.encoder.layer.9.attention.output.LayerNorm.bias', 'Darkformer.encoder.layer.9.intermediate.dense.weight', 'Darkformer.encoder.layer.9.intermediate.dense.bias', 'Darkformer.encoder.layer.9.output.dense.weight', 'Darkformer.encoder.layer.9.output.dense.bias', 'Darkformer.encoder.layer.9.output.LayerNorm.weight', 'Darkformer.encoder.layer.9.output.LayerNorm.bias', 'Darkformer.encoder.layer.10.attention.self.query.weight', 'Darkformer.encoder.layer.10.attention.self.query.bias', 'Darkformer.encoder.layer.10.attention.self.key.weight', 'Darkformer.encoder.layer.10.attention.self.key.bias', 'Darkformer.encoder.layer.10.attention.self.value.weight', 'Darkformer.encoder.layer.10.attention.self.value.bias', 'Darkformer.encoder.layer.10.attention.output.dense.weight', 'Darkformer.encoder.layer.10.attention.output.dense.bias', 'Darkformer.encoder.layer.10.attention.output.LayerNorm.weight', 'Darkformer.encoder.layer.10.attention.output.LayerNorm.bias', 'Darkformer.encoder.layer.10.intermediate.dense.weight', 'Darkformer.encoder.layer.10.intermediate.dense.bias', 'Darkformer.encoder.layer.10.output.dense.weight', 'Darkformer.encoder.layer.10.output.dense.bias', 'Darkformer.encoder.layer.10.output.LayerNorm.weight', 'Darkformer.encoder.layer.10.output.LayerNorm.bias', 'Darkformer.encoder.layer.11.attention.self.query.weight', 'Darkformer.encoder.layer.11.attention.self.query.bias', 'Darkformer.encoder.layer.11.attention.self.key.weight', 'Darkformer.encoder.layer.11.attention.self.key.bias', 'Darkformer.encoder.layer.11.attention.self.value.weight', 'Darkformer.encoder.layer.11.attention.self.value.bias', 'Darkformer.encoder.layer.11.attention.output.dense.weight', 'Darkformer.encoder.layer.11.attention.output.dense.bias', 'Darkformer.encoder.layer.11.attention.output.LayerNorm.weight', 'Darkformer.encoder.layer.11.attention.output.LayerNorm.bias', 'Darkformer.encoder.layer.11.intermediate.dense.weight', 'Darkformer.encoder.layer.11.intermediate.dense.bias', 'Darkformer.encoder.layer.11.output.dense.weight', 'Darkformer.encoder.layer.11.output.dense.bias', 'Darkformer.encoder.layer.11.output.LayerNorm.weight', 'Darkformer.encoder.layer.11.output.LayerNorm.bias', 'Darkformer.cls_proj.weight', 'Darkformer.cls_proj.bias', 'Darkformer.pooler.0.weight', 'Darkformer.pooler.0.bias', 'Darkformer.opt_proj.weight', 'Darkformer.opt_proj.bias']
2023-05-10 18:37:02,014 [INFO] load checkpoint from https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP2/blip2_pretrained_opt2.7b.pth
2023-05-10 18:37:16,973 [INFO] Missing keys ['VL_adaptor.embeddings.position_ids', 'VL_adaptor.embeddings.word_embeddings.weight', 'VL_adaptor.embeddings.position_embeddings.weight', 'VL_adaptor.embeddings.token_type_embeddings.weight', 'VL_adaptor.embeddings.LayerNorm.weight', 'VL_adaptor.embeddings.LayerNorm.bias', 'VL_adaptor.encoder.layer.0.attention.self.query.weight', 'VL_adaptor.encoder.layer.0.attention.self.query.bias', 'VL_adaptor.encoder.layer.0.attention.self.key.weight', 'VL_adaptor.encoder.layer.0.attention.self.key.bias', 'VL_adaptor.encoder.layer.0.attention.self.value.weight', 'VL_adaptor.encoder.layer.0.attention.self.value.bias', 'VL_adaptor.encoder.layer.0.attention.output.dense.weight', 'VL_adaptor.encoder.layer.0.attention.output.dense.bias', 'VL_adaptor.encoder.layer.0.attention.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.0.attention.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.0.intermediate.dense.weight', 'VL_adaptor.encoder.layer.0.intermediate.dense.bias', 'VL_adaptor.encoder.layer.0.output.dense.weight', 'VL_adaptor.encoder.layer.0.output.dense.bias', 'VL_adaptor.encoder.layer.0.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.0.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.1.attention.self.query.weight', 'VL_adaptor.encoder.layer.1.attention.self.query.bias', 'VL_adaptor.encoder.layer.1.attention.self.key.weight', 'VL_adaptor.encoder.layer.1.attention.self.key.bias', 'VL_adaptor.encoder.layer.1.attention.self.value.weight', 'VL_adaptor.encoder.layer.1.attention.self.value.bias', 'VL_adaptor.encoder.layer.1.attention.output.dense.weight', 'VL_adaptor.encoder.layer.1.attention.output.dense.bias', 'VL_adaptor.encoder.layer.1.attention.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.1.attention.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.1.intermediate.dense.weight', 'VL_adaptor.encoder.layer.1.intermediate.dense.bias', 'VL_adaptor.encoder.layer.1.output.dense.weight', 'VL_adaptor.encoder.layer.1.output.dense.bias', 'VL_adaptor.encoder.layer.1.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.1.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.2.attention.self.query.weight', 'VL_adaptor.encoder.layer.2.attention.self.query.bias', 'VL_adaptor.encoder.layer.2.attention.self.key.weight', 'VL_adaptor.encoder.layer.2.attention.self.key.bias', 'VL_adaptor.encoder.layer.2.attention.self.value.weight', 'VL_adaptor.encoder.layer.2.attention.self.value.bias', 'VL_adaptor.encoder.layer.2.attention.output.dense.weight', 'VL_adaptor.encoder.layer.2.attention.output.dense.bias', 'VL_adaptor.encoder.layer.2.attention.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.2.attention.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.2.intermediate.dense.weight', 'VL_adaptor.encoder.layer.2.intermediate.dense.bias', 'VL_adaptor.encoder.layer.2.output.dense.weight', 'VL_adaptor.encoder.layer.2.output.dense.bias', 'VL_adaptor.encoder.layer.2.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.2.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.3.attention.self.query.weight', 'VL_adaptor.encoder.layer.3.attention.self.query.bias', 'VL_adaptor.encoder.layer.3.attention.self.key.weight', 'VL_adaptor.encoder.layer.3.attention.self.key.bias', 'VL_adaptor.encoder.layer.3.attention.self.value.weight', 'VL_adaptor.encoder.layer.3.attention.self.value.bias', 'VL_adaptor.encoder.layer.3.attention.output.dense.weight', 'VL_adaptor.encoder.layer.3.attention.output.dense.bias', 'VL_adaptor.encoder.layer.3.attention.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.3.attention.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.3.intermediate.dense.weight', 'VL_adaptor.encoder.layer.3.intermediate.dense.bias', 'VL_adaptor.encoder.layer.3.output.dense.weight', 'VL_adaptor.encoder.layer.3.output.dense.bias', 'VL_adaptor.encoder.layer.3.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.3.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.4.attention.self.query.weight', 'VL_adaptor.encoder.layer.4.attention.self.query.bias', 'VL_adaptor.encoder.layer.4.attention.self.key.weight', 'VL_adaptor.encoder.layer.4.attention.self.key.bias', 'VL_adaptor.encoder.layer.4.attention.self.value.weight', 'VL_adaptor.encoder.layer.4.attention.self.value.bias', 'VL_adaptor.encoder.layer.4.attention.output.dense.weight', 'VL_adaptor.encoder.layer.4.attention.output.dense.bias', 'VL_adaptor.encoder.layer.4.attention.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.4.attention.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.4.intermediate.dense.weight', 'VL_adaptor.encoder.layer.4.intermediate.dense.bias', 'VL_adaptor.encoder.layer.4.output.dense.weight', 'VL_adaptor.encoder.layer.4.output.dense.bias', 'VL_adaptor.encoder.layer.4.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.4.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.5.attention.self.query.weight', 'VL_adaptor.encoder.layer.5.attention.self.query.bias', 'VL_adaptor.encoder.layer.5.attention.self.key.weight', 'VL_adaptor.encoder.layer.5.attention.self.key.bias', 'VL_adaptor.encoder.layer.5.attention.self.value.weight', 'VL_adaptor.encoder.layer.5.attention.self.value.bias', 'VL_adaptor.encoder.layer.5.attention.output.dense.weight', 'VL_adaptor.encoder.layer.5.attention.output.dense.bias', 'VL_adaptor.encoder.layer.5.attention.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.5.attention.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.5.intermediate.dense.weight', 'VL_adaptor.encoder.layer.5.intermediate.dense.bias', 'VL_adaptor.encoder.layer.5.output.dense.weight', 'VL_adaptor.encoder.layer.5.output.dense.bias', 'VL_adaptor.encoder.layer.5.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.5.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.6.attention.self.query.weight', 'VL_adaptor.encoder.layer.6.attention.self.query.bias', 'VL_adaptor.encoder.layer.6.attention.self.key.weight', 'VL_adaptor.encoder.layer.6.attention.self.key.bias', 'VL_adaptor.encoder.layer.6.attention.self.value.weight', 'VL_adaptor.encoder.layer.6.attention.self.value.bias', 'VL_adaptor.encoder.layer.6.attention.output.dense.weight', 'VL_adaptor.encoder.layer.6.attention.output.dense.bias', 'VL_adaptor.encoder.layer.6.attention.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.6.attention.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.6.intermediate.dense.weight', 'VL_adaptor.encoder.layer.6.intermediate.dense.bias', 'VL_adaptor.encoder.layer.6.output.dense.weight', 'VL_adaptor.encoder.layer.6.output.dense.bias', 'VL_adaptor.encoder.layer.6.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.6.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.7.attention.self.query.weight', 'VL_adaptor.encoder.layer.7.attention.self.query.bias', 'VL_adaptor.encoder.layer.7.attention.self.key.weight', 'VL_adaptor.encoder.layer.7.attention.self.key.bias', 'VL_adaptor.encoder.layer.7.attention.self.value.weight', 'VL_adaptor.encoder.layer.7.attention.self.value.bias', 'VL_adaptor.encoder.layer.7.attention.output.dense.weight', 'VL_adaptor.encoder.layer.7.attention.output.dense.bias', 'VL_adaptor.encoder.layer.7.attention.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.7.attention.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.7.intermediate.dense.weight', 'VL_adaptor.encoder.layer.7.intermediate.dense.bias', 'VL_adaptor.encoder.layer.7.output.dense.weight', 'VL_adaptor.encoder.layer.7.output.dense.bias', 'VL_adaptor.encoder.layer.7.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.7.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.8.attention.self.query.weight', 'VL_adaptor.encoder.layer.8.attention.self.query.bias', 'VL_adaptor.encoder.layer.8.attention.self.key.weight', 'VL_adaptor.encoder.layer.8.attention.self.key.bias', 'VL_adaptor.encoder.layer.8.attention.self.value.weight', 'VL_adaptor.encoder.layer.8.attention.self.value.bias', 'VL_adaptor.encoder.layer.8.attention.output.dense.weight', 'VL_adaptor.encoder.layer.8.attention.output.dense.bias', 'VL_adaptor.encoder.layer.8.attention.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.8.attention.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.8.intermediate.dense.weight', 'VL_adaptor.encoder.layer.8.intermediate.dense.bias', 'VL_adaptor.encoder.layer.8.output.dense.weight', 'VL_adaptor.encoder.layer.8.output.dense.bias', 'VL_adaptor.encoder.layer.8.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.8.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.9.attention.self.query.weight', 'VL_adaptor.encoder.layer.9.attention.self.query.bias', 'VL_adaptor.encoder.layer.9.attention.self.key.weight', 'VL_adaptor.encoder.layer.9.attention.self.key.bias', 'VL_adaptor.encoder.layer.9.attention.self.value.weight', 'VL_adaptor.encoder.layer.9.attention.self.value.bias', 'VL_adaptor.encoder.layer.9.attention.output.dense.weight', 'VL_adaptor.encoder.layer.9.attention.output.dense.bias', 'VL_adaptor.encoder.layer.9.attention.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.9.attention.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.9.intermediate.dense.weight', 'VL_adaptor.encoder.layer.9.intermediate.dense.bias', 'VL_adaptor.encoder.layer.9.output.dense.weight', 'VL_adaptor.encoder.layer.9.output.dense.bias', 'VL_adaptor.encoder.layer.9.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.9.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.10.attention.self.query.weight', 'VL_adaptor.encoder.layer.10.attention.self.query.bias', 'VL_adaptor.encoder.layer.10.attention.self.key.weight', 'VL_adaptor.encoder.layer.10.attention.self.key.bias', 'VL_adaptor.encoder.layer.10.attention.self.value.weight', 'VL_adaptor.encoder.layer.10.attention.self.value.bias', 'VL_adaptor.encoder.layer.10.attention.output.dense.weight', 'VL_adaptor.encoder.layer.10.attention.output.dense.bias', 'VL_adaptor.encoder.layer.10.attention.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.10.attention.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.10.intermediate.dense.weight', 'VL_adaptor.encoder.layer.10.intermediate.dense.bias', 'VL_adaptor.encoder.layer.10.output.dense.weight', 'VL_adaptor.encoder.layer.10.output.dense.bias', 'VL_adaptor.encoder.layer.10.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.10.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.11.attention.self.query.weight', 'VL_adaptor.encoder.layer.11.attention.self.query.bias', 'VL_adaptor.encoder.layer.11.attention.self.key.weight', 'VL_adaptor.encoder.layer.11.attention.self.key.bias', 'VL_adaptor.encoder.layer.11.attention.self.value.weight', 'VL_adaptor.encoder.layer.11.attention.self.value.bias', 'VL_adaptor.encoder.layer.11.attention.output.dense.weight', 'VL_adaptor.encoder.layer.11.attention.output.dense.bias', 'VL_adaptor.encoder.layer.11.attention.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.11.attention.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.11.intermediate.dense.weight', 'VL_adaptor.encoder.layer.11.intermediate.dense.bias', 'VL_adaptor.encoder.layer.11.output.dense.weight', 'VL_adaptor.encoder.layer.11.output.dense.bias', 'VL_adaptor.encoder.layer.11.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.11.output.LayerNorm.bias', 'VL_adaptor.feat_proj.weight', 'VL_adaptor.feat_proj.bias', 'opt_proj.weight', 'opt_proj.bias']
2023-05-10 18:37:16,973 [INFO] load checkpoint from /home/yiren/LAVIS/lavis/output/BLIP-T/Pretrain_stage0/vq/40m-noisy/checkpoint_60000.pth
2023-05-10 18:37:17,128 [INFO] Start training
2023-05-10 18:37:17,965 [INFO] dataset_ratios not specified, datasets will be concatenated (map-style datasets) or chained (webdataset.DataPipeline).
2023-05-10 18:37:17,965 [INFO] Loaded 259910 records for train split from the dataset.
2023-05-10 18:37:17,965 [INFO] Loaded 3000 records for val split from the dataset.
2023-05-10 18:37:17,974 [INFO] number of trainable parameters: 87810304
2023-05-10 18:37:17,975 [INFO] Start training epoch 0, 2030 iters per inner epoch.
/home/yiren/anaconda3/envs/lavis/lib/python3.8/site-packages/transformers/modeling_utils.py:810: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
Train: data epoch: [0]  [   0/2030]  eta: 0:41:22  lr: 0.000001  loss: 21.7157  time: 1.2227  data: 0.0000  max mem: 8448
2023-05-10 18:37:19,201 [INFO] Reducer buckets have been rebuilt in this iteration.
Train: data epoch: [0]  [  50/2030]  eta: 0:04:50  lr: 0.000006  loss: 5.4797  time: 0.1263  data: 0.0000  max mem: 9128
Train: data epoch: [0]  [ 100/2030]  eta: 0:04:22  lr: 0.000011  loss: 3.6765  time: 0.1249  data: 0.0000  max mem: 9128
Train: data epoch: [0]  [ 150/2030]  eta: 0:04:09  lr: 0.000016  loss: 2.6226  time: 0.1269  data: 0.0000  max mem: 9128
Train: data epoch: [0]  [ 200/2030]  eta: 0:03:58  lr: 0.000021  loss: 2.3513  time: 0.1251  data: 0.0000  max mem: 9128
Train: data epoch: [0]  [ 250/2030]  eta: 0:03:50  lr: 0.000026  loss: 2.1208  time: 0.1241  data: 0.0000  max mem: 9128
Train: data epoch: [0]  [ 300/2030]  eta: 0:03:42  lr: 0.000031  loss: 1.9740  time: 0.1241  data: 0.0000  max mem: 9128
Train: data epoch: [0]  [ 350/2030]  eta: 0:03:34  lr: 0.000036  loss: 1.9265  time: 0.1247  data: 0.0000  max mem: 9128
Train: data epoch: [0]  [ 400/2030]  eta: 0:03:27  lr: 0.000041  loss: 2.0495  time: 0.1250  data: 0.0000  max mem: 9128
Train: data epoch: [0]  [ 450/2030]  eta: 0:03:21  lr: 0.000046  loss: 1.9258  time: 0.1258  data: 0.0000  max mem: 9128
Train: data epoch: [0]  [ 500/2030]  eta: 0:03:14  lr: 0.000051  loss: 1.9483  time: 0.1260  data: 0.0000  max mem: 9128
Train: data epoch: [0]  [ 550/2030]  eta: 0:03:08  lr: 0.000055  loss: 1.8475  time: 0.1259  data: 0.0000  max mem: 9128
Train: data epoch: [0]  [ 600/2030]  eta: 0:03:01  lr: 0.000060  loss: 1.8888  time: 0.1254  data: 0.0000  max mem: 9128
Train: data epoch: [0]  [ 650/2030]  eta: 0:02:55  lr: 0.000065  loss: 1.9605  time: 0.1263  data: 0.0000  max mem: 9128
Train: data epoch: [0]  [ 700/2030]  eta: 0:02:49  lr: 0.000070  loss: 1.9878  time: 0.1261  data: 0.0000  max mem: 9128
Train: data epoch: [0]  [ 750/2030]  eta: 0:02:42  lr: 0.000075  loss: 1.9907  time: 0.1266  data: 0.0000  max mem: 9128
Train: data epoch: [0]  [ 800/2030]  eta: 0:02:36  lr: 0.000080  loss: 2.0686  time: 0.1272  data: 0.0000  max mem: 9128
Train: data epoch: [0]  [ 850/2030]  eta: 0:02:30  lr: 0.000085  loss: 1.9077  time: 0.1269  data: 0.0000  max mem: 9128
Train: data epoch: [0]  [ 900/2030]  eta: 0:02:23  lr: 0.000090  loss: 2.0820  time: 0.1264  data: 0.0000  max mem: 9128
Train: data epoch: [0]  [ 950/2030]  eta: 0:02:17  lr: 0.000095  loss: 1.9856  time: 0.1265  data: 0.0000  max mem: 9128
Train: data epoch: [0]  [1000/2030]  eta: 0:02:10  lr: 0.000100  loss: 2.0715  time: 0.1267  data: 0.0000  max mem: 9128
Train: data epoch: [0]  [1050/2030]  eta: 0:02:04  lr: 0.000100  loss: 2.0393  time: 0.1258  data: 0.0000  max mem: 9128
Train: data epoch: [0]  [1100/2030]  eta: 0:01:58  lr: 0.000100  loss: 1.9280  time: 0.1265  data: 0.0000  max mem: 9128
Train: data epoch: [0]  [1150/2030]  eta: 0:01:51  lr: 0.000100  loss: 1.7614  time: 0.1264  data: 0.0000  max mem: 9128
Train: data epoch: [0]  [1200/2030]  eta: 0:01:45  lr: 0.000100  loss: 1.9591  time: 0.1257  data: 0.0000  max mem: 9128
Train: data epoch: [0]  [1250/2030]  eta: 0:01:38  lr: 0.000100  loss: 1.9357  time: 0.1259  data: 0.0000  max mem: 9128
Train: data epoch: [0]  [1300/2030]  eta: 0:01:32  lr: 0.000100  loss: 2.0496  time: 0.1262  data: 0.0000  max mem: 9128
Train: data epoch: [0]  [1350/2030]  eta: 0:01:26  lr: 0.000100  loss: 2.0558  time: 0.1268  data: 0.0000  max mem: 9128
Train: data epoch: [0]  [1400/2030]  eta: 0:01:19  lr: 0.000100  loss: 1.9135  time: 0.1274  data: 0.0000  max mem: 9128
Train: data epoch: [0]  [1450/2030]  eta: 0:01:13  lr: 0.000100  loss: 2.0732  time: 0.1262  data: 0.0000  max mem: 9128
Train: data epoch: [0]  [1500/2030]  eta: 0:01:07  lr: 0.000100  loss: 1.9076  time: 0.1267  data: 0.0000  max mem: 9128
Train: data epoch: [0]  [1550/2030]  eta: 0:01:00  lr: 0.000100  loss: 1.6133  time: 0.1277  data: 0.0000  max mem: 9128
Train: data epoch: [0]  [1600/2030]  eta: 0:00:54  lr: 0.000100  loss: 1.6090  time: 0.1272  data: 0.0000  max mem: 9128
Train: data epoch: [0]  [1650/2030]  eta: 0:00:48  lr: 0.000100  loss: 1.4142  time: 0.1269  data: 0.0000  max mem: 9128
Train: data epoch: [0]  [1700/2030]  eta: 0:00:41  lr: 0.000100  loss: 1.5201  time: 0.1267  data: 0.0000  max mem: 9128
Train: data epoch: [0]  [1750/2030]  eta: 0:00:35  lr: 0.000100  loss: 1.3206  time: 0.1275  data: 0.0000  max mem: 9128
Train: data epoch: [0]  [1800/2030]  eta: 0:00:29  lr: 0.000100  loss: 1.2829  time: 0.1276  data: 0.0000  max mem: 9128
Train: data epoch: [0]  [1850/2030]  eta: 0:00:22  lr: 0.000100  loss: 1.3419  time: 0.1270  data: 0.0000  max mem: 9128
Train: data epoch: [0]  [1900/2030]  eta: 0:00:16  lr: 0.000100  loss: 1.0961  time: 0.1261  data: 0.0000  max mem: 9128
Train: data epoch: [0]  [1950/2030]  eta: 0:00:10  lr: 0.000100  loss: 1.0856  time: 0.1271  data: 0.0000  max mem: 9128
Train: data epoch: [0]  [2000/2030]  eta: 0:00:03  lr: 0.000100  loss: 1.0845  time: 0.1264  data: 0.0000  max mem: 9128
Train: data epoch: [0]  [2029/2030]  eta: 0:00:00  lr: 0.000100  loss: 1.0174  time: 0.1311  data: 0.0000  max mem: 9128
Train: data epoch: [0] Total time: 0:04:17 (0.1270 s / it)
2023-05-10 18:41:35,853 [INFO] Averaged stats: lr: 0.0001  loss: 2.1227
2023-05-10 18:41:35,854 [INFO] Start training
2023-05-10 18:41:35,871 [INFO] Start training epoch 1, 2030 iters per inner epoch.
Train: data epoch: [1]  [   0/2030]  eta: 1:22:46  lr: 0.000098  loss: 1.0420  time: 2.4463  data: 0.0000  max mem: 9128
Train: data epoch: [1]  [  50/2030]  eta: 0:05:41  lr: 0.000098  loss: 1.0336  time: 0.1266  data: 0.0000  max mem: 9128
Train: data epoch: [1]  [ 100/2030]  eta: 0:04:48  lr: 0.000098  loss: 0.8620  time: 0.1260  data: 0.0000  max mem: 9128
Train: data epoch: [1]  [ 150/2030]  eta: 0:04:27  lr: 0.000098  loss: 0.9375  time: 0.1264  data: 0.0000  max mem: 9128
Train: data epoch: [1]  [ 200/2030]  eta: 0:04:12  lr: 0.000098  loss: 0.7775  time: 0.1263  data: 0.0000  max mem: 9128
Train: data epoch: [1]  [ 250/2030]  eta: 0:04:02  lr: 0.000098  loss: 0.8786  time: 0.1279  data: 0.0000  max mem: 9128
Train: data epoch: [1]  [ 300/2030]  eta: 0:03:52  lr: 0.000098  loss: 0.8651  time: 0.1269  data: 0.0000  max mem: 9128
Train: data epoch: [1]  [ 350/2030]  eta: 0:03:44  lr: 0.000098  loss: 0.9121  time: 0.1267  data: 0.0000  max mem: 9128
Train: data epoch: [1]  [ 400/2030]  eta: 0:03:36  lr: 0.000098  loss: 0.7539  time: 0.1324  data: 0.0000  max mem: 9128
Train: data epoch: [1]  [ 450/2030]  eta: 0:03:28  lr: 0.000098  loss: 0.8224  time: 0.1265  data: 0.0000  max mem: 9128
Train: data epoch: [1]  [ 500/2030]  eta: 0:03:21  lr: 0.000098  loss: 0.7222  time: 0.1262  data: 0.0000  max mem: 9128
Train: data epoch: [1]  [ 550/2030]  eta: 0:03:14  lr: 0.000098  loss: 0.7799  time: 0.1267  data: 0.0000  max mem: 9128
Train: data epoch: [1]  [ 600/2030]  eta: 0:03:07  lr: 0.000098  loss: 0.7822  time: 0.1271  data: 0.0000  max mem: 9128
Train: data epoch: [1]  [ 650/2030]  eta: 0:03:00  lr: 0.000098  loss: 0.7374  time: 0.1265  data: 0.0000  max mem: 9128
Train: data epoch: [1]  [ 700/2030]  eta: 0:02:53  lr: 0.000098  loss: 0.8305  time: 0.1266  data: 0.0000  max mem: 9128
Train: data epoch: [1]  [ 750/2030]  eta: 0:02:46  lr: 0.000098  loss: 0.8253  time: 0.1268  data: 0.0000  max mem: 9128
Train: data epoch: [1]  [ 800/2030]  eta: 0:02:39  lr: 0.000098  loss: 0.7189  time: 0.1266  data: 0.0000  max mem: 9128
Train: data epoch: [1]  [ 850/2030]  eta: 0:02:32  lr: 0.000098  loss: 0.7172  time: 0.1260  data: 0.0000  max mem: 9128
Train: data epoch: [1]  [ 900/2030]  eta: 0:02:26  lr: 0.000098  loss: 0.6699  time: 0.1268  data: 0.0000  max mem: 9128
Train: data epoch: [1]  [ 950/2030]  eta: 0:02:19  lr: 0.000098  loss: 0.6633  time: 0.1265  data: 0.0000  max mem: 9128
Train: data epoch: [1]  [1000/2030]  eta: 0:02:12  lr: 0.000098  loss: 0.7462  time: 0.1267  data: 0.0000  max mem: 9128
Train: data epoch: [1]  [1050/2030]  eta: 0:02:06  lr: 0.000098  loss: 0.7980  time: 0.1267  data: 0.0000  max mem: 9128
Train: data epoch: [1]  [1100/2030]  eta: 0:01:59  lr: 0.000098  loss: 0.6858  time: 0.1268  data: 0.0000  max mem: 9128
Train: data epoch: [1]  [1150/2030]  eta: 0:01:53  lr: 0.000098  loss: 0.6780  time: 0.1265  data: 0.0000  max mem: 9128
Train: data epoch: [1]  [1200/2030]  eta: 0:01:46  lr: 0.000098  loss: 0.7243  time: 0.1269  data: 0.0000  max mem: 9128
Train: data epoch: [1]  [1250/2030]  eta: 0:01:40  lr: 0.000098  loss: 0.6853  time: 0.1267  data: 0.0000  max mem: 9128
Train: data epoch: [1]  [1300/2030]  eta: 0:01:33  lr: 0.000098  loss: 0.6670  time: 0.1310  data: 0.0000  max mem: 9128
Train: data epoch: [1]  [1350/2030]  eta: 0:01:27  lr: 0.000098  loss: 0.7358  time: 0.1263  data: 0.0000  max mem: 9128
Train: data epoch: [1]  [1400/2030]  eta: 0:01:20  lr: 0.000098  loss: 0.6681  time: 0.1264  data: 0.0000  max mem: 9128
Train: data epoch: [1]  [1450/2030]  eta: 0:01:14  lr: 0.000098  loss: 0.6635  time: 0.1265  data: 0.0000  max mem: 9128
Train: data epoch: [1]  [1500/2030]  eta: 0:01:08  lr: 0.000098  loss: 0.6941  time: 0.1264  data: 0.0000  max mem: 9128
Train: data epoch: [1]  [1550/2030]  eta: 0:01:01  lr: 0.000098  loss: 0.6878  time: 0.1265  data: 0.0000  max mem: 9128
Train: data epoch: [1]  [1600/2030]  eta: 0:00:55  lr: 0.000098  loss: 0.7511  time: 0.1265  data: 0.0000  max mem: 9128
Train: data epoch: [1]  [1650/2030]  eta: 0:00:48  lr: 0.000098  loss: 0.6968  time: 0.1279  data: 0.0000  max mem: 9128
Train: data epoch: [1]  [1700/2030]  eta: 0:00:42  lr: 0.000098  loss: 0.7195  time: 0.1263  data: 0.0000  max mem: 9128
Train: data epoch: [1]  [1750/2030]  eta: 0:00:35  lr: 0.000098  loss: 0.6854  time: 0.1285  data: 0.0000  max mem: 9128
Train: data epoch: [1]  [1800/2030]  eta: 0:00:29  lr: 0.000098  loss: 0.5753  time: 0.1274  data: 0.0000  max mem: 9128
Train: data epoch: [1]  [1850/2030]  eta: 0:00:23  lr: 0.000098  loss: 0.6682  time: 0.1267  data: 0.0000  max mem: 9128
Train: data epoch: [1]  [1900/2030]  eta: 0:00:16  lr: 0.000098  loss: 0.6448  time: 0.1268  data: 0.0000  max mem: 9128
Train: data epoch: [1]  [1950/2030]  eta: 0:00:10  lr: 0.000098  loss: 0.6641  time: 0.1271  data: 0.0000  max mem: 9128
Train: data epoch: [1]  [2000/2030]  eta: 0:00:03  lr: 0.000098  loss: 0.6480  time: 0.1268  data: 0.0000  max mem: 9128
Train: data epoch: [1]  [2029/2030]  eta: 0:00:00  lr: 0.000098  loss: 0.6281  time: 0.1302  data: 0.0000  max mem: 9128
Train: data epoch: [1] Total time: 0:04:19 (0.1280 s / it)
2023-05-10 18:45:55,778 [INFO] Averaged stats: lr: 0.0001  loss: 0.7446
2023-05-10 18:45:55,779 [INFO] Start training
2023-05-10 18:45:55,797 [INFO] Start training epoch 2, 2030 iters per inner epoch.
Train: data epoch: [2]  [   0/2030]  eta: 1:22:00  lr: 0.000091  loss: 0.6292  time: 2.4238  data: 0.0000  max mem: 9128
Train: data epoch: [2]  [  50/2030]  eta: 0:05:40  lr: 0.000091  loss: 0.5795  time: 0.1268  data: 0.0000  max mem: 9128
Train: data epoch: [2]  [ 100/2030]  eta: 0:04:49  lr: 0.000091  loss: 0.5953  time: 0.1275  data: 0.0000  max mem: 9128
Train: data epoch: [2]  [ 150/2030]  eta: 0:04:28  lr: 0.000091  loss: 0.6315  time: 0.1313  data: 0.0000  max mem: 9128
Train: data epoch: [2]  [ 200/2030]  eta: 0:04:14  lr: 0.000091  loss: 0.5845  time: 0.1268  data: 0.0000  max mem: 9128
Train: data epoch: [2]  [ 250/2030]  eta: 0:04:03  lr: 0.000091  loss: 0.6963  time: 0.1271  data: 0.0000  max mem: 9128
Train: data epoch: [2]  [ 300/2030]  eta: 0:03:53  lr: 0.000091  loss: 0.5987  time: 0.1265  data: 0.0000  max mem: 9128
Train: data epoch: [2]  [ 350/2030]  eta: 0:03:44  lr: 0.000091  loss: 0.6483  time: 0.1271  data: 0.0000  max mem: 9128
Train: data epoch: [2]  [ 400/2030]  eta: 0:03:36  lr: 0.000091  loss: 0.5568  time: 0.1269  data: 0.0000  max mem: 9128
Train: data epoch: [2]  [ 450/2030]  eta: 0:03:28  lr: 0.000091  loss: 0.6339  time: 0.1268  data: 0.0000  max mem: 9128
Train: data epoch: [2]  [ 500/2030]  eta: 0:03:21  lr: 0.000091  loss: 0.6078  time: 0.1271  data: 0.0000  max mem: 9128
Train: data epoch: [2]  [ 550/2030]  eta: 0:03:14  lr: 0.000091  loss: 0.6051  time: 0.1262  data: 0.0000  max mem: 9128
Train: data epoch: [2]  [ 600/2030]  eta: 0:03:07  lr: 0.000091  loss: 0.6282  time: 0.1263  data: 0.0000  max mem: 9128
Train: data epoch: [2]  [ 650/2030]  eta: 0:03:00  lr: 0.000091  loss: 0.5772  time: 0.1264  data: 0.0000  max mem: 9128
Train: data epoch: [2]  [ 700/2030]  eta: 0:02:53  lr: 0.000091  loss: 0.6065  time: 0.1265  data: 0.0000  max mem: 9128
Train: data epoch: [2]  [ 750/2030]  eta: 0:02:46  lr: 0.000091  loss: 0.6217  time: 0.1264  data: 0.0000  max mem: 9128
Train: data epoch: [2]  [ 800/2030]  eta: 0:02:39  lr: 0.000091  loss: 0.6099  time: 0.1265  data: 0.0000  max mem: 9128
Train: data epoch: [2]  [ 850/2030]  eta: 0:02:32  lr: 0.000091  loss: 0.6454  time: 0.1265  data: 0.0000  max mem: 9128
Train: data epoch: [2]  [ 900/2030]  eta: 0:02:26  lr: 0.000091  loss: 0.6071  time: 0.1271  data: 0.0000  max mem: 9128
Train: data epoch: [2]  [ 950/2030]  eta: 0:02:19  lr: 0.000091  loss: 0.6534  time: 0.1272  data: 0.0000  max mem: 9128
Train: data epoch: [2]  [1000/2030]  eta: 0:02:13  lr: 0.000091  loss: 0.6511  time: 0.1270  data: 0.0000  max mem: 9128
Train: data epoch: [2]  [1050/2030]  eta: 0:02:06  lr: 0.000091  loss: 0.6581  time: 0.1312  data: 0.0000  max mem: 9128
Train: data epoch: [2]  [1100/2030]  eta: 0:01:59  lr: 0.000091  loss: 0.5969  time: 0.1266  data: 0.0000  max mem: 9128
Train: data epoch: [2]  [1150/2030]  eta: 0:01:53  lr: 0.000091  loss: 0.6205  time: 0.1258  data: 0.0000  max mem: 9128
Train: data epoch: [2]  [1200/2030]  eta: 0:01:46  lr: 0.000091  loss: 0.6505  time: 0.1275  data: 0.0000  max mem: 9128
Train: data epoch: [2]  [1250/2030]  eta: 0:01:40  lr: 0.000091  loss: 0.5947  time: 0.1269  data: 0.0000  max mem: 9128
Train: data epoch: [2]  [1300/2030]  eta: 0:01:33  lr: 0.000091  loss: 0.6017  time: 0.1265  data: 0.0000  max mem: 9128
Train: data epoch: [2]  [1350/2030]  eta: 0:01:27  lr: 0.000091  loss: 0.6410  time: 0.1264  data: 0.0000  max mem: 9128
Train: data epoch: [2]  [1400/2030]  eta: 0:01:20  lr: 0.000091  loss: 0.6012  time: 0.1271  data: 0.0000  max mem: 9128
Train: data epoch: [2]  [1450/2030]  eta: 0:01:14  lr: 0.000091  loss: 0.6685  time: 0.1269  data: 0.0000  max mem: 9128
Train: data epoch: [2]  [1500/2030]  eta: 0:01:08  lr: 0.000091  loss: 0.6331  time: 0.1267  data: 0.0000  max mem: 9128
Train: data epoch: [2]  [1550/2030]  eta: 0:01:01  lr: 0.000091  loss: 0.6240  time: 0.1269  data: 0.0000  max mem: 9128
Train: data epoch: [2]  [1600/2030]  eta: 0:00:55  lr: 0.000091  loss: 0.6334  time: 0.1275  data: 0.0000  max mem: 9128
Train: data epoch: [2]  [1650/2030]  eta: 0:00:48  lr: 0.000091  loss: 0.5969  time: 0.1269  data: 0.0000  max mem: 9128
Train: data epoch: [2]  [1700/2030]  eta: 0:00:42  lr: 0.000091  loss: 0.6814  time: 0.1264  data: 0.0000  max mem: 9128
Train: data epoch: [2]  [1750/2030]  eta: 0:00:35  lr: 0.000091  loss: 0.6800  time: 0.1278  data: 0.0000  max mem: 9128
Train: data epoch: [2]  [1800/2030]  eta: 0:00:29  lr: 0.000091  loss: 0.5797  time: 0.1270  data: 0.0000  max mem: 9128
Train: data epoch: [2]  [1850/2030]  eta: 0:00:23  lr: 0.000091  loss: 0.5863  time: 0.1265  data: 0.0000  max mem: 9128
Train: data epoch: [2]  [1900/2030]  eta: 0:00:16  lr: 0.000091  loss: 0.6186  time: 0.1269  data: 0.0000  max mem: 9128
Train: data epoch: [2]  [1950/2030]  eta: 0:00:10  lr: 0.000091  loss: 0.5987  time: 0.1309  data: 0.0000  max mem: 9128
Train: data epoch: [2]  [2000/2030]  eta: 0:00:03  lr: 0.000091  loss: 0.6754  time: 0.1271  data: 0.0000  max mem: 9128
Train: data epoch: [2]  [2029/2030]  eta: 0:00:00  lr: 0.000091  loss: 0.5751  time: 0.1301  data: 0.0000  max mem: 9128
Train: data epoch: [2] Total time: 0:04:19 (0.1281 s / it)
2023-05-10 18:50:15,784 [INFO] Averaged stats: lr: 0.0001  loss: 0.6266
2023-05-10 18:50:15,785 [INFO] Start training
2023-05-10 18:50:15,803 [INFO] Start training epoch 3, 2030 iters per inner epoch.
Train: data epoch: [3]  [   0/2030]  eta: 1:22:35  lr: 0.000081  loss: 0.6095  time: 2.4410  data: 0.0000  max mem: 9128
Train: data epoch: [3]  [  50/2030]  eta: 0:05:41  lr: 0.000081  loss: 0.5832  time: 0.1266  data: 0.0000  max mem: 9128
Train: data epoch: [3]  [ 100/2030]  eta: 0:04:48  lr: 0.000081  loss: 0.6062  time: 0.1261  data: 0.0000  max mem: 9128
Train: data epoch: [3]  [ 150/2030]  eta: 0:04:27  lr: 0.000081  loss: 0.5720  time: 0.1265  data: 0.0000  max mem: 9128
Train: data epoch: [3]  [ 200/2030]  eta: 0:04:13  lr: 0.000081  loss: 0.6265  time: 0.1275  data: 0.0000  max mem: 9128
Train: data epoch: [3]  [ 250/2030]  eta: 0:04:02  lr: 0.000081  loss: 0.6384  time: 0.1267  data: 0.0000  max mem: 9128
Train: data epoch: [3]  [ 300/2030]  eta: 0:03:53  lr: 0.000081  loss: 0.6098  time: 0.1270  data: 0.0000  max mem: 9128
Train: data epoch: [3]  [ 350/2030]  eta: 0:03:44  lr: 0.000081  loss: 0.6043  time: 0.1269  data: 0.0000  max mem: 9128
Train: data epoch: [3]  [ 400/2030]  eta: 0:03:36  lr: 0.000081  loss: 0.5356  time: 0.1271  data: 0.0000  max mem: 9128
Train: data epoch: [3]  [ 450/2030]  eta: 0:03:28  lr: 0.000081  loss: 0.6697  time: 0.1269  data: 0.0000  max mem: 9128
Train: data epoch: [3]  [ 500/2030]  eta: 0:03:21  lr: 0.000081  loss: 0.6328  time: 0.1272  data: 0.0000  max mem: 9128
Train: data epoch: [3]  [ 550/2030]  eta: 0:03:14  lr: 0.000081  loss: 0.6344  time: 0.1271  data: 0.0000  max mem: 9128
Train: data epoch: [3]  [ 600/2030]  eta: 0:03:07  lr: 0.000081  loss: 0.6209  time: 0.1275  data: 0.0000  max mem: 9128
Train: data epoch: [3]  [ 650/2030]  eta: 0:03:00  lr: 0.000081  loss: 0.6460  time: 0.1280  data: 0.0000  max mem: 9128
Train: data epoch: [3]  [ 700/2030]  eta: 0:02:53  lr: 0.000081  loss: 0.6113  time: 0.1271  data: 0.0000  max mem: 9128
Train: data epoch: [3]  [ 750/2030]  eta: 0:02:46  lr: 0.000081  loss: 0.6189  time: 0.1270  data: 0.0000  max mem: 9128
Train: data epoch: [3]  [ 800/2030]  eta: 0:02:39  lr: 0.000081  loss: 0.6439  time: 0.1264  data: 0.0000  max mem: 9128
Train: data epoch: [3]  [ 850/2030]  eta: 0:02:33  lr: 0.000081  loss: 0.6111  time: 0.1267  data: 0.0000  max mem: 9128
Train: data epoch: [3]  [ 900/2030]  eta: 0:02:26  lr: 0.000081  loss: 0.6131  time: 0.1270  data: 0.0000  max mem: 9128
Train: data epoch: [3]  [ 950/2030]  eta: 0:02:19  lr: 0.000081  loss: 0.6293  time: 0.1265  data: 0.0000  max mem: 9128
Train: data epoch: [3]  [1000/2030]  eta: 0:02:13  lr: 0.000081  loss: 0.7017  time: 0.1268  data: 0.0000  max mem: 9128
Train: data epoch: [3]  [1050/2030]  eta: 0:02:06  lr: 0.000081  loss: 0.6270  time: 0.1267  data: 0.0000  max mem: 9128
Train: data epoch: [3]  [1100/2030]  eta: 0:02:00  lr: 0.000081  loss: 0.5687  time: 0.1266  data: 0.0000  max mem: 9128
Train: data epoch: [3]  [1150/2030]  eta: 0:01:53  lr: 0.000081  loss: 0.5765  time: 0.1269  data: 0.0000  max mem: 9128
Train: data epoch: [3]  [1200/2030]  eta: 0:01:47  lr: 0.000081  loss: 0.5760  time: 0.1264  data: 0.0000  max mem: 9128
Train: data epoch: [3]  [1250/2030]  eta: 0:01:40  lr: 0.000081  loss: 0.6370  time: 0.1268  data: 0.0000  max mem: 9128
Train: data epoch: [3]  [1300/2030]  eta: 0:01:34  lr: 0.000081  loss: 0.6257  time: 0.1271  data: 0.0000  max mem: 9128
Train: data epoch: [3]  [1350/2030]  eta: 0:01:27  lr: 0.000081  loss: 0.6132  time: 0.1264  data: 0.0000  max mem: 9128
Train: data epoch: [3]  [1400/2030]  eta: 0:01:21  lr: 0.000081  loss: 0.5808  time: 0.1270  data: 0.0000  max mem: 9128
Train: data epoch: [3]  [1450/2030]  eta: 0:01:14  lr: 0.000081  loss: 0.6422  time: 0.1268  data: 0.0000  max mem: 9128
Train: data epoch: [3]  [1500/2030]  eta: 0:01:08  lr: 0.000081  loss: 0.6817  time: 0.1268  data: 0.0000  max mem: 9128
Train: data epoch: [3]  [1550/2030]  eta: 0:01:01  lr: 0.000081  loss: 0.5407  time: 0.1270  data: 0.0000  max mem: 9128
Train: data epoch: [3]  [1600/2030]  eta: 0:00:55  lr: 0.000081  loss: 0.6527  time: 0.1271  data: 0.0000  max mem: 9128
Train: data epoch: [3]  [1650/2030]  eta: 0:00:48  lr: 0.000081  loss: 0.5691  time: 0.1266  data: 0.0000  max mem: 9128
Train: data epoch: [3]  [1700/2030]  eta: 0:00:42  lr: 0.000081  loss: 0.7108  time: 0.1273  data: 0.0000  max mem: 9128
Train: data epoch: [3]  [1750/2030]  eta: 0:00:35  lr: 0.000081  loss: 0.6020  time: 0.1272  data: 0.0000  max mem: 9128
Train: data epoch: [3]  [1800/2030]  eta: 0:00:29  lr: 0.000081  loss: 0.6063  time: 0.1264  data: 0.0000  max mem: 9128
Train: data epoch: [3]  [1850/2030]  eta: 0:00:23  lr: 0.000081  loss: 0.5655  time: 0.1279  data: 0.0000  max mem: 9128
Train: data epoch: [3]  [1900/2030]  eta: 0:00:16  lr: 0.000081  loss: 0.6131  time: 0.1275  data: 0.0000  max mem: 9128
Train: data epoch: [3]  [1950/2030]  eta: 0:00:10  lr: 0.000081  loss: 0.6519  time: 0.1269  data: 0.0000  max mem: 9128
Train: data epoch: [3]  [2000/2030]  eta: 0:00:03  lr: 0.000081  loss: 0.5809  time: 0.1279  data: 0.0000  max mem: 9128
Train: data epoch: [3]  [2029/2030]  eta: 0:00:00  lr: 0.000081  loss: 0.5864  time: 0.1302  data: 0.0000  max mem: 9128
Train: data epoch: [3] Total time: 0:04:20 (0.1282 s / it)
2023-05-10 18:54:36,132 [INFO] Averaged stats: lr: 0.0001  loss: 0.6183
2023-05-10 18:54:36,133 [INFO] Start training
2023-05-10 18:54:36,150 [INFO] Start training epoch 4, 2030 iters per inner epoch.
Train: data epoch: [4]  [   0/2030]  eta: 1:22:12  lr: 0.000069  loss: 0.5544  time: 2.4296  data: 0.0000  max mem: 9128
Train: data epoch: [4]  [  50/2030]  eta: 0:05:39  lr: 0.000069  loss: 0.5617  time: 0.1266  data: 0.0000  max mem: 9128
Train: data epoch: [4]  [ 100/2030]  eta: 0:04:47  lr: 0.000069  loss: 0.5856  time: 0.1261  data: 0.0000  max mem: 9128
Train: data epoch: [4]  [ 150/2030]  eta: 0:04:26  lr: 0.000069  loss: 0.5285  time: 0.1263  data: 0.0000  max mem: 9128
Train: data epoch: [4]  [ 200/2030]  eta: 0:04:12  lr: 0.000069  loss: 0.5690  time: 0.1263  data: 0.0000  max mem: 9128
Train: data epoch: [4]  [ 250/2030]  eta: 0:04:01  lr: 0.000069  loss: 0.5672  time: 0.1266  data: 0.0000  max mem: 9128
Train: data epoch: [4]  [ 300/2030]  eta: 0:03:52  lr: 0.000069  loss: 0.5927  time: 0.1269  data: 0.0000  max mem: 9128
Train: data epoch: [4]  [ 350/2030]  eta: 0:03:43  lr: 0.000069  loss: 0.5856  time: 0.1278  data: 0.0000  max mem: 9128
Train: data epoch: [4]  [ 400/2030]  eta: 0:03:35  lr: 0.000069  loss: 0.5998  time: 0.1261  data: 0.0000  max mem: 9128
Train: data epoch: [4]  [ 450/2030]  eta: 0:03:28  lr: 0.000069  loss: 0.6495  time: 0.1269  data: 0.0000  max mem: 9128
Train: data epoch: [4]  [ 500/2030]  eta: 0:03:20  lr: 0.000069  loss: 0.5387  time: 0.1263  data: 0.0000  max mem: 9128
Train: data epoch: [4]  [ 550/2030]  eta: 0:03:13  lr: 0.000069  loss: 0.6939  time: 0.1271  data: 0.0000  max mem: 9128
Train: data epoch: [4]  [ 600/2030]  eta: 0:03:06  lr: 0.000069  loss: 0.6792  time: 0.1275  data: 0.0000  max mem: 9128
Train: data epoch: [4]  [ 650/2030]  eta: 0:03:00  lr: 0.000069  loss: 0.6017  time: 0.1267  data: 0.0000  max mem: 9128
Train: data epoch: [4]  [ 700/2030]  eta: 0:02:53  lr: 0.000069  loss: 0.5730  time: 0.1266  data: 0.0000  max mem: 9128
Train: data epoch: [4]  [ 750/2030]  eta: 0:02:46  lr: 0.000069  loss: 0.6492  time: 0.1272  data: 0.0000  max mem: 9128
Train: data epoch: [4]  [ 800/2030]  eta: 0:02:39  lr: 0.000069  loss: 0.6183  time: 0.1272  data: 0.0000  max mem: 9128
Train: data epoch: [4]  [ 850/2030]  eta: 0:02:32  lr: 0.000069  loss: 0.6226  time: 0.1261  data: 0.0000  max mem: 9128
Train: data epoch: [4]  [ 900/2030]  eta: 0:02:26  lr: 0.000069  loss: 0.6246  time: 0.1265  data: 0.0000  max mem: 9128
Train: data epoch: [4]  [ 950/2030]  eta: 0:02:19  lr: 0.000069  loss: 0.5868  time: 0.1268  data: 0.0000  max mem: 9128
Train: data epoch: [4]  [1000/2030]  eta: 0:02:13  lr: 0.000069  loss: 0.6702  time: 0.1266  data: 0.0000  max mem: 9128
Train: data epoch: [4]  [1050/2030]  eta: 0:02:06  lr: 0.000069  loss: 0.5977  time: 0.1262  data: 0.0000  max mem: 9128
Train: data epoch: [4]  [1100/2030]  eta: 0:01:59  lr: 0.000069  loss: 0.5364  time: 0.1267  data: 0.0000  max mem: 9128
Train: data epoch: [4]  [1150/2030]  eta: 0:01:53  lr: 0.000069  loss: 0.6625  time: 0.1269  data: 0.0000  max mem: 9128
Train: data epoch: [4]  [1200/2030]  eta: 0:01:46  lr: 0.000069  loss: 0.6720  time: 0.1264  data: 0.0000  max mem: 9128
Train: data epoch: [4]  [1250/2030]  eta: 0:01:40  lr: 0.000069  loss: 0.6042  time: 0.1270  data: 0.0000  max mem: 9128
Train: data epoch: [4]  [1300/2030]  eta: 0:01:33  lr: 0.000069  loss: 0.5902  time: 0.1267  data: 0.0000  max mem: 9128
Train: data epoch: [4]  [1350/2030]  eta: 0:01:27  lr: 0.000069  loss: 0.6530  time: 0.1269  data: 0.0000  max mem: 9128
Train: data epoch: [4]  [1400/2030]  eta: 0:01:20  lr: 0.000069  loss: 0.5550  time: 0.1271  data: 0.0000  max mem: 9128
Train: data epoch: [4]  [1450/2030]  eta: 0:01:14  lr: 0.000069  loss: 0.6170  time: 0.1273  data: 0.0000  max mem: 9128
Train: data epoch: [4]  [1500/2030]  eta: 0:01:08  lr: 0.000069  loss: 0.5681  time: 0.1276  data: 0.0000  max mem: 9128
Train: data epoch: [4]  [1550/2030]  eta: 0:01:01  lr: 0.000069  loss: 0.6569  time: 0.1272  data: 0.0000  max mem: 9128
Train: data epoch: [4]  [1600/2030]  eta: 0:00:55  lr: 0.000069  loss: 0.6687  time: 0.1271  data: 0.0000  max mem: 9128
Train: data epoch: [4]  [1650/2030]  eta: 0:00:48  lr: 0.000069  loss: 0.6715  time: 0.1274  data: 0.0000  max mem: 9128
Train: data epoch: [4]  [1700/2030]  eta: 0:00:42  lr: 0.000069  loss: 0.5821  time: 0.1273  data: 0.0000  max mem: 9128
Train: data epoch: [4]  [1750/2030]  eta: 0:00:35  lr: 0.000069  loss: 0.6494  time: 0.1271  data: 0.0000  max mem: 9128
Train: data epoch: [4]  [1800/2030]  eta: 0:00:29  lr: 0.000069  loss: 0.6068  time: 0.1280  data: 0.0000  max mem: 9128
Train: data epoch: [4]  [1850/2030]  eta: 0:00:23  lr: 0.000069  loss: 0.5906  time: 0.1271  data: 0.0000  max mem: 9128
Train: data epoch: [4]  [1900/2030]  eta: 0:00:16  lr: 0.000069  loss: 0.6072  time: 0.1275  data: 0.0000  max mem: 9128
Train: data epoch: [4]  [1950/2030]  eta: 0:00:10  lr: 0.000069  loss: 0.6289  time: 0.1265  data: 0.0000  max mem: 9128
Train: data epoch: [4]  [2000/2030]  eta: 0:00:03  lr: 0.000069  loss: 0.6973  time: 0.1275  data: 0.0000  max mem: 9128
Train: data epoch: [4]  [2029/2030]  eta: 0:00:00  lr: 0.000069  loss: 0.5924  time: 0.1303  data: 0.0000  max mem: 9128
Train: data epoch: [4] Total time: 0:04:20 (0.1282 s / it)
2023-05-10 18:58:56,452 [INFO] Averaged stats: lr: 0.0001  loss: 0.6099
2023-05-10 18:58:56,453 [INFO] Start training
2023-05-10 18:58:56,471 [INFO] Start training epoch 5, 2030 iters per inner epoch.
Train: data epoch: [5]  [   0/2030]  eta: 1:22:49  lr: 0.000055  loss: 0.6096  time: 2.4481  data: 0.0000  max mem: 9128
Train: data epoch: [5]  [  50/2030]  eta: 0:05:40  lr: 0.000055  loss: 0.5688  time: 0.1265  data: 0.0000  max mem: 9128
Train: data epoch: [5]  [ 100/2030]  eta: 0:04:48  lr: 0.000055  loss: 0.6045  time: 0.1269  data: 0.0000  max mem: 9128
Train: data epoch: [5]  [ 150/2030]  eta: 0:04:26  lr: 0.000055  loss: 0.5785  time: 0.1268  data: 0.0000  max mem: 9128
Train: data epoch: [5]  [ 200/2030]  eta: 0:04:12  lr: 0.000055  loss: 0.5868  time: 0.1268  data: 0.0000  max mem: 9128
Train: data epoch: [5]  [ 250/2030]  eta: 0:04:01  lr: 0.000055  loss: 0.5343  time: 0.1265  data: 0.0000  max mem: 9128
Train: data epoch: [5]  [ 300/2030]  eta: 0:03:52  lr: 0.000055  loss: 0.6726  time: 0.1267  data: 0.0000  max mem: 9128
Train: data epoch: [5]  [ 350/2030]  eta: 0:03:44  lr: 0.000055  loss: 0.5980  time: 0.1266  data: 0.0000  max mem: 9128
Train: data epoch: [5]  [ 400/2030]  eta: 0:03:36  lr: 0.000055  loss: 0.5685  time: 0.1263  data: 0.0000  max mem: 9128
Train: data epoch: [5]  [ 450/2030]  eta: 0:03:28  lr: 0.000055  loss: 0.5595  time: 0.1276  data: 0.0000  max mem: 9128
Train: data epoch: [5]  [ 500/2030]  eta: 0:03:21  lr: 0.000055  loss: 0.6021  time: 0.1273  data: 0.0000  max mem: 9128
Train: data epoch: [5]  [ 550/2030]  eta: 0:03:14  lr: 0.000055  loss: 0.5495  time: 0.1268  data: 0.0000  max mem: 9128
Train: data epoch: [5]  [ 600/2030]  eta: 0:03:06  lr: 0.000055  loss: 0.6416  time: 0.1263  data: 0.0000  max mem: 9128
Train: data epoch: [5]  [ 650/2030]  eta: 0:03:00  lr: 0.000055  loss: 0.6027  time: 0.1268  data: 0.0000  max mem: 9128
Train: data epoch: [5]  [ 700/2030]  eta: 0:02:53  lr: 0.000055  loss: 0.6279  time: 0.1266  data: 0.0000  max mem: 9128
Train: data epoch: [5]  [ 750/2030]  eta: 0:02:46  lr: 0.000055  loss: 0.5801  time: 0.1262  data: 0.0000  max mem: 9128
Train: data epoch: [5]  [ 800/2030]  eta: 0:02:39  lr: 0.000055  loss: 0.6505  time: 0.1270  data: 0.0000  max mem: 9128
Train: data epoch: [5]  [ 850/2030]  eta: 0:02:32  lr: 0.000055  loss: 0.6570  time: 0.1272  data: 0.0000  max mem: 9128
Train: data epoch: [5]  [ 900/2030]  eta: 0:02:26  lr: 0.000055  loss: 0.6348  time: 0.1269  data: 0.0000  max mem: 9128
Train: data epoch: [5]  [ 950/2030]  eta: 0:02:19  lr: 0.000055  loss: 0.6356  time: 0.1271  data: 0.0000  max mem: 9128
Train: data epoch: [5]  [1000/2030]  eta: 0:02:13  lr: 0.000055  loss: 0.6212  time: 0.1268  data: 0.0000  max mem: 9128
Train: data epoch: [5]  [1050/2030]  eta: 0:02:06  lr: 0.000055  loss: 0.6268  time: 0.1264  data: 0.0000  max mem: 9128
Train: data epoch: [5]  [1100/2030]  eta: 0:01:59  lr: 0.000055  loss: 0.6167  time: 0.1272  data: 0.0000  max mem: 9128
Train: data epoch: [5]  [1150/2030]  eta: 0:01:53  lr: 0.000055  loss: 0.5561  time: 0.1278  data: 0.0000  max mem: 9128
Train: data epoch: [5]  [1200/2030]  eta: 0:01:46  lr: 0.000055  loss: 0.6009  time: 0.1267  data: 0.0000  max mem: 9128
Train: data epoch: [5]  [1250/2030]  eta: 0:01:40  lr: 0.000055  loss: 0.6252  time: 0.1270  data: 0.0000  max mem: 9128
Train: data epoch: [5]  [1300/2030]  eta: 0:01:34  lr: 0.000055  loss: 0.5652  time: 0.1267  data: 0.0000  max mem: 9128
Train: data epoch: [5]  [1350/2030]  eta: 0:01:27  lr: 0.000055  loss: 0.5709  time: 0.1270  data: 0.0000  max mem: 9128
Train: data epoch: [5]  [1400/2030]  eta: 0:01:21  lr: 0.000055  loss: 0.5441  time: 0.1265  data: 0.0000  max mem: 9128
Train: data epoch: [5]  [1450/2030]  eta: 0:01:14  lr: 0.000055  loss: 0.6003  time: 0.1272  data: 0.0000  max mem: 9128
Train: data epoch: [5]  [1500/2030]  eta: 0:01:08  lr: 0.000055  loss: 0.6562  time: 0.1264  data: 0.0000  max mem: 9128
Train: data epoch: [5]  [1550/2030]  eta: 0:01:01  lr: 0.000055  loss: 0.5656  time: 0.1264  data: 0.0000  max mem: 9128
Train: data epoch: [5]  [1600/2030]  eta: 0:00:55  lr: 0.000055  loss: 0.5914  time: 0.1275  data: 0.0000  max mem: 9128
Train: data epoch: [5]  [1650/2030]  eta: 0:00:48  lr: 0.000055  loss: 0.5885  time: 0.1261  data: 0.0000  max mem: 9128
Train: data epoch: [5]  [1700/2030]  eta: 0:00:42  lr: 0.000055  loss: 0.6195  time: 0.1269  data: 0.0000  max mem: 9128
Train: data epoch: [5]  [1750/2030]  eta: 0:00:35  lr: 0.000055  loss: 0.6231  time: 0.1263  data: 0.0000  max mem: 9128
Train: data epoch: [5]  [1800/2030]  eta: 0:00:29  lr: 0.000055  loss: 0.6089  time: 0.1269  data: 0.0000  max mem: 9128
Train: data epoch: [5]  [1850/2030]  eta: 0:00:23  lr: 0.000055  loss: 0.6594  time: 0.1267  data: 0.0000  max mem: 9128
Train: data epoch: [5]  [1900/2030]  eta: 0:00:16  lr: 0.000055  loss: 0.6877  time: 0.1273  data: 0.0000  max mem: 9128
Train: data epoch: [5]  [1950/2030]  eta: 0:00:10  lr: 0.000055  loss: 0.6091  time: 0.1272  data: 0.0000  max mem: 9128
Train: data epoch: [5]  [2000/2030]  eta: 0:00:03  lr: 0.000055  loss: 0.5724  time: 0.1264  data: 0.0000  max mem: 9128
Train: data epoch: [5]  [2029/2030]  eta: 0:00:00  lr: 0.000055  loss: 0.6725  time: 0.1309  data: 0.0000  max mem: 9128
Train: data epoch: [5] Total time: 0:04:20 (0.1281 s / it)
2023-05-10 19:03:16,526 [INFO] Averaged stats: lr: 0.0001  loss: 0.6040
2023-05-10 19:03:16,527 [INFO] Start training
2023-05-10 19:03:16,544 [INFO] Start training epoch 6, 2030 iters per inner epoch.
Train: data epoch: [6]  [   0/2030]  eta: 1:21:55  lr: 0.000041  loss: 0.5507  time: 2.4215  data: 0.0000  max mem: 9128
Train: data epoch: [6]  [  50/2030]  eta: 0:05:39  lr: 0.000041  loss: 0.6067  time: 0.1268  data: 0.0000  max mem: 9128
Train: data epoch: [6]  [ 100/2030]  eta: 0:04:50  lr: 0.000041  loss: 0.5866  time: 0.1316  data: 0.0000  max mem: 9128
Train: data epoch: [6]  [ 150/2030]  eta: 0:04:28  lr: 0.000041  loss: 0.5661  time: 0.1270  data: 0.0000  max mem: 9128
Train: data epoch: [6]  [ 200/2030]  eta: 0:04:13  lr: 0.000041  loss: 0.6157  time: 0.1267  data: 0.0000  max mem: 9128
Train: data epoch: [6]  [ 250/2030]  eta: 0:04:02  lr: 0.000041  loss: 0.6014  time: 0.1264  data: 0.0000  max mem: 9128
Train: data epoch: [6]  [ 300/2030]  eta: 0:03:52  lr: 0.000041  loss: 0.6096  time: 0.1261  data: 0.0000  max mem: 9128
Train: data epoch: [6]  [ 350/2030]  eta: 0:03:44  lr: 0.000041  loss: 0.6165  time: 0.1265  data: 0.0000  max mem: 9128
Train: data epoch: [6]  [ 400/2030]  eta: 0:03:36  lr: 0.000041  loss: 0.5215  time: 0.1266  data: 0.0000  max mem: 9128
Train: data epoch: [6]  [ 450/2030]  eta: 0:03:28  lr: 0.000041  loss: 0.5688  time: 0.1270  data: 0.0000  max mem: 9128
Train: data epoch: [6]  [ 500/2030]  eta: 0:03:21  lr: 0.000041  loss: 0.5630  time: 0.1269  data: 0.0000  max mem: 9128
Train: data epoch: [6]  [ 550/2030]  eta: 0:03:14  lr: 0.000041  loss: 0.5918  time: 0.1268  data: 0.0000  max mem: 9128
Train: data epoch: [6]  [ 600/2030]  eta: 0:03:07  lr: 0.000041  loss: 0.6535  time: 0.1273  data: 0.0000  max mem: 9128
Train: data epoch: [6]  [ 650/2030]  eta: 0:03:00  lr: 0.000041  loss: 0.6007  time: 0.1267  data: 0.0000  max mem: 9128
Train: data epoch: [6]  [ 700/2030]  eta: 0:02:53  lr: 0.000041  loss: 0.6310  time: 0.1267  data: 0.0000  max mem: 9128
Train: data epoch: [6]  [ 750/2030]  eta: 0:02:46  lr: 0.000041  loss: 0.6131  time: 0.1277  data: 0.0000  max mem: 9128
Train: data epoch: [6]  [ 800/2030]  eta: 0:02:39  lr: 0.000041  loss: 0.5922  time: 0.1269  data: 0.0000  max mem: 9128
Train: data epoch: [6]  [ 850/2030]  eta: 0:02:33  lr: 0.000041  loss: 0.6132  time: 0.1270  data: 0.0000  max mem: 9128
Train: data epoch: [6]  [ 900/2030]  eta: 0:02:26  lr: 0.000041  loss: 0.5801  time: 0.1271  data: 0.0000  max mem: 9128
Train: data epoch: [6]  [ 950/2030]  eta: 0:02:19  lr: 0.000041  loss: 0.6053  time: 0.1270  data: 0.0000  max mem: 9128
Train: data epoch: [6]  [1000/2030]  eta: 0:02:13  lr: 0.000041  loss: 0.6653  time: 0.1305  data: 0.0000  max mem: 9128
Train: data epoch: [6]  [1050/2030]  eta: 0:02:06  lr: 0.000041  loss: 0.6032  time: 0.1275  data: 0.0000  max mem: 9128
Train: data epoch: [6]  [1100/2030]  eta: 0:02:00  lr: 0.000041  loss: 0.5681  time: 0.1265  data: 0.0000  max mem: 9128
Train: data epoch: [6]  [1150/2030]  eta: 0:01:53  lr: 0.000041  loss: 0.5899  time: 0.1268  data: 0.0000  max mem: 9128
Train: data epoch: [6]  [1200/2030]  eta: 0:01:47  lr: 0.000041  loss: 0.6148  time: 0.1269  data: 0.0000  max mem: 9128
Train: data epoch: [6]  [1250/2030]  eta: 0:01:40  lr: 0.000041  loss: 0.5941  time: 0.1261  data: 0.0000  max mem: 9128
Train: data epoch: [6]  [1300/2030]  eta: 0:01:33  lr: 0.000041  loss: 0.5781  time: 0.1260  data: 0.0000  max mem: 9128
Train: data epoch: [6]  [1350/2030]  eta: 0:01:27  lr: 0.000041  loss: 0.5673  time: 0.1270  data: 0.0000  max mem: 9128
Train: data epoch: [6]  [1400/2030]  eta: 0:01:21  lr: 0.000041  loss: 0.6180  time: 0.1262  data: 0.0000  max mem: 9128
Train: data epoch: [6]  [1450/2030]  eta: 0:01:14  lr: 0.000041  loss: 0.5782  time: 0.1274  data: 0.0000  max mem: 9128
Train: data epoch: [6]  [1500/2030]  eta: 0:01:08  lr: 0.000041  loss: 0.5980  time: 0.1261  data: 0.0000  max mem: 9128
Train: data epoch: [6]  [1550/2030]  eta: 0:01:01  lr: 0.000041  loss: 0.5163  time: 0.1270  data: 0.0000  max mem: 9128
Train: data epoch: [6]  [1600/2030]  eta: 0:00:55  lr: 0.000041  loss: 0.5951  time: 0.1269  data: 0.0000  max mem: 9128
Train: data epoch: [6]  [1650/2030]  eta: 0:00:48  lr: 0.000041  loss: 0.5965  time: 0.1270  data: 0.0000  max mem: 9128
Train: data epoch: [6]  [1700/2030]  eta: 0:00:42  lr: 0.000041  loss: 0.6125  time: 0.1276  data: 0.0000  max mem: 9128
Train: data epoch: [6]  [1750/2030]  eta: 0:00:35  lr: 0.000041  loss: 0.5882  time: 0.1279  data: 0.0000  max mem: 9128
Train: data epoch: [6]  [1800/2030]  eta: 0:00:29  lr: 0.000041  loss: 0.5930  time: 0.1274  data: 0.0000  max mem: 9128
Train: data epoch: [6]  [1850/2030]  eta: 0:00:23  lr: 0.000041  loss: 0.5722  time: 0.1272  data: 0.0000  max mem: 9128
Train: data epoch: [6]  [1900/2030]  eta: 0:00:16  lr: 0.000041  loss: 0.6146  time: 0.1310  data: 0.0000  max mem: 9128
Train: data epoch: [6]  [1950/2030]  eta: 0:00:10  lr: 0.000041  loss: 0.6318  time: 0.1268  data: 0.0000  max mem: 9128
Train: data epoch: [6]  [2000/2030]  eta: 0:00:03  lr: 0.000041  loss: 0.6301  time: 0.1270  data: 0.0000  max mem: 9128
Train: data epoch: [6]  [2029/2030]  eta: 0:00:00  lr: 0.000041  loss: 0.5997  time: 0.1301  data: 0.0000  max mem: 9128
Train: data epoch: [6] Total time: 0:04:20 (0.1282 s / it)
2023-05-10 19:07:36,853 [INFO] Averaged stats: lr: 0.0000  loss: 0.5974
2023-05-10 19:07:36,854 [INFO] Start training
2023-05-10 19:07:36,871 [INFO] Start training epoch 7, 2030 iters per inner epoch.
Train: data epoch: [7]  [   0/2030]  eta: 1:22:24  lr: 0.000029  loss: 0.5200  time: 2.4356  data: 0.0000  max mem: 9128
Train: data epoch: [7]  [  50/2030]  eta: 0:05:40  lr: 0.000029  loss: 0.5788  time: 0.1265  data: 0.0000  max mem: 9128
Train: data epoch: [7]  [ 100/2030]  eta: 0:04:48  lr: 0.000029  loss: 0.5524  time: 0.1271  data: 0.0000  max mem: 9128
Train: data epoch: [7]  [ 150/2030]  eta: 0:04:26  lr: 0.000029  loss: 0.6376  time: 0.1264  data: 0.0000  max mem: 9128
Train: data epoch: [7]  [ 200/2030]  eta: 0:04:12  lr: 0.000029  loss: 0.5650  time: 0.1266  data: 0.0000  max mem: 9128
Train: data epoch: [7]  [ 250/2030]  eta: 0:04:01  lr: 0.000029  loss: 0.6192  time: 0.1263  data: 0.0000  max mem: 9128
Train: data epoch: [7]  [ 300/2030]  eta: 0:03:52  lr: 0.000029  loss: 0.5937  time: 0.1265  data: 0.0000  max mem: 9128
Train: data epoch: [7]  [ 350/2030]  eta: 0:03:43  lr: 0.000029  loss: 0.5513  time: 0.1278  data: 0.0000  max mem: 9128
Train: data epoch: [7]  [ 400/2030]  eta: 0:03:35  lr: 0.000029  loss: 0.5683  time: 0.1261  data: 0.0000  max mem: 9128
Train: data epoch: [7]  [ 450/2030]  eta: 0:03:28  lr: 0.000029  loss: 0.5949  time: 0.1267  data: 0.0000  max mem: 9128
Train: data epoch: [7]  [ 500/2030]  eta: 0:03:20  lr: 0.000029  loss: 0.5089  time: 0.1273  data: 0.0000  max mem: 9128
Train: data epoch: [7]  [ 550/2030]  eta: 0:03:13  lr: 0.000029  loss: 0.6419  time: 0.1277  data: 0.0000  max mem: 9128
Train: data epoch: [7]  [ 600/2030]  eta: 0:03:06  lr: 0.000029  loss: 0.5741  time: 0.1269  data: 0.0000  max mem: 9128
Train: data epoch: [7]  [ 650/2030]  eta: 0:02:59  lr: 0.000029  loss: 0.5927  time: 0.1276  data: 0.0000  max mem: 9128
Train: data epoch: [7]  [ 700/2030]  eta: 0:02:53  lr: 0.000029  loss: 0.5915  time: 0.1274  data: 0.0000  max mem: 9128
Train: data epoch: [7]  [ 750/2030]  eta: 0:02:46  lr: 0.000029  loss: 0.6203  time: 0.1318  data: 0.0000  max mem: 9128
Train: data epoch: [7]  [ 800/2030]  eta: 0:02:39  lr: 0.000029  loss: 0.5756  time: 0.1270  data: 0.0000  max mem: 9128
Train: data epoch: [7]  [ 850/2030]  eta: 0:02:32  lr: 0.000029  loss: 0.6134  time: 0.1267  data: 0.0000  max mem: 9128
Train: data epoch: [7]  [ 900/2030]  eta: 0:02:26  lr: 0.000029  loss: 0.5962  time: 0.1266  data: 0.0000  max mem: 9128
Train: data epoch: [7]  [ 950/2030]  eta: 0:02:19  lr: 0.000029  loss: 0.5558  time: 0.1266  data: 0.0000  max mem: 9128
Train: data epoch: [7]  [1000/2030]  eta: 0:02:13  lr: 0.000029  loss: 0.5990  time: 0.1285  data: 0.0000  max mem: 9128
Train: data epoch: [7]  [1050/2030]  eta: 0:02:06  lr: 0.000029  loss: 0.5343  time: 0.1268  data: 0.0000  max mem: 9128
Train: data epoch: [7]  [1100/2030]  eta: 0:02:00  lr: 0.000029  loss: 0.5943  time: 0.1266  data: 0.0000  max mem: 9128
Train: data epoch: [7]  [1150/2030]  eta: 0:01:53  lr: 0.000029  loss: 0.5985  time: 0.1265  data: 0.0000  max mem: 9128
Train: data epoch: [7]  [1200/2030]  eta: 0:01:46  lr: 0.000029  loss: 0.5547  time: 0.1265  data: 0.0000  max mem: 9128
Train: data epoch: [7]  [1250/2030]  eta: 0:01:40  lr: 0.000029  loss: 0.5523  time: 0.1265  data: 0.0000  max mem: 9128
Train: data epoch: [7]  [1300/2030]  eta: 0:01:33  lr: 0.000029  loss: 0.6016  time: 0.1265  data: 0.0000  max mem: 9128
Train: data epoch: [7]  [1350/2030]  eta: 0:01:27  lr: 0.000029  loss: 0.6046  time: 0.1271  data: 0.0000  max mem: 9128
Train: data epoch: [7]  [1400/2030]  eta: 0:01:20  lr: 0.000029  loss: 0.6147  time: 0.1268  data: 0.0000  max mem: 9128
Train: data epoch: [7]  [1450/2030]  eta: 0:01:14  lr: 0.000029  loss: 0.6197  time: 0.1268  data: 0.0000  max mem: 9128
Train: data epoch: [7]  [1500/2030]  eta: 0:01:08  lr: 0.000029  loss: 0.5791  time: 0.1276  data: 0.0000  max mem: 9128
Train: data epoch: [7]  [1550/2030]  eta: 0:01:01  lr: 0.000029  loss: 0.4673  time: 0.1269  data: 0.0000  max mem: 9128
Train: data epoch: [7]  [1600/2030]  eta: 0:00:55  lr: 0.000029  loss: 0.5809  time: 0.1269  data: 0.0000  max mem: 9128
Train: data epoch: [7]  [1650/2030]  eta: 0:00:48  lr: 0.000029  loss: 0.5825  time: 0.1308  data: 0.0000  max mem: 9128
Train: data epoch: [7]  [1700/2030]  eta: 0:00:42  lr: 0.000029  loss: 0.5932  time: 0.1265  data: 0.0000  max mem: 9128
Train: data epoch: [7]  [1750/2030]  eta: 0:00:35  lr: 0.000029  loss: 0.6048  time: 0.1269  data: 0.0000  max mem: 9128
Train: data epoch: [7]  [1800/2030]  eta: 0:00:29  lr: 0.000029  loss: 0.5832  time: 0.1271  data: 0.0000  max mem: 9128
Train: data epoch: [7]  [1850/2030]  eta: 0:00:23  lr: 0.000029  loss: 0.5741  time: 0.1269  data: 0.0000  max mem: 9128
Train: data epoch: [7]  [1900/2030]  eta: 0:00:16  lr: 0.000029  loss: 0.5819  time: 0.1280  data: 0.0000  max mem: 9128
Train: data epoch: [7]  [1950/2030]  eta: 0:00:10  lr: 0.000029  loss: 0.5430  time: 0.1288  data: 0.0000  max mem: 9128
Train: data epoch: [7]  [2000/2030]  eta: 0:00:03  lr: 0.000029  loss: 0.5418  time: 0.1266  data: 0.0000  max mem: 9128
Train: data epoch: [7]  [2029/2030]  eta: 0:00:00  lr: 0.000029  loss: 0.6134  time: 0.1303  data: 0.0000  max mem: 9128
Train: data epoch: [7] Total time: 0:04:20 (0.1282 s / it)
2023-05-10 19:11:57,058 [INFO] Averaged stats: lr: 0.0000  loss: 0.5904
2023-05-10 19:11:57,058 [INFO] Start training
2023-05-10 19:11:57,076 [INFO] Start training epoch 8, 2030 iters per inner epoch.
Train: data epoch: [8]  [   0/2030]  eta: 1:22:16  lr: 0.000019  loss: 0.5651  time: 2.4317  data: 0.0000  max mem: 9128
Train: data epoch: [8]  [  50/2030]  eta: 0:05:40  lr: 0.000019  loss: 0.6010  time: 0.1268  data: 0.0000  max mem: 9128
Train: data epoch: [8]  [ 100/2030]  eta: 0:04:49  lr: 0.000019  loss: 0.5519  time: 0.1279  data: 0.0000  max mem: 9128
Train: data epoch: [8]  [ 150/2030]  eta: 0:04:27  lr: 0.000019  loss: 0.5854  time: 0.1273  data: 0.0000  max mem: 9128
Train: data epoch: [8]  [ 200/2030]  eta: 0:04:13  lr: 0.000019  loss: 0.5399  time: 0.1275  data: 0.0000  max mem: 9128
Train: data epoch: [8]  [ 250/2030]  eta: 0:04:02  lr: 0.000019  loss: 0.5530  time: 0.1272  data: 0.0000  max mem: 9128
Train: data epoch: [8]  [ 300/2030]  eta: 0:03:53  lr: 0.000019  loss: 0.5802  time: 0.1274  data: 0.0000  max mem: 9128
Train: data epoch: [8]  [ 350/2030]  eta: 0:03:44  lr: 0.000019  loss: 0.6173  time: 0.1276  data: 0.0000  max mem: 9128
Train: data epoch: [8]  [ 400/2030]  eta: 0:03:36  lr: 0.000019  loss: 0.5449  time: 0.1262  data: 0.0000  max mem: 9128
Train: data epoch: [8]  [ 450/2030]  eta: 0:03:28  lr: 0.000019  loss: 0.5350  time: 0.1265  data: 0.0000  max mem: 9128
Train: data epoch: [8]  [ 500/2030]  eta: 0:03:21  lr: 0.000019  loss: 0.6036  time: 0.1269  data: 0.0000  max mem: 9128
Train: data epoch: [8]  [ 550/2030]  eta: 0:03:14  lr: 0.000019  loss: 0.6131  time: 0.1271  data: 0.0000  max mem: 9128
Train: data epoch: [8]  [ 600/2030]  eta: 0:03:07  lr: 0.000019  loss: 0.6683  time: 0.1279  data: 0.0000  max mem: 9128
Train: data epoch: [8]  [ 650/2030]  eta: 0:03:00  lr: 0.000019  loss: 0.6347  time: 0.1276  data: 0.0000  max mem: 9128
Train: data epoch: [8]  [ 700/2030]  eta: 0:02:53  lr: 0.000019  loss: 0.5367  time: 0.1275  data: 0.0000  max mem: 9128
Train: data epoch: [8]  [ 750/2030]  eta: 0:02:46  lr: 0.000019  loss: 0.5954  time: 0.1266  data: 0.0000  max mem: 9128
Train: data epoch: [8]  [ 800/2030]  eta: 0:02:40  lr: 0.000019  loss: 0.6391  time: 0.1279  data: 0.0000  max mem: 9128
Train: data epoch: [8]  [ 850/2030]  eta: 0:02:33  lr: 0.000019  loss: 0.5769  time: 0.1263  data: 0.0000  max mem: 9128
Train: data epoch: [8]  [ 900/2030]  eta: 0:02:26  lr: 0.000019  loss: 0.5903  time: 0.1267  data: 0.0000  max mem: 9128
Train: data epoch: [8]  [ 950/2030]  eta: 0:02:19  lr: 0.000019  loss: 0.5571  time: 0.1263  data: 0.0000  max mem: 9128
Train: data epoch: [8]  [1000/2030]  eta: 0:02:13  lr: 0.000019  loss: 0.5667  time: 0.1263  data: 0.0000  max mem: 9128
Train: data epoch: [8]  [1050/2030]  eta: 0:02:06  lr: 0.000019  loss: 0.5643  time: 0.1277  data: 0.0000  max mem: 9128
Train: data epoch: [8]  [1100/2030]  eta: 0:02:00  lr: 0.000019  loss: 0.6187  time: 0.1271  data: 0.0000  max mem: 9128
Train: data epoch: [8]  [1150/2030]  eta: 0:01:53  lr: 0.000019  loss: 0.5617  time: 0.1268  data: 0.0000  max mem: 9128
Train: data epoch: [8]  [1200/2030]  eta: 0:01:47  lr: 0.000019  loss: 0.6070  time: 0.1278  data: 0.0000  max mem: 9128
Train: data epoch: [8]  [1250/2030]  eta: 0:01:40  lr: 0.000019  loss: 0.5973  time: 0.1271  data: 0.0000  max mem: 9128
Train: data epoch: [8]  [1300/2030]  eta: 0:01:34  lr: 0.000019  loss: 0.5459  time: 0.1265  data: 0.0000  max mem: 9128
Train: data epoch: [8]  [1350/2030]  eta: 0:01:27  lr: 0.000019  loss: 0.6285  time: 0.1266  data: 0.0000  max mem: 9128
Train: data epoch: [8]  [1400/2030]  eta: 0:01:21  lr: 0.000019  loss: 0.6205  time: 0.1270  data: 0.0000  max mem: 9128
Train: data epoch: [8]  [1450/2030]  eta: 0:01:14  lr: 0.000019  loss: 0.6334  time: 0.1271  data: 0.0000  max mem: 9128
Train: data epoch: [8]  [1500/2030]  eta: 0:01:08  lr: 0.000019  loss: 0.5901  time: 0.1277  data: 0.0000  max mem: 9128
Train: data epoch: [8]  [1550/2030]  eta: 0:01:01  lr: 0.000019  loss: 0.5336  time: 0.1279  data: 0.0000  max mem: 9128
Train: data epoch: [8]  [1600/2030]  eta: 0:00:55  lr: 0.000019  loss: 0.5599  time: 0.1283  data: 0.0000  max mem: 9128
Train: data epoch: [8]  [1650/2030]  eta: 0:00:48  lr: 0.000019  loss: 0.5308  time: 0.1272  data: 0.0000  max mem: 9128
Train: data epoch: [8]  [1700/2030]  eta: 0:00:42  lr: 0.000019  loss: 0.6695  time: 0.1272  data: 0.0000  max mem: 9128
Train: data epoch: [8]  [1750/2030]  eta: 0:00:35  lr: 0.000019  loss: 0.5989  time: 0.1277  data: 0.0000  max mem: 9128
Train: data epoch: [8]  [1800/2030]  eta: 0:00:29  lr: 0.000019  loss: 0.6167  time: 0.1271  data: 0.0000  max mem: 9128
Train: data epoch: [8]  [1850/2030]  eta: 0:00:23  lr: 0.000019  loss: 0.5136  time: 0.1274  data: 0.0000  max mem: 9128
Train: data epoch: [8]  [1900/2030]  eta: 0:00:16  lr: 0.000019  loss: 0.5874  time: 0.1275  data: 0.0000  max mem: 9128
Train: data epoch: [8]  [1950/2030]  eta: 0:00:10  lr: 0.000019  loss: 0.5420  time: 0.1275  data: 0.0000  max mem: 9128
Train: data epoch: [8]  [2000/2030]  eta: 0:00:03  lr: 0.000019  loss: 0.5249  time: 0.1273  data: 0.0000  max mem: 9128
Train: data epoch: [8]  [2029/2030]  eta: 0:00:00  lr: 0.000019  loss: 0.5676  time: 0.1306  data: 0.0000  max mem: 9128
Train: data epoch: [8] Total time: 0:04:20 (0.1285 s / it)
2023-05-10 19:16:17,845 [INFO] Averaged stats: lr: 0.0000  loss: 0.5847
2023-05-10 19:16:17,846 [INFO] Start training
2023-05-10 19:16:17,864 [INFO] Start training epoch 9, 2030 iters per inner epoch.
Train: data epoch: [9]  [   0/2030]  eta: 1:21:40  lr: 0.000012  loss: 0.5935  time: 2.4142  data: 0.0000  max mem: 9128
Train: data epoch: [9]  [  50/2030]  eta: 0:05:40  lr: 0.000012  loss: 0.5507  time: 0.1267  data: 0.0000  max mem: 9128
Train: data epoch: [9]  [ 100/2030]  eta: 0:04:48  lr: 0.000012  loss: 0.6023  time: 0.1261  data: 0.0000  max mem: 9128
Train: data epoch: [9]  [ 150/2030]  eta: 0:04:26  lr: 0.000012  loss: 0.5554  time: 0.1260  data: 0.0000  max mem: 9128
Train: data epoch: [9]  [ 200/2030]  eta: 0:04:12  lr: 0.000012  loss: 0.5673  time: 0.1268  data: 0.0000  max mem: 9128
Train: data epoch: [9]  [ 250/2030]  eta: 0:04:01  lr: 0.000012  loss: 0.6010  time: 0.1287  data: 0.0000  max mem: 9128
Train: data epoch: [9]  [ 300/2030]  eta: 0:03:53  lr: 0.000012  loss: 0.6487  time: 0.1266  data: 0.0000  max mem: 9128
Train: data epoch: [9]  [ 350/2030]  eta: 0:03:44  lr: 0.000012  loss: 0.6332  time: 0.1267  data: 0.0000  max mem: 9128
Train: data epoch: [9]  [ 400/2030]  eta: 0:03:36  lr: 0.000012  loss: 0.5387  time: 0.1279  data: 0.0000  max mem: 9128
Train: data epoch: [9]  [ 450/2030]  eta: 0:03:28  lr: 0.000012  loss: 0.5195  time: 0.1265  data: 0.0000  max mem: 9128
Train: data epoch: [9]  [ 500/2030]  eta: 0:03:21  lr: 0.000012  loss: 0.5882  time: 0.1277  data: 0.0000  max mem: 9128
Train: data epoch: [9]  [ 550/2030]  eta: 0:03:14  lr: 0.000012  loss: 0.5142  time: 0.1273  data: 0.0000  max mem: 9128
Train: data epoch: [9]  [ 600/2030]  eta: 0:03:07  lr: 0.000012  loss: 0.6109  time: 0.1271  data: 0.0000  max mem: 9128
Train: data epoch: [9]  [ 650/2030]  eta: 0:03:00  lr: 0.000012  loss: 0.5468  time: 0.1281  data: 0.0000  max mem: 9128
Train: data epoch: [9]  [ 700/2030]  eta: 0:02:53  lr: 0.000012  loss: 0.5568  time: 0.1261  data: 0.0000  max mem: 9128
Train: data epoch: [9]  [ 750/2030]  eta: 0:02:46  lr: 0.000012  loss: 0.5484  time: 0.1262  data: 0.0000  max mem: 9128
Train: data epoch: [9]  [ 800/2030]  eta: 0:02:39  lr: 0.000012  loss: 0.6208  time: 0.1275  data: 0.0000  max mem: 9128
Train: data epoch: [9]  [ 850/2030]  eta: 0:02:33  lr: 0.000012  loss: 0.5778  time: 0.1269  data: 0.0000  max mem: 9128
Train: data epoch: [9]  [ 900/2030]  eta: 0:02:26  lr: 0.000012  loss: 0.5296  time: 0.1271  data: 0.0000  max mem: 9128
Train: data epoch: [9]  [ 950/2030]  eta: 0:02:19  lr: 0.000012  loss: 0.6205  time: 0.1283  data: 0.0000  max mem: 9128
Train: data epoch: [9]  [1000/2030]  eta: 0:02:13  lr: 0.000012  loss: 0.5611  time: 0.1274  data: 0.0000  max mem: 9128
Train: data epoch: [9]  [1050/2030]  eta: 0:02:06  lr: 0.000012  loss: 0.6111  time: 0.1265  data: 0.0000  max mem: 9128
Train: data epoch: [9]  [1100/2030]  eta: 0:02:00  lr: 0.000012  loss: 0.5419  time: 0.1261  data: 0.0000  max mem: 9128
Train: data epoch: [9]  [1150/2030]  eta: 0:01:53  lr: 0.000012  loss: 0.6573  time: 0.1269  data: 0.0000  max mem: 9128
Train: data epoch: [9]  [1200/2030]  eta: 0:01:47  lr: 0.000012  loss: 0.5194  time: 0.1271  data: 0.0000  max mem: 9128
Train: data epoch: [9]  [1250/2030]  eta: 0:01:40  lr: 0.000012  loss: 0.5277  time: 0.1266  data: 0.0000  max mem: 9128
Train: data epoch: [9]  [1300/2030]  eta: 0:01:34  lr: 0.000012  loss: 0.5907  time: 0.1271  data: 0.0000  max mem: 9128
Train: data epoch: [9]  [1350/2030]  eta: 0:01:27  lr: 0.000012  loss: 0.6237  time: 0.1285  data: 0.0000  max mem: 9128
Train: data epoch: [9]  [1400/2030]  eta: 0:01:21  lr: 0.000012  loss: 0.5341  time: 0.1278  data: 0.0000  max mem: 9128
Train: data epoch: [9]  [1450/2030]  eta: 0:01:14  lr: 0.000012  loss: 0.5500  time: 0.1268  data: 0.0000  max mem: 9128
Train: data epoch: [9]  [1500/2030]  eta: 0:01:08  lr: 0.000012  loss: 0.5350  time: 0.1272  data: 0.0000  max mem: 9128
Train: data epoch: [9]  [1550/2030]  eta: 0:01:01  lr: 0.000012  loss: 0.6426  time: 0.1269  data: 0.0000  max mem: 9128
Train: data epoch: [9]  [1600/2030]  eta: 0:00:55  lr: 0.000012  loss: 0.5625  time: 0.1270  data: 0.0000  max mem: 9128
Train: data epoch: [9]  [1650/2030]  eta: 0:00:48  lr: 0.000012  loss: 0.6160  time: 0.1267  data: 0.0000  max mem: 9128
Train: data epoch: [9]  [1700/2030]  eta: 0:00:42  lr: 0.000012  loss: 0.5823  time: 0.1275  data: 0.0000  max mem: 9128
Train: data epoch: [9]  [1750/2030]  eta: 0:00:35  lr: 0.000012  loss: 0.5617  time: 0.1268  data: 0.0000  max mem: 9128
Train: data epoch: [9]  [1800/2030]  eta: 0:00:29  lr: 0.000012  loss: 0.6511  time: 0.1271  data: 0.0000  max mem: 9128
Train: data epoch: [9]  [1850/2030]  eta: 0:00:23  lr: 0.000012  loss: 0.5371  time: 0.1271  data: 0.0000  max mem: 9128
Train: data epoch: [9]  [1900/2030]  eta: 0:00:16  lr: 0.000012  loss: 0.5416  time: 0.1269  data: 0.0000  max mem: 9128
Train: data epoch: [9]  [1950/2030]  eta: 0:00:10  lr: 0.000012  loss: 0.5463  time: 0.1275  data: 0.0000  max mem: 9128
Train: data epoch: [9]  [2000/2030]  eta: 0:00:03  lr: 0.000012  loss: 0.5484  time: 0.1285  data: 0.0000  max mem: 9128
Train: data epoch: [9]  [2029/2030]  eta: 0:00:00  lr: 0.000012  loss: 0.5553  time: 0.1322  data: 0.0000  max mem: 9128
Train: data epoch: [9] Total time: 0:04:20 (0.1283 s / it)
2023-05-10 19:20:38,397 [INFO] Averaged stats: lr: 0.0000  loss: 0.5807
2023-05-10 19:20:38,413 [INFO] Saving checkpoint at epoch 9 to /home/yiren/VATEX/lavis/output/BLIP-T/Caption_vatex_stage1/20230510183/checkpoint_9.pth.
2023-05-10 19:20:39,508 [INFO] Evaluating on val.
Evaluation  [ 0/47]  eta: 0:16:56    time: 21.6337  data: 0.2680  max mem: 27624
Evaluation  [10/47]  eta: 0:12:42    time: 20.6054  data: 0.0253  max mem: 27624
Evaluation  [20/47]  eta: 0:09:16    time: 20.5471  data: 0.0010  max mem: 27624
Evaluation  [30/47]  eta: 0:05:48    time: 20.4737  data: 0.0010  max mem: 27624
Evaluation  [40/47]  eta: 0:02:23    time: 20.2908  data: 0.0010  max mem: 27624
Evaluation  [46/47]  eta: 0:00:20    time: 20.3505  data: 0.0051  max mem: 27989
Evaluation Total time: 0:16:01 (20.4590 s / it)
2023-05-10 19:36:41,100 [WARNING] rank 0 starts merging results.
result file saved to /home/yiren/VATEX/lavis/output/BLIP-T/Caption_vatex_stage1/20230510183/result/val_epoch9.json
2023-05-10 19:36:41,159 [INFO] Training time 0:59:24
(lavis) xxxx@xxxx:~/VATEX$ bash run_scripts/blip2/train/train_caption_vatex_stage2.sh
| distributed init (rank 0, world 1): env://
2023-05-11 01:27:22,437 [INFO]
=====  Running Parameters    =====
2023-05-11 01:27:22,438 [INFO] {
    "accum_grad_iters": 1,
    "amp": true,
    "batch_size_eval": 64,
    "batch_size_train": 128,
    "device": "cuda",
    "dist_backend": "nccl",
    "dist_url": "env://",
    "distributed": true,
    "evaluate": false,
    "gpu": 0,
    "init_lr": 0.0001,
    "lr_sched": "linear_warmup_cosine_lr",
    "max_epoch": 10,
    "max_len": 30,
    "min_len": 8,
    "min_lr": 1e-05,
    "num_beams": 5,
    "num_workers": 4,
    "output_dir": "output/BLIP-T/Caption_vatex_stage2",
    "rank": 0,
    "report_metric": false,
    "resume_ckpt_path": null,
    "seed": 42,
    "task": "captioning",
    "train_splits": [
        "train"
    ],
    "valid_splits": [
        "val"
    ],
    "warmup_lr": 1e-06,
    "warmup_steps": 1000,
    "weight_decay": 0.05,
    "world_size": 1
}
2023-05-11 01:27:22,438 [INFO]
======  Dataset Attributes  ======
2023-05-11 01:27:22,438 [INFO]
======== my_vatex_caption =======
2023-05-11 01:27:22,438 [INFO] {
    "build_info": {
        "annotations": {
            "train": {
                "storage": "vatex/annotations/cap_train.json",
                "url": "https://storage.googleapis.com/sfr-vision-language-research/LAVIS/datasets/vatex/cap_train.json"
            },
            "val": {
                "storage": "vatex/annotations/cap_val.json",
                "url": "https://storage.googleapis.com/sfr-vision-language-research/LAVIS/datasets/vatex/cap_val.json"
            }
        },
        "videos": {
            "storage": "vatex/images"
        }
    },
    "data_type": "videos",
    "text_processor": {
        "eval": {
            "name": "blip_caption"
        },
        "train": {
            "name": "blip_caption",
            "prompt": "a photo of "
        }
    }
}
2023-05-11 01:27:22,438 [INFO]
======  Model Attributes  ======
2023-05-11 01:27:22,439 [INFO] {
    "arch": "video_feature_opt_stage2",
    "drop_path_rate": 0,
    "finetuned": "https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP2/blip2_caption_opt2.7b.pth",
    "freeze_vit": true,
    "image_size": 364,
    "load_finetuned": false,
    "load_pretrained": true,
    "model_type": "caption_coco_opt2.7b",
    "num_query_token": 32,
    "opt_model": "facebook/opt-2.7b",
    "pretrained": "/home/yiren/VATEX/lavis/output/BLIP-T/Caption_vatex_stage1/20230510183/checkpoint_9.pth",
    "pretrained_stage0": "/home/yiren/LAVIS/lavis/output/BLIP-T/Pretrain_stage0/vq/40m-noisy/checkpoint_60000.pth",
    "prompt": "a photo of",
    "use_grad_checkpoint": false,
    "vit_precision": "fp32"
}
Using downloaded and verified file: /home/yiren/lavis_datasets/vatex/annotations/cap_train.json
Using downloaded and verified file: /home/yiren/lavis_datasets/vatex/annotations/cap_val.json
2023-05-11 01:27:22,439 [INFO] Building datasets...
2023-05-11 01:28:13,272 [INFO] Missing keys ['VL_adaptor.embeddings.word_embeddings.weight', 'VL_adaptor.embeddings.position_embeddings.weight', 'VL_adaptor.embeddings.token_type_embeddings.weight', 'VL_adaptor.embeddings.LayerNorm.weight', 'VL_adaptor.embeddings.LayerNorm.bias', 'opt_model.model.decoder.embed_tokens.weight', 'opt_model.model.decoder.embed_positions.weight', 'opt_model.model.decoder.final_layer_norm.weight', 'opt_model.model.decoder.final_layer_norm.bias', 'opt_model.model.decoder.layers.0.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.0.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.0.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.0.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.0.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.0.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.0.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.0.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.0.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.0.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.0.fc1.weight', 'opt_model.model.decoder.layers.0.fc1.bias', 'opt_model.model.decoder.layers.0.fc2.weight', 'opt_model.model.decoder.layers.0.fc2.bias', 'opt_model.model.decoder.layers.0.final_layer_norm.weight', 'opt_model.model.decoder.layers.0.final_layer_norm.bias', 'opt_model.model.decoder.layers.1.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.1.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.1.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.1.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.1.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.1.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.1.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.1.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.1.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.1.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.1.fc1.weight', 'opt_model.model.decoder.layers.1.fc1.bias', 'opt_model.model.decoder.layers.1.fc2.weight', 'opt_model.model.decoder.layers.1.fc2.bias', 'opt_model.model.decoder.layers.1.final_layer_norm.weight', 'opt_model.model.decoder.layers.1.final_layer_norm.bias', 'opt_model.model.decoder.layers.2.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.2.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.2.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.2.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.2.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.2.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.2.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.2.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.2.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.2.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.2.fc1.weight', 'opt_model.model.decoder.layers.2.fc1.bias', 'opt_model.model.decoder.layers.2.fc2.weight', 'opt_model.model.decoder.layers.2.fc2.bias', 'opt_model.model.decoder.layers.2.final_layer_norm.weight', 'opt_model.model.decoder.layers.2.final_layer_norm.bias', 'opt_model.model.decoder.layers.3.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.3.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.3.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.3.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.3.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.3.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.3.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.3.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.3.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.3.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.3.fc1.weight', 'opt_model.model.decoder.layers.3.fc1.bias', 'opt_model.model.decoder.layers.3.fc2.weight', 'opt_model.model.decoder.layers.3.fc2.bias', 'opt_model.model.decoder.layers.3.final_layer_norm.weight', 'opt_model.model.decoder.layers.3.final_layer_norm.bias', 'opt_model.model.decoder.layers.4.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.4.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.4.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.4.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.4.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.4.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.4.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.4.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.4.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.4.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.4.fc1.weight', 'opt_model.model.decoder.layers.4.fc1.bias', 'opt_model.model.decoder.layers.4.fc2.weight', 'opt_model.model.decoder.layers.4.fc2.bias', 'opt_model.model.decoder.layers.4.final_layer_norm.weight', 'opt_model.model.decoder.layers.4.final_layer_norm.bias', 'opt_model.model.decoder.layers.5.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.5.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.5.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.5.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.5.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.5.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.5.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.5.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.5.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.5.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.5.fc1.weight', 'opt_model.model.decoder.layers.5.fc1.bias', 'opt_model.model.decoder.layers.5.fc2.weight', 'opt_model.model.decoder.layers.5.fc2.bias', 'opt_model.model.decoder.layers.5.final_layer_norm.weight', 'opt_model.model.decoder.layers.5.final_layer_norm.bias', 'opt_model.model.decoder.layers.6.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.6.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.6.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.6.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.6.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.6.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.6.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.6.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.6.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.6.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.6.fc1.weight', 'opt_model.model.decoder.layers.6.fc1.bias', 'opt_model.model.decoder.layers.6.fc2.weight', 'opt_model.model.decoder.layers.6.fc2.bias', 'opt_model.model.decoder.layers.6.final_layer_norm.weight', 'opt_model.model.decoder.layers.6.final_layer_norm.bias', 'opt_model.model.decoder.layers.7.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.7.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.7.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.7.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.7.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.7.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.7.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.7.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.7.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.7.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.7.fc1.weight', 'opt_model.model.decoder.layers.7.fc1.bias', 'opt_model.model.decoder.layers.7.fc2.weight', 'opt_model.model.decoder.layers.7.fc2.bias', 'opt_model.model.decoder.layers.7.final_layer_norm.weight', 'opt_model.model.decoder.layers.7.final_layer_norm.bias', 'opt_model.model.decoder.layers.8.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.8.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.8.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.8.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.8.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.8.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.8.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.8.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.8.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.8.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.8.fc1.weight', 'opt_model.model.decoder.layers.8.fc1.bias', 'opt_model.model.decoder.layers.8.fc2.weight', 'opt_model.model.decoder.layers.8.fc2.bias', 'opt_model.model.decoder.layers.8.final_layer_norm.weight', 'opt_model.model.decoder.layers.8.final_layer_norm.bias', 'opt_model.model.decoder.layers.9.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.9.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.9.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.9.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.9.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.9.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.9.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.9.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.9.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.9.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.9.fc1.weight', 'opt_model.model.decoder.layers.9.fc1.bias', 'opt_model.model.decoder.layers.9.fc2.weight', 'opt_model.model.decoder.layers.9.fc2.bias', 'opt_model.model.decoder.layers.9.final_layer_norm.weight', 'opt_model.model.decoder.layers.9.final_layer_norm.bias', 'opt_model.model.decoder.layers.10.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.10.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.10.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.10.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.10.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.10.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.10.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.10.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.10.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.10.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.10.fc1.weight', 'opt_model.model.decoder.layers.10.fc1.bias', 'opt_model.model.decoder.layers.10.fc2.weight', 'opt_model.model.decoder.layers.10.fc2.bias', 'opt_model.model.decoder.layers.10.final_layer_norm.weight', 'opt_model.model.decoder.layers.10.final_layer_norm.bias', 'opt_model.model.decoder.layers.11.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.11.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.11.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.11.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.11.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.11.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.11.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.11.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.11.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.11.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.11.fc1.weight', 'opt_model.model.decoder.layers.11.fc1.bias', 'opt_model.model.decoder.layers.11.fc2.weight', 'opt_model.model.decoder.layers.11.fc2.bias', 'opt_model.model.decoder.layers.11.final_layer_norm.weight', 'opt_model.model.decoder.layers.11.final_layer_norm.bias', 'opt_model.model.decoder.layers.12.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.12.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.12.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.12.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.12.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.12.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.12.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.12.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.12.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.12.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.12.fc1.weight', 'opt_model.model.decoder.layers.12.fc1.bias', 'opt_model.model.decoder.layers.12.fc2.weight', 'opt_model.model.decoder.layers.12.fc2.bias', 'opt_model.model.decoder.layers.12.final_layer_norm.weight', 'opt_model.model.decoder.layers.12.final_layer_norm.bias', 'opt_model.model.decoder.layers.13.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.13.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.13.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.13.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.13.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.13.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.13.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.13.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.13.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.13.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.13.fc1.weight', 'opt_model.model.decoder.layers.13.fc1.bias', 'opt_model.model.decoder.layers.13.fc2.weight', 'opt_model.model.decoder.layers.13.fc2.bias', 'opt_model.model.decoder.layers.13.final_layer_norm.weight', 'opt_model.model.decoder.layers.13.final_layer_norm.bias', 'opt_model.model.decoder.layers.14.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.14.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.14.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.14.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.14.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.14.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.14.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.14.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.14.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.14.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.14.fc1.weight', 'opt_model.model.decoder.layers.14.fc1.bias', 'opt_model.model.decoder.layers.14.fc2.weight', 'opt_model.model.decoder.layers.14.fc2.bias', 'opt_model.model.decoder.layers.14.final_layer_norm.weight', 'opt_model.model.decoder.layers.14.final_layer_norm.bias', 'opt_model.model.decoder.layers.15.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.15.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.15.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.15.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.15.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.15.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.15.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.15.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.15.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.15.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.15.fc1.weight', 'opt_model.model.decoder.layers.15.fc1.bias', 'opt_model.model.decoder.layers.15.fc2.weight', 'opt_model.model.decoder.layers.15.fc2.bias', 'opt_model.model.decoder.layers.15.final_layer_norm.weight', 'opt_model.model.decoder.layers.15.final_layer_norm.bias', 'opt_model.model.decoder.layers.16.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.16.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.16.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.16.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.16.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.16.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.16.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.16.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.16.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.16.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.16.fc1.weight', 'opt_model.model.decoder.layers.16.fc1.bias', 'opt_model.model.decoder.layers.16.fc2.weight', 'opt_model.model.decoder.layers.16.fc2.bias', 'opt_model.model.decoder.layers.16.final_layer_norm.weight', 'opt_model.model.decoder.layers.16.final_layer_norm.bias', 'opt_model.model.decoder.layers.17.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.17.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.17.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.17.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.17.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.17.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.17.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.17.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.17.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.17.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.17.fc1.weight', 'opt_model.model.decoder.layers.17.fc1.bias', 'opt_model.model.decoder.layers.17.fc2.weight', 'opt_model.model.decoder.layers.17.fc2.bias', 'opt_model.model.decoder.layers.17.final_layer_norm.weight', 'opt_model.model.decoder.layers.17.final_layer_norm.bias', 'opt_model.model.decoder.layers.18.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.18.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.18.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.18.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.18.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.18.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.18.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.18.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.18.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.18.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.18.fc1.weight', 'opt_model.model.decoder.layers.18.fc1.bias', 'opt_model.model.decoder.layers.18.fc2.weight', 'opt_model.model.decoder.layers.18.fc2.bias', 'opt_model.model.decoder.layers.18.final_layer_norm.weight', 'opt_model.model.decoder.layers.18.final_layer_norm.bias', 'opt_model.model.decoder.layers.19.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.19.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.19.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.19.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.19.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.19.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.19.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.19.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.19.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.19.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.19.fc1.weight', 'opt_model.model.decoder.layers.19.fc1.bias', 'opt_model.model.decoder.layers.19.fc2.weight', 'opt_model.model.decoder.layers.19.fc2.bias', 'opt_model.model.decoder.layers.19.final_layer_norm.weight', 'opt_model.model.decoder.layers.19.final_layer_norm.bias', 'opt_model.model.decoder.layers.20.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.20.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.20.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.20.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.20.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.20.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.20.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.20.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.20.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.20.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.20.fc1.weight', 'opt_model.model.decoder.layers.20.fc1.bias', 'opt_model.model.decoder.layers.20.fc2.weight', 'opt_model.model.decoder.layers.20.fc2.bias', 'opt_model.model.decoder.layers.20.final_layer_norm.weight', 'opt_model.model.decoder.layers.20.final_layer_norm.bias', 'opt_model.model.decoder.layers.21.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.21.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.21.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.21.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.21.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.21.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.21.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.21.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.21.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.21.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.21.fc1.weight', 'opt_model.model.decoder.layers.21.fc1.bias', 'opt_model.model.decoder.layers.21.fc2.weight', 'opt_model.model.decoder.layers.21.fc2.bias', 'opt_model.model.decoder.layers.21.final_layer_norm.weight', 'opt_model.model.decoder.layers.21.final_layer_norm.bias', 'opt_model.model.decoder.layers.22.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.22.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.22.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.22.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.22.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.22.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.22.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.22.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.22.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.22.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.22.fc1.weight', 'opt_model.model.decoder.layers.22.fc1.bias', 'opt_model.model.decoder.layers.22.fc2.weight', 'opt_model.model.decoder.layers.22.fc2.bias', 'opt_model.model.decoder.layers.22.final_layer_norm.weight', 'opt_model.model.decoder.layers.22.final_layer_norm.bias', 'opt_model.model.decoder.layers.23.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.23.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.23.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.23.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.23.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.23.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.23.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.23.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.23.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.23.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.23.fc1.weight', 'opt_model.model.decoder.layers.23.fc1.bias', 'opt_model.model.decoder.layers.23.fc2.weight', 'opt_model.model.decoder.layers.23.fc2.bias', 'opt_model.model.decoder.layers.23.final_layer_norm.weight', 'opt_model.model.decoder.layers.23.final_layer_norm.bias', 'opt_model.model.decoder.layers.24.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.24.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.24.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.24.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.24.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.24.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.24.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.24.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.24.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.24.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.24.fc1.weight', 'opt_model.model.decoder.layers.24.fc1.bias', 'opt_model.model.decoder.layers.24.fc2.weight', 'opt_model.model.decoder.layers.24.fc2.bias', 'opt_model.model.decoder.layers.24.final_layer_norm.weight', 'opt_model.model.decoder.layers.24.final_layer_norm.bias', 'opt_model.model.decoder.layers.25.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.25.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.25.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.25.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.25.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.25.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.25.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.25.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.25.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.25.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.25.fc1.weight', 'opt_model.model.decoder.layers.25.fc1.bias', 'opt_model.model.decoder.layers.25.fc2.weight', 'opt_model.model.decoder.layers.25.fc2.bias', 'opt_model.model.decoder.layers.25.final_layer_norm.weight', 'opt_model.model.decoder.layers.25.final_layer_norm.bias', 'opt_model.model.decoder.layers.26.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.26.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.26.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.26.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.26.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.26.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.26.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.26.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.26.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.26.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.26.fc1.weight', 'opt_model.model.decoder.layers.26.fc1.bias', 'opt_model.model.decoder.layers.26.fc2.weight', 'opt_model.model.decoder.layers.26.fc2.bias', 'opt_model.model.decoder.layers.26.final_layer_norm.weight', 'opt_model.model.decoder.layers.26.final_layer_norm.bias', 'opt_model.model.decoder.layers.27.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.27.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.27.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.27.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.27.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.27.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.27.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.27.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.27.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.27.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.27.fc1.weight', 'opt_model.model.decoder.layers.27.fc1.bias', 'opt_model.model.decoder.layers.27.fc2.weight', 'opt_model.model.decoder.layers.27.fc2.bias', 'opt_model.model.decoder.layers.27.final_layer_norm.weight', 'opt_model.model.decoder.layers.27.final_layer_norm.bias', 'opt_model.model.decoder.layers.28.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.28.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.28.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.28.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.28.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.28.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.28.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.28.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.28.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.28.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.28.fc1.weight', 'opt_model.model.decoder.layers.28.fc1.bias', 'opt_model.model.decoder.layers.28.fc2.weight', 'opt_model.model.decoder.layers.28.fc2.bias', 'opt_model.model.decoder.layers.28.final_layer_norm.weight', 'opt_model.model.decoder.layers.28.final_layer_norm.bias', 'opt_model.model.decoder.layers.29.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.29.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.29.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.29.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.29.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.29.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.29.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.29.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.29.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.29.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.29.fc1.weight', 'opt_model.model.decoder.layers.29.fc1.bias', 'opt_model.model.decoder.layers.29.fc2.weight', 'opt_model.model.decoder.layers.29.fc2.bias', 'opt_model.model.decoder.layers.29.final_layer_norm.weight', 'opt_model.model.decoder.layers.29.final_layer_norm.bias', 'opt_model.model.decoder.layers.30.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.30.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.30.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.30.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.30.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.30.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.30.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.30.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.30.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.30.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.30.fc1.weight', 'opt_model.model.decoder.layers.30.fc1.bias', 'opt_model.model.decoder.layers.30.fc2.weight', 'opt_model.model.decoder.layers.30.fc2.bias', 'opt_model.model.decoder.layers.30.final_layer_norm.weight', 'opt_model.model.decoder.layers.30.final_layer_norm.bias', 'opt_model.model.decoder.layers.31.self_attn.k_proj.weight', 'opt_model.model.decoder.layers.31.self_attn.k_proj.bias', 'opt_model.model.decoder.layers.31.self_attn.v_proj.weight', 'opt_model.model.decoder.layers.31.self_attn.v_proj.bias', 'opt_model.model.decoder.layers.31.self_attn.q_proj.weight', 'opt_model.model.decoder.layers.31.self_attn.q_proj.bias', 'opt_model.model.decoder.layers.31.self_attn.out_proj.weight', 'opt_model.model.decoder.layers.31.self_attn.out_proj.bias', 'opt_model.model.decoder.layers.31.self_attn_layer_norm.weight', 'opt_model.model.decoder.layers.31.self_attn_layer_norm.bias', 'opt_model.model.decoder.layers.31.fc1.weight', 'opt_model.model.decoder.layers.31.fc1.bias', 'opt_model.model.decoder.layers.31.fc2.weight', 'opt_model.model.decoder.layers.31.fc2.bias', 'opt_model.model.decoder.layers.31.final_layer_norm.weight', 'opt_model.model.decoder.layers.31.final_layer_norm.bias', 'Darkformer.embeddings.word_embeddings.weight', 'Darkformer.embeddings.position_embeddings.weight', 'Darkformer.embeddings.token_type_embeddings.weight', 'Darkformer.embeddings.LayerNorm.weight', 'Darkformer.embeddings.LayerNorm.bias', 'Darkformer.encoder.layer.0.attention.self.query.weight', 'Darkformer.encoder.layer.0.attention.self.query.bias', 'Darkformer.encoder.layer.0.attention.self.key.weight', 'Darkformer.encoder.layer.0.attention.self.key.bias', 'Darkformer.encoder.layer.0.attention.self.value.weight', 'Darkformer.encoder.layer.0.attention.self.value.bias', 'Darkformer.encoder.layer.0.attention.output.dense.weight', 'Darkformer.encoder.layer.0.attention.output.dense.bias', 'Darkformer.encoder.layer.0.attention.output.LayerNorm.weight', 'Darkformer.encoder.layer.0.attention.output.LayerNorm.bias', 'Darkformer.encoder.layer.0.intermediate.dense.weight', 'Darkformer.encoder.layer.0.intermediate.dense.bias', 'Darkformer.encoder.layer.0.output.dense.weight', 'Darkformer.encoder.layer.0.output.dense.bias', 'Darkformer.encoder.layer.0.output.LayerNorm.weight', 'Darkformer.encoder.layer.0.output.LayerNorm.bias', 'Darkformer.encoder.layer.1.attention.self.query.weight', 'Darkformer.encoder.layer.1.attention.self.query.bias', 'Darkformer.encoder.layer.1.attention.self.key.weight', 'Darkformer.encoder.layer.1.attention.self.key.bias', 'Darkformer.encoder.layer.1.attention.self.value.weight', 'Darkformer.encoder.layer.1.attention.self.value.bias', 'Darkformer.encoder.layer.1.attention.output.dense.weight', 'Darkformer.encoder.layer.1.attention.output.dense.bias', 'Darkformer.encoder.layer.1.attention.output.LayerNorm.weight', 'Darkformer.encoder.layer.1.attention.output.LayerNorm.bias', 'Darkformer.encoder.layer.1.intermediate.dense.weight', 'Darkformer.encoder.layer.1.intermediate.dense.bias', 'Darkformer.encoder.layer.1.output.dense.weight', 'Darkformer.encoder.layer.1.output.dense.bias', 'Darkformer.encoder.layer.1.output.LayerNorm.weight', 'Darkformer.encoder.layer.1.output.LayerNorm.bias', 'Darkformer.encoder.layer.2.attention.self.query.weight', 'Darkformer.encoder.layer.2.attention.self.query.bias', 'Darkformer.encoder.layer.2.attention.self.key.weight', 'Darkformer.encoder.layer.2.attention.self.key.bias', 'Darkformer.encoder.layer.2.attention.self.value.weight', 'Darkformer.encoder.layer.2.attention.self.value.bias', 'Darkformer.encoder.layer.2.attention.output.dense.weight', 'Darkformer.encoder.layer.2.attention.output.dense.bias', 'Darkformer.encoder.layer.2.attention.output.LayerNorm.weight', 'Darkformer.encoder.layer.2.attention.output.LayerNorm.bias', 'Darkformer.encoder.layer.2.intermediate.dense.weight', 'Darkformer.encoder.layer.2.intermediate.dense.bias', 'Darkformer.encoder.layer.2.output.dense.weight', 'Darkformer.encoder.layer.2.output.dense.bias', 'Darkformer.encoder.layer.2.output.LayerNorm.weight', 'Darkformer.encoder.layer.2.output.LayerNorm.bias', 'Darkformer.encoder.layer.3.attention.self.query.weight', 'Darkformer.encoder.layer.3.attention.self.query.bias', 'Darkformer.encoder.layer.3.attention.self.key.weight', 'Darkformer.encoder.layer.3.attention.self.key.bias', 'Darkformer.encoder.layer.3.attention.self.value.weight', 'Darkformer.encoder.layer.3.attention.self.value.bias', 'Darkformer.encoder.layer.3.attention.output.dense.weight', 'Darkformer.encoder.layer.3.attention.output.dense.bias', 'Darkformer.encoder.layer.3.attention.output.LayerNorm.weight', 'Darkformer.encoder.layer.3.attention.output.LayerNorm.bias', 'Darkformer.encoder.layer.3.intermediate.dense.weight', 'Darkformer.encoder.layer.3.intermediate.dense.bias', 'Darkformer.encoder.layer.3.output.dense.weight', 'Darkformer.encoder.layer.3.output.dense.bias', 'Darkformer.encoder.layer.3.output.LayerNorm.weight', 'Darkformer.encoder.layer.3.output.LayerNorm.bias', 'Darkformer.encoder.layer.4.attention.self.query.weight', 'Darkformer.encoder.layer.4.attention.self.query.bias', 'Darkformer.encoder.layer.4.attention.self.key.weight', 'Darkformer.encoder.layer.4.attention.self.key.bias', 'Darkformer.encoder.layer.4.attention.self.value.weight', 'Darkformer.encoder.layer.4.attention.self.value.bias', 'Darkformer.encoder.layer.4.attention.output.dense.weight', 'Darkformer.encoder.layer.4.attention.output.dense.bias', 'Darkformer.encoder.layer.4.attention.output.LayerNorm.weight', 'Darkformer.encoder.layer.4.attention.output.LayerNorm.bias', 'Darkformer.encoder.layer.4.intermediate.dense.weight', 'Darkformer.encoder.layer.4.intermediate.dense.bias', 'Darkformer.encoder.layer.4.output.dense.weight', 'Darkformer.encoder.layer.4.output.dense.bias', 'Darkformer.encoder.layer.4.output.LayerNorm.weight', 'Darkformer.encoder.layer.4.output.LayerNorm.bias', 'Darkformer.encoder.layer.5.attention.self.query.weight', 'Darkformer.encoder.layer.5.attention.self.query.bias', 'Darkformer.encoder.layer.5.attention.self.key.weight', 'Darkformer.encoder.layer.5.attention.self.key.bias', 'Darkformer.encoder.layer.5.attention.self.value.weight', 'Darkformer.encoder.layer.5.attention.self.value.bias', 'Darkformer.encoder.layer.5.attention.output.dense.weight', 'Darkformer.encoder.layer.5.attention.output.dense.bias', 'Darkformer.encoder.layer.5.attention.output.LayerNorm.weight', 'Darkformer.encoder.layer.5.attention.output.LayerNorm.bias', 'Darkformer.encoder.layer.5.intermediate.dense.weight', 'Darkformer.encoder.layer.5.intermediate.dense.bias', 'Darkformer.encoder.layer.5.output.dense.weight', 'Darkformer.encoder.layer.5.output.dense.bias', 'Darkformer.encoder.layer.5.output.LayerNorm.weight', 'Darkformer.encoder.layer.5.output.LayerNorm.bias', 'Darkformer.encoder.layer.6.attention.self.query.weight', 'Darkformer.encoder.layer.6.attention.self.query.bias', 'Darkformer.encoder.layer.6.attention.self.key.weight', 'Darkformer.encoder.layer.6.attention.self.key.bias', 'Darkformer.encoder.layer.6.attention.self.value.weight', 'Darkformer.encoder.layer.6.attention.self.value.bias', 'Darkformer.encoder.layer.6.attention.output.dense.weight', 'Darkformer.encoder.layer.6.attention.output.dense.bias', 'Darkformer.encoder.layer.6.attention.output.LayerNorm.weight', 'Darkformer.encoder.layer.6.attention.output.LayerNorm.bias', 'Darkformer.encoder.layer.6.intermediate.dense.weight', 'Darkformer.encoder.layer.6.intermediate.dense.bias', 'Darkformer.encoder.layer.6.output.dense.weight', 'Darkformer.encoder.layer.6.output.dense.bias', 'Darkformer.encoder.layer.6.output.LayerNorm.weight', 'Darkformer.encoder.layer.6.output.LayerNorm.bias', 'Darkformer.encoder.layer.7.attention.self.query.weight', 'Darkformer.encoder.layer.7.attention.self.query.bias', 'Darkformer.encoder.layer.7.attention.self.key.weight', 'Darkformer.encoder.layer.7.attention.self.key.bias', 'Darkformer.encoder.layer.7.attention.self.value.weight', 'Darkformer.encoder.layer.7.attention.self.value.bias', 'Darkformer.encoder.layer.7.attention.output.dense.weight', 'Darkformer.encoder.layer.7.attention.output.dense.bias', 'Darkformer.encoder.layer.7.attention.output.LayerNorm.weight', 'Darkformer.encoder.layer.7.attention.output.LayerNorm.bias', 'Darkformer.encoder.layer.7.intermediate.dense.weight', 'Darkformer.encoder.layer.7.intermediate.dense.bias', 'Darkformer.encoder.layer.7.output.dense.weight', 'Darkformer.encoder.layer.7.output.dense.bias', 'Darkformer.encoder.layer.7.output.LayerNorm.weight', 'Darkformer.encoder.layer.7.output.LayerNorm.bias', 'Darkformer.encoder.layer.8.attention.self.query.weight', 'Darkformer.encoder.layer.8.attention.self.query.bias', 'Darkformer.encoder.layer.8.attention.self.key.weight', 'Darkformer.encoder.layer.8.attention.self.key.bias', 'Darkformer.encoder.layer.8.attention.self.value.weight', 'Darkformer.encoder.layer.8.attention.self.value.bias', 'Darkformer.encoder.layer.8.attention.output.dense.weight', 'Darkformer.encoder.layer.8.attention.output.dense.bias', 'Darkformer.encoder.layer.8.attention.output.LayerNorm.weight', 'Darkformer.encoder.layer.8.attention.output.LayerNorm.bias', 'Darkformer.encoder.layer.8.intermediate.dense.weight', 'Darkformer.encoder.layer.8.intermediate.dense.bias', 'Darkformer.encoder.layer.8.output.dense.weight', 'Darkformer.encoder.layer.8.output.dense.bias', 'Darkformer.encoder.layer.8.output.LayerNorm.weight', 'Darkformer.encoder.layer.8.output.LayerNorm.bias', 'Darkformer.encoder.layer.9.attention.self.query.weight', 'Darkformer.encoder.layer.9.attention.self.query.bias', 'Darkformer.encoder.layer.9.attention.self.key.weight', 'Darkformer.encoder.layer.9.attention.self.key.bias', 'Darkformer.encoder.layer.9.attention.self.value.weight', 'Darkformer.encoder.layer.9.attention.self.value.bias', 'Darkformer.encoder.layer.9.attention.output.dense.weight', 'Darkformer.encoder.layer.9.attention.output.dense.bias', 'Darkformer.encoder.layer.9.attention.output.LayerNorm.weight', 'Darkformer.encoder.layer.9.attention.output.LayerNorm.bias', 'Darkformer.encoder.layer.9.intermediate.dense.weight', 'Darkformer.encoder.layer.9.intermediate.dense.bias', 'Darkformer.encoder.layer.9.output.dense.weight', 'Darkformer.encoder.layer.9.output.dense.bias', 'Darkformer.encoder.layer.9.output.LayerNorm.weight', 'Darkformer.encoder.layer.9.output.LayerNorm.bias', 'Darkformer.encoder.layer.10.attention.self.query.weight', 'Darkformer.encoder.layer.10.attention.self.query.bias', 'Darkformer.encoder.layer.10.attention.self.key.weight', 'Darkformer.encoder.layer.10.attention.self.key.bias', 'Darkformer.encoder.layer.10.attention.self.value.weight', 'Darkformer.encoder.layer.10.attention.self.value.bias', 'Darkformer.encoder.layer.10.attention.output.dense.weight', 'Darkformer.encoder.layer.10.attention.output.dense.bias', 'Darkformer.encoder.layer.10.attention.output.LayerNorm.weight', 'Darkformer.encoder.layer.10.attention.output.LayerNorm.bias', 'Darkformer.encoder.layer.10.intermediate.dense.weight', 'Darkformer.encoder.layer.10.intermediate.dense.bias', 'Darkformer.encoder.layer.10.output.dense.weight', 'Darkformer.encoder.layer.10.output.dense.bias', 'Darkformer.encoder.layer.10.output.LayerNorm.weight', 'Darkformer.encoder.layer.10.output.LayerNorm.bias', 'Darkformer.encoder.layer.11.attention.self.query.weight', 'Darkformer.encoder.layer.11.attention.self.query.bias', 'Darkformer.encoder.layer.11.attention.self.key.weight', 'Darkformer.encoder.layer.11.attention.self.key.bias', 'Darkformer.encoder.layer.11.attention.self.value.weight', 'Darkformer.encoder.layer.11.attention.self.value.bias', 'Darkformer.encoder.layer.11.attention.output.dense.weight', 'Darkformer.encoder.layer.11.attention.output.dense.bias', 'Darkformer.encoder.layer.11.attention.output.LayerNorm.weight', 'Darkformer.encoder.layer.11.attention.output.LayerNorm.bias', 'Darkformer.encoder.layer.11.intermediate.dense.weight', 'Darkformer.encoder.layer.11.intermediate.dense.bias', 'Darkformer.encoder.layer.11.output.dense.weight', 'Darkformer.encoder.layer.11.output.dense.bias', 'Darkformer.encoder.layer.11.output.LayerNorm.weight', 'Darkformer.encoder.layer.11.output.LayerNorm.bias', 'Darkformer.cls_proj.weight', 'Darkformer.cls_proj.bias', 'Darkformer.pooler.0.weight', 'Darkformer.pooler.0.bias', 'Darkformer.opt_proj.weight', 'Darkformer.opt_proj.bias']
2023-05-11 01:28:13,272 [INFO] load checkpoint from /home/yiren/VATEX/lavis/output/BLIP-T/Caption_vatex_stage1/20230510183/checkpoint_9.pth
2023-05-11 01:28:15,974 [INFO] Missing keys ['VL_adaptor.embeddings.position_ids', 'VL_adaptor.embeddings.word_embeddings.weight', 'VL_adaptor.embeddings.position_embeddings.weight', 'VL_adaptor.embeddings.token_type_embeddings.weight', 'VL_adaptor.embeddings.LayerNorm.weight', 'VL_adaptor.embeddings.LayerNorm.bias', 'VL_adaptor.encoder.layer.0.attention.self.query.weight', 'VL_adaptor.encoder.layer.0.attention.self.query.bias', 'VL_adaptor.encoder.layer.0.attention.self.key.weight', 'VL_adaptor.encoder.layer.0.attention.self.key.bias', 'VL_adaptor.encoder.layer.0.attention.self.value.weight', 'VL_adaptor.encoder.layer.0.attention.self.value.bias', 'VL_adaptor.encoder.layer.0.attention.output.dense.weight', 'VL_adaptor.encoder.layer.0.attention.output.dense.bias', 'VL_adaptor.encoder.layer.0.attention.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.0.attention.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.0.intermediate.dense.weight', 'VL_adaptor.encoder.layer.0.intermediate.dense.bias', 'VL_adaptor.encoder.layer.0.output.dense.weight', 'VL_adaptor.encoder.layer.0.output.dense.bias', 'VL_adaptor.encoder.layer.0.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.0.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.1.attention.self.query.weight', 'VL_adaptor.encoder.layer.1.attention.self.query.bias', 'VL_adaptor.encoder.layer.1.attention.self.key.weight', 'VL_adaptor.encoder.layer.1.attention.self.key.bias', 'VL_adaptor.encoder.layer.1.attention.self.value.weight', 'VL_adaptor.encoder.layer.1.attention.self.value.bias', 'VL_adaptor.encoder.layer.1.attention.output.dense.weight', 'VL_adaptor.encoder.layer.1.attention.output.dense.bias', 'VL_adaptor.encoder.layer.1.attention.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.1.attention.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.1.intermediate.dense.weight', 'VL_adaptor.encoder.layer.1.intermediate.dense.bias', 'VL_adaptor.encoder.layer.1.output.dense.weight', 'VL_adaptor.encoder.layer.1.output.dense.bias', 'VL_adaptor.encoder.layer.1.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.1.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.2.attention.self.query.weight', 'VL_adaptor.encoder.layer.2.attention.self.query.bias', 'VL_adaptor.encoder.layer.2.attention.self.key.weight', 'VL_adaptor.encoder.layer.2.attention.self.key.bias', 'VL_adaptor.encoder.layer.2.attention.self.value.weight', 'VL_adaptor.encoder.layer.2.attention.self.value.bias', 'VL_adaptor.encoder.layer.2.attention.output.dense.weight', 'VL_adaptor.encoder.layer.2.attention.output.dense.bias', 'VL_adaptor.encoder.layer.2.attention.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.2.attention.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.2.intermediate.dense.weight', 'VL_adaptor.encoder.layer.2.intermediate.dense.bias', 'VL_adaptor.encoder.layer.2.output.dense.weight', 'VL_adaptor.encoder.layer.2.output.dense.bias', 'VL_adaptor.encoder.layer.2.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.2.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.3.attention.self.query.weight', 'VL_adaptor.encoder.layer.3.attention.self.query.bias', 'VL_adaptor.encoder.layer.3.attention.self.key.weight', 'VL_adaptor.encoder.layer.3.attention.self.key.bias', 'VL_adaptor.encoder.layer.3.attention.self.value.weight', 'VL_adaptor.encoder.layer.3.attention.self.value.bias', 'VL_adaptor.encoder.layer.3.attention.output.dense.weight', 'VL_adaptor.encoder.layer.3.attention.output.dense.bias', 'VL_adaptor.encoder.layer.3.attention.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.3.attention.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.3.intermediate.dense.weight', 'VL_adaptor.encoder.layer.3.intermediate.dense.bias', 'VL_adaptor.encoder.layer.3.output.dense.weight', 'VL_adaptor.encoder.layer.3.output.dense.bias', 'VL_adaptor.encoder.layer.3.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.3.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.4.attention.self.query.weight', 'VL_adaptor.encoder.layer.4.attention.self.query.bias', 'VL_adaptor.encoder.layer.4.attention.self.key.weight', 'VL_adaptor.encoder.layer.4.attention.self.key.bias', 'VL_adaptor.encoder.layer.4.attention.self.value.weight', 'VL_adaptor.encoder.layer.4.attention.self.value.bias', 'VL_adaptor.encoder.layer.4.attention.output.dense.weight', 'VL_adaptor.encoder.layer.4.attention.output.dense.bias', 'VL_adaptor.encoder.layer.4.attention.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.4.attention.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.4.intermediate.dense.weight', 'VL_adaptor.encoder.layer.4.intermediate.dense.bias', 'VL_adaptor.encoder.layer.4.output.dense.weight', 'VL_adaptor.encoder.layer.4.output.dense.bias', 'VL_adaptor.encoder.layer.4.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.4.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.5.attention.self.query.weight', 'VL_adaptor.encoder.layer.5.attention.self.query.bias', 'VL_adaptor.encoder.layer.5.attention.self.key.weight', 'VL_adaptor.encoder.layer.5.attention.self.key.bias', 'VL_adaptor.encoder.layer.5.attention.self.value.weight', 'VL_adaptor.encoder.layer.5.attention.self.value.bias', 'VL_adaptor.encoder.layer.5.attention.output.dense.weight', 'VL_adaptor.encoder.layer.5.attention.output.dense.bias', 'VL_adaptor.encoder.layer.5.attention.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.5.attention.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.5.intermediate.dense.weight', 'VL_adaptor.encoder.layer.5.intermediate.dense.bias', 'VL_adaptor.encoder.layer.5.output.dense.weight', 'VL_adaptor.encoder.layer.5.output.dense.bias', 'VL_adaptor.encoder.layer.5.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.5.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.6.attention.self.query.weight', 'VL_adaptor.encoder.layer.6.attention.self.query.bias', 'VL_adaptor.encoder.layer.6.attention.self.key.weight', 'VL_adaptor.encoder.layer.6.attention.self.key.bias', 'VL_adaptor.encoder.layer.6.attention.self.value.weight', 'VL_adaptor.encoder.layer.6.attention.self.value.bias', 'VL_adaptor.encoder.layer.6.attention.output.dense.weight', 'VL_adaptor.encoder.layer.6.attention.output.dense.bias', 'VL_adaptor.encoder.layer.6.attention.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.6.attention.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.6.intermediate.dense.weight', 'VL_adaptor.encoder.layer.6.intermediate.dense.bias', 'VL_adaptor.encoder.layer.6.output.dense.weight', 'VL_adaptor.encoder.layer.6.output.dense.bias', 'VL_adaptor.encoder.layer.6.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.6.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.7.attention.self.query.weight', 'VL_adaptor.encoder.layer.7.attention.self.query.bias', 'VL_adaptor.encoder.layer.7.attention.self.key.weight', 'VL_adaptor.encoder.layer.7.attention.self.key.bias', 'VL_adaptor.encoder.layer.7.attention.self.value.weight', 'VL_adaptor.encoder.layer.7.attention.self.value.bias', 'VL_adaptor.encoder.layer.7.attention.output.dense.weight', 'VL_adaptor.encoder.layer.7.attention.output.dense.bias', 'VL_adaptor.encoder.layer.7.attention.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.7.attention.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.7.intermediate.dense.weight', 'VL_adaptor.encoder.layer.7.intermediate.dense.bias', 'VL_adaptor.encoder.layer.7.output.dense.weight', 'VL_adaptor.encoder.layer.7.output.dense.bias', 'VL_adaptor.encoder.layer.7.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.7.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.8.attention.self.query.weight', 'VL_adaptor.encoder.layer.8.attention.self.query.bias', 'VL_adaptor.encoder.layer.8.attention.self.key.weight', 'VL_adaptor.encoder.layer.8.attention.self.key.bias', 'VL_adaptor.encoder.layer.8.attention.self.value.weight', 'VL_adaptor.encoder.layer.8.attention.self.value.bias', 'VL_adaptor.encoder.layer.8.attention.output.dense.weight', 'VL_adaptor.encoder.layer.8.attention.output.dense.bias', 'VL_adaptor.encoder.layer.8.attention.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.8.attention.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.8.intermediate.dense.weight', 'VL_adaptor.encoder.layer.8.intermediate.dense.bias', 'VL_adaptor.encoder.layer.8.output.dense.weight', 'VL_adaptor.encoder.layer.8.output.dense.bias', 'VL_adaptor.encoder.layer.8.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.8.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.9.attention.self.query.weight', 'VL_adaptor.encoder.layer.9.attention.self.query.bias', 'VL_adaptor.encoder.layer.9.attention.self.key.weight', 'VL_adaptor.encoder.layer.9.attention.self.key.bias', 'VL_adaptor.encoder.layer.9.attention.self.value.weight', 'VL_adaptor.encoder.layer.9.attention.self.value.bias', 'VL_adaptor.encoder.layer.9.attention.output.dense.weight', 'VL_adaptor.encoder.layer.9.attention.output.dense.bias', 'VL_adaptor.encoder.layer.9.attention.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.9.attention.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.9.intermediate.dense.weight', 'VL_adaptor.encoder.layer.9.intermediate.dense.bias', 'VL_adaptor.encoder.layer.9.output.dense.weight', 'VL_adaptor.encoder.layer.9.output.dense.bias', 'VL_adaptor.encoder.layer.9.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.9.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.10.attention.self.query.weight', 'VL_adaptor.encoder.layer.10.attention.self.query.bias', 'VL_adaptor.encoder.layer.10.attention.self.key.weight', 'VL_adaptor.encoder.layer.10.attention.self.key.bias', 'VL_adaptor.encoder.layer.10.attention.self.value.weight', 'VL_adaptor.encoder.layer.10.attention.self.value.bias', 'VL_adaptor.encoder.layer.10.attention.output.dense.weight', 'VL_adaptor.encoder.layer.10.attention.output.dense.bias', 'VL_adaptor.encoder.layer.10.attention.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.10.attention.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.10.intermediate.dense.weight', 'VL_adaptor.encoder.layer.10.intermediate.dense.bias', 'VL_adaptor.encoder.layer.10.output.dense.weight', 'VL_adaptor.encoder.layer.10.output.dense.bias', 'VL_adaptor.encoder.layer.10.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.10.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.11.attention.self.query.weight', 'VL_adaptor.encoder.layer.11.attention.self.query.bias', 'VL_adaptor.encoder.layer.11.attention.self.key.weight', 'VL_adaptor.encoder.layer.11.attention.self.key.bias', 'VL_adaptor.encoder.layer.11.attention.self.value.weight', 'VL_adaptor.encoder.layer.11.attention.self.value.bias', 'VL_adaptor.encoder.layer.11.attention.output.dense.weight', 'VL_adaptor.encoder.layer.11.attention.output.dense.bias', 'VL_adaptor.encoder.layer.11.attention.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.11.attention.output.LayerNorm.bias', 'VL_adaptor.encoder.layer.11.intermediate.dense.weight', 'VL_adaptor.encoder.layer.11.intermediate.dense.bias', 'VL_adaptor.encoder.layer.11.output.dense.weight', 'VL_adaptor.encoder.layer.11.output.dense.bias', 'VL_adaptor.encoder.layer.11.output.LayerNorm.weight', 'VL_adaptor.encoder.layer.11.output.LayerNorm.bias', 'VL_adaptor.feat_proj.weight', 'VL_adaptor.feat_proj.bias', 'opt_proj.weight', 'opt_proj.bias']
2023-05-11 01:28:15,974 [INFO] load checkpoint from /home/yiren/LAVIS/lavis/output/BLIP-T/Pretrain_stage0/vq/40m-noisy/checkpoint_60000.pth
2023-05-11 01:28:16,138 [INFO] Start training
2023-05-11 01:28:16,975 [INFO] dataset_ratios not specified, datasets will be concatenated (map-style datasets) or chained (webdataset.DataPipeline).
2023-05-11 01:28:16,975 [INFO] Loaded 259910 records for train split from the dataset.
2023-05-11 01:28:16,976 [INFO] Loaded 3000 records for val split from the dataset.
2023-05-11 01:28:16,985 [INFO] number of trainable parameters: 87810304
2023-05-11 01:28:16,986 [INFO] Start training epoch 0, 2030 iters per inner epoch.
/home/yiren/anaconda3/envs/lavis/lib/python3.8/site-packages/transformers/modeling_utils.py:810: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
Train: data epoch: [0]  [   0/2030]  eta: 1:19:02  lr: 0.000001  loss: 5.7303  time: 2.3360  data: 0.0000  max mem: 31792
2023-05-11 01:28:19,325 [INFO] Reducer buckets have been rebuilt in this iteration.
Train: data epoch: [0]  [  50/2030]  eta: 0:41:47  lr: 0.000006  loss: 3.2305  time: 1.2596  data: 0.0000  max mem: 32518
Train: data epoch: [0]  [ 100/2030]  eta: 0:40:47  lr: 0.000011  loss: 2.9640  time: 1.2688  data: 0.0000  max mem: 32518
Train: data epoch: [0]  [ 150/2030]  eta: 0:39:51  lr: 0.000016  loss: 2.9132  time: 1.2783  data: 0.0000  max mem: 32518
Train: data epoch: [0]  [ 200/2030]  eta: 0:38:51  lr: 0.000021  loss: 2.8420  time: 1.2847  data: 0.0000  max mem: 32518
Train: data epoch: [0]  [ 250/2030]  eta: 0:37:47  lr: 0.000026  loss: 2.8413  time: 1.2755  data: 0.0000  max mem: 32518
Train: data epoch: [0]  [ 300/2030]  eta: 0:36:46  lr: 0.000031  loss: 2.7960  time: 1.2804  data: 0.0000  max mem: 32518
Train: data epoch: [0]  [ 350/2030]  eta: 0:35:44  lr: 0.000036  loss: 2.7359  time: 1.2794  data: 0.0000  max mem: 32518
Train: data epoch: [0]  [ 400/2030]  eta: 0:34:41  lr: 0.000041  loss: 2.7165  time: 1.2843  data: 0.0000  max mem: 32518
Train: data epoch: [0]  [ 450/2030]  eta: 0:33:38  lr: 0.000046  loss: 2.7796  time: 1.2801  data: 0.0000  max mem: 32518
Train: data epoch: [0]  [ 500/2030]  eta: 0:32:33  lr: 0.000051  loss: 2.6293  time: 1.2797  data: 0.0000  max mem: 32518
Train: data epoch: [0]  [ 550/2030]  eta: 0:31:30  lr: 0.000055  loss: 2.6311  time: 1.2827  data: 0.0000  max mem: 32518
Train: data epoch: [0]  [ 600/2030]  eta: 0:30:26  lr: 0.000060  loss: 2.6368  time: 1.2810  data: 0.0000  max mem: 32518
Train: data epoch: [0]  [ 650/2030]  eta: 0:29:23  lr: 0.000065  loss: 2.7632  time: 1.2817  data: 0.0000  max mem: 32518
Train: data epoch: [0]  [ 700/2030]  eta: 0:28:19  lr: 0.000070  loss: 2.5627  time: 1.2780  data: 0.0000  max mem: 32518
Train: data epoch: [0]  [ 750/2030]  eta: 0:27:15  lr: 0.000075  loss: 2.7905  time: 1.2778  data: 0.0000  max mem: 32518
Train: data epoch: [0]  [ 800/2030]  eta: 0:26:12  lr: 0.000080  loss: 2.5876  time: 1.2796  data: 0.0000  max mem: 32518
Train: data epoch: [0]  [ 850/2030]  eta: 0:25:08  lr: 0.000085  loss: 2.6191  time: 1.2766  data: 0.0000  max mem: 32518
Train: data epoch: [0]  [ 900/2030]  eta: 0:24:04  lr: 0.000090  loss: 2.6131  time: 1.2741  data: 0.0000  max mem: 32518
Train: data epoch: [0]  [ 950/2030]  eta: 0:23:00  lr: 0.000095  loss: 2.5105  time: 1.2762  data: 0.0000  max mem: 32518
Train: data epoch: [0]  [1000/2030]  eta: 0:21:56  lr: 0.000100  loss: 2.5987  time: 1.2817  data: 0.0000  max mem: 32518
Train: data epoch: [0]  [1050/2030]  eta: 0:20:52  lr: 0.000100  loss: 2.5798  time: 1.2772  data: 0.0000  max mem: 32518
Train: data epoch: [0]  [1100/2030]  eta: 0:19:48  lr: 0.000100  loss: 2.5595  time: 1.2792  data: 0.0000  max mem: 32518
Train: data epoch: [0]  [1150/2030]  eta: 0:18:44  lr: 0.000100  loss: 2.5645  time: 1.2733  data: 0.0000  max mem: 32518
Train: data epoch: [0]  [1200/2030]  eta: 0:17:40  lr: 0.000100  loss: 2.5437  time: 1.2712  data: 0.0000  max mem: 32518
Train: data epoch: [0]  [1250/2030]  eta: 0:16:36  lr: 0.000100  loss: 2.5095  time: 1.2839  data: 0.0000  max mem: 32518
Train: data epoch: [0]  [1300/2030]  eta: 0:15:32  lr: 0.000100  loss: 2.4678  time: 1.2741  data: 0.0000  max mem: 32518
Train: data epoch: [0]  [1350/2030]  eta: 0:14:29  lr: 0.000100  loss: 2.6134  time: 1.2822  data: 0.0000  max mem: 32518
Train: data epoch: [0]  [1400/2030]  eta: 0:13:25  lr: 0.000100  loss: 2.5360  time: 1.2736  data: 0.0000  max mem: 32518
Train: data epoch: [0]  [1450/2030]  eta: 0:12:21  lr: 0.000100  loss: 2.5142  time: 1.2851  data: 0.0000  max mem: 32518
Train: data epoch: [0]  [1500/2030]  eta: 0:11:17  lr: 0.000100  loss: 2.6296  time: 1.2723  data: 0.0000  max mem: 32518
Train: data epoch: [0]  [1550/2030]  eta: 0:10:13  lr: 0.000100  loss: 2.4472  time: 1.2808  data: 0.0000  max mem: 32518
Train: data epoch: [0]  [1600/2030]  eta: 0:09:09  lr: 0.000100  loss: 2.4840  time: 1.2790  data: 0.0000  max mem: 32518
Train: data epoch: [0]  [1650/2030]  eta: 0:08:05  lr: 0.000100  loss: 2.4959  time: 1.2816  data: 0.0000  max mem: 32518
Train: data epoch: [0]  [1700/2030]  eta: 0:07:01  lr: 0.000100  loss: 2.4944  time: 1.2799  data: 0.0000  max mem: 32518
Train: data epoch: [0]  [1750/2030]  eta: 0:05:57  lr: 0.000100  loss: 2.4163  time: 1.2848  data: 0.0000  max mem: 32518
Train: data epoch: [0]  [1800/2030]  eta: 0:04:54  lr: 0.000100  loss: 2.5374  time: 1.2745  data: 0.0000  max mem: 32518
Train: data epoch: [0]  [1850/2030]  eta: 0:03:50  lr: 0.000100  loss: 2.6616  time: 1.2723  data: 0.0000  max mem: 32518
Train: data epoch: [0]  [1900/2030]  eta: 0:02:46  lr: 0.000100  loss: 2.3910  time: 1.2842  data: 0.0000  max mem: 32518
Train: data epoch: [0]  [1950/2030]  eta: 0:01:42  lr: 0.000100  loss: 2.4407  time: 1.2789  data: 0.0000  max mem: 32518
Train: data epoch: [0]  [2000/2030]  eta: 0:00:38  lr: 0.000100  loss: 2.3628  time: 1.2799  data: 0.0000  max mem: 32518
Train: data epoch: [0]  [2029/2030]  eta: 0:00:01  lr: 0.000100  loss: 2.5500  time: 1.2847  data: 0.0000  max mem: 32518
Train: data epoch: [0] Total time: 0:43:15 (1.2786 s / it)
2023-05-11 02:11:32,524 [INFO] Averaged stats: lr: 0.0001  loss: 2.6326
2023-05-11 02:11:32,526 [INFO] Start training
2023-05-11 02:11:32,543 [INFO] Start training epoch 1, 2030 iters per inner epoch.
Train: data epoch: [1]  [   0/2030]  eta: 2:00:32  lr: 0.000098  loss: 2.4730  time: 3.5629  data: 0.0000  max mem: 32518
Train: data epoch: [1]  [  50/2030]  eta: 0:43:39  lr: 0.000098  loss: 2.4523  time: 1.2845  data: 0.0000  max mem: 32518
Train: data epoch: [1]  [ 100/2030]  eta: 0:41:53  lr: 0.000098  loss: 2.4080  time: 1.2774  data: 0.0000  max mem: 32518
Train: data epoch: [1]  [ 150/2030]  eta: 0:40:34  lr: 0.000098  loss: 2.4792  time: 1.2803  data: 0.0000  max mem: 32518
Train: data epoch: [1]  [ 200/2030]  eta: 0:39:20  lr: 0.000098  loss: 2.3819  time: 1.2745  data: 0.0000  max mem: 32518
Train: data epoch: [1]  [ 250/2030]  eta: 0:38:12  lr: 0.000098  loss: 2.4144  time: 1.2792  data: 0.0000  max mem: 32518
Train: data epoch: [1]  [ 300/2030]  eta: 0:37:05  lr: 0.000098  loss: 2.3541  time: 1.2775  data: 0.0000  max mem: 32518
Train: data epoch: [1]  [ 350/2030]  eta: 0:35:57  lr: 0.000098  loss: 2.4825  time: 1.2780  data: 0.0000  max mem: 32518
Train: data epoch: [1]  [ 400/2030]  eta: 0:34:52  lr: 0.000098  loss: 2.3147  time: 1.2761  data: 0.0000  max mem: 32518
Train: data epoch: [1]  [ 450/2030]  eta: 0:33:46  lr: 0.000098  loss: 2.3421  time: 1.2767  data: 0.0000  max mem: 32518
Train: data epoch: [1]  [ 500/2030]  eta: 0:32:41  lr: 0.000098  loss: 2.3218  time: 1.2690  data: 0.0000  max mem: 32518
Train: data epoch: [1]  [ 550/2030]  eta: 0:31:37  lr: 0.000098  loss: 2.3844  time: 1.2823  data: 0.0000  max mem: 32518
Train: data epoch: [1]  [ 600/2030]  eta: 0:30:32  lr: 0.000098  loss: 2.4530  time: 1.2737  data: 0.0000  max mem: 32518
Train: data epoch: [1]  [ 650/2030]  eta: 0:29:28  lr: 0.000098  loss: 2.3374  time: 1.2809  data: 0.0000  max mem: 32518
Train: data epoch: [1]  [ 700/2030]  eta: 0:28:24  lr: 0.000098  loss: 2.3956  time: 1.2832  data: 0.0000  max mem: 32518
Train: data epoch: [1]  [ 750/2030]  eta: 0:27:19  lr: 0.000098  loss: 2.4335  time: 1.2819  data: 0.0000  max mem: 32518
Train: data epoch: [1]  [ 800/2030]  eta: 0:26:15  lr: 0.000098  loss: 2.3503  time: 1.2792  data: 0.0000  max mem: 32518
Train: data epoch: [1]  [ 850/2030]  eta: 0:25:11  lr: 0.000098  loss: 2.4002  time: 1.2673  data: 0.0000  max mem: 32518
Train: data epoch: [1]  [ 900/2030]  eta: 0:24:07  lr: 0.000098  loss: 2.3708  time: 1.2807  data: 0.0000  max mem: 32518
Train: data epoch: [1]  [ 950/2030]  eta: 0:23:03  lr: 0.000098  loss: 2.3012  time: 1.2785  data: 0.0000  max mem: 32518
Train: data epoch: [1]  [1000/2030]  eta: 0:21:58  lr: 0.000098  loss: 2.3211  time: 1.2721  data: 0.0000  max mem: 32518
Train: data epoch: [1]  [1050/2030]  eta: 0:20:54  lr: 0.000098  loss: 2.4430  time: 1.2784  data: 0.0000  max mem: 32518
Train: data epoch: [1]  [1100/2030]  eta: 0:19:50  lr: 0.000098  loss: 2.4038  time: 1.2825  data: 0.0000  max mem: 32518
Train: data epoch: [1]  [1150/2030]  eta: 0:18:46  lr: 0.000098  loss: 2.3369  time: 1.2831  data: 0.0000  max mem: 32518
Train: data epoch: [1]  [1200/2030]  eta: 0:17:42  lr: 0.000098  loss: 2.4333  time: 1.2773  data: 0.0000  max mem: 32518
Train: data epoch: [1]  [1250/2030]  eta: 0:16:38  lr: 0.000098  loss: 2.3444  time: 1.2823  data: 0.0000  max mem: 32518
Train: data epoch: [1]  [1300/2030]  eta: 0:15:34  lr: 0.000098  loss: 2.3237  time: 1.2828  data: 0.0000  max mem: 32518
Train: data epoch: [1]  [1350/2030]  eta: 0:14:30  lr: 0.000098  loss: 2.4369  time: 1.2810  data: 0.0000  max mem: 32518
Train: data epoch: [1]  [1400/2030]  eta: 0:13:26  lr: 0.000098  loss: 2.2859  time: 1.2772  data: 0.0000  max mem: 32518
Train: data epoch: [1]  [1450/2030]  eta: 0:12:22  lr: 0.000098  loss: 2.3924  time: 1.2762  data: 0.0000  max mem: 32518
Train: data epoch: [1]  [1500/2030]  eta: 0:11:18  lr: 0.000098  loss: 2.3689  time: 1.2776  data: 0.0000  max mem: 32518
Train: data epoch: [1]  [1550/2030]  eta: 0:10:14  lr: 0.000098  loss: 2.4024  time: 1.2712  data: 0.0000  max mem: 32518
Train: data epoch: [1]  [1600/2030]  eta: 0:09:10  lr: 0.000098  loss: 2.3645  time: 1.2819  data: 0.0000  max mem: 32518
Train: data epoch: [1]  [1650/2030]  eta: 0:08:06  lr: 0.000098  loss: 2.3407  time: 1.2769  data: 0.0000  max mem: 32518
Train: data epoch: [1]  [1700/2030]  eta: 0:07:02  lr: 0.000098  loss: 2.3181  time: 1.2842  data: 0.0000  max mem: 32518
Train: data epoch: [1]  [1750/2030]  eta: 0:05:58  lr: 0.000098  loss: 2.3555  time: 1.2791  data: 0.0000  max mem: 32518
Train: data epoch: [1]  [1800/2030]  eta: 0:04:54  lr: 0.000098  loss: 2.2080  time: 1.2735  data: 0.0000  max mem: 32518
Train: data epoch: [1]  [1850/2030]  eta: 0:03:50  lr: 0.000098  loss: 2.2485  time: 1.2819  data: 0.0000  max mem: 32518
Train: data epoch: [1]  [1900/2030]  eta: 0:02:46  lr: 0.000098  loss: 2.2481  time: 1.2784  data: 0.0000  max mem: 32518
Train: data epoch: [1]  [1950/2030]  eta: 0:01:42  lr: 0.000098  loss: 2.2978  time: 1.2852  data: 0.0000  max mem: 32518
Train: data epoch: [1]  [2000/2030]  eta: 0:00:38  lr: 0.000098  loss: 2.2231  time: 1.2853  data: 0.0000  max mem: 32518
Train: data epoch: [1]  [2029/2030]  eta: 0:00:01  lr: 0.000098  loss: 2.4122  time: 1.2792  data: 0.0000  max mem: 32518
Train: data epoch: [1] Total time: 0:43:18 (1.2799 s / it)
2023-05-11 02:54:50,686 [INFO] Averaged stats: lr: 0.0001  loss: 2.3627
2023-05-11 02:54:50,688 [INFO] Start training
2023-05-11 02:54:50,705 [INFO] Start training epoch 2, 2030 iters per inner epoch.
Train: data epoch: [2]  [   0/2030]  eta: 2:00:53  lr: 0.000091  loss: 2.2769  time: 3.5730  data: 0.0000  max mem: 32518
Train: data epoch: [2]  [  50/2030]  eta: 0:43:43  lr: 0.000091  loss: 2.2521  time: 1.2818  data: 0.0000  max mem: 32518
Train: data epoch: [2]  [ 100/2030]  eta: 0:41:53  lr: 0.000091  loss: 2.2829  time: 1.2778  data: 0.0000  max mem: 32518
Train: data epoch: [2]  [ 150/2030]  eta: 0:40:32  lr: 0.000091  loss: 2.2403  time: 1.2662  data: 0.0000  max mem: 32518
Train: data epoch: [2]  [ 200/2030]  eta: 0:39:22  lr: 0.000091  loss: 2.2573  time: 1.2846  data: 0.0000  max mem: 32518
Train: data epoch: [2]  [ 250/2030]  eta: 0:38:13  lr: 0.000091  loss: 2.3125  time: 1.2805  data: 0.0000  max mem: 32518
Train: data epoch: [2]  [ 300/2030]  eta: 0:37:07  lr: 0.000091  loss: 2.3164  time: 1.2804  data: 0.0000  max mem: 32518
Train: data epoch: [2]  [ 350/2030]  eta: 0:36:01  lr: 0.000091  loss: 2.3758  time: 1.2758  data: 0.0000  max mem: 32518
Train: data epoch: [2]  [ 400/2030]  eta: 0:34:56  lr: 0.000091  loss: 2.2574  time: 1.2845  data: 0.0000  max mem: 32518
Train: data epoch: [2]  [ 450/2030]  eta: 0:33:50  lr: 0.000091  loss: 2.2953  time: 1.2834  data: 0.0000  max mem: 32518
Train: data epoch: [2]  [ 500/2030]  eta: 0:32:45  lr: 0.000091  loss: 2.2411  time: 1.2785  data: 0.0000  max mem: 32518
Train: data epoch: [2]  [ 550/2030]  eta: 0:31:40  lr: 0.000091  loss: 2.2495  time: 1.2848  data: 0.0000  max mem: 32518
Train: data epoch: [2]  [ 600/2030]  eta: 0:30:36  lr: 0.000091  loss: 2.1669  time: 1.2798  data: 0.0000  max mem: 32518
Train: data epoch: [2]  [ 650/2030]  eta: 0:29:31  lr: 0.000091  loss: 2.1664  time: 1.2797  data: 0.0000  max mem: 32518
Train: data epoch: [2]  [ 700/2030]  eta: 0:28:26  lr: 0.000091  loss: 2.2651  time: 1.2853  data: 0.0000  max mem: 32518
Train: data epoch: [2]  [ 750/2030]  eta: 0:27:22  lr: 0.000091  loss: 2.2131  time: 1.2823  data: 0.0000  max mem: 32518
Train: data epoch: [2]  [ 800/2030]  eta: 0:26:18  lr: 0.000091  loss: 2.3612  time: 1.2832  data: 0.0000  max mem: 32518
Train: data epoch: [2]  [ 850/2030]  eta: 0:25:13  lr: 0.000091  loss: 2.3469  time: 1.2771  data: 0.0000  max mem: 32518
Train: data epoch: [2]  [ 900/2030]  eta: 0:24:09  lr: 0.000091  loss: 2.2617  time: 1.2748  data: 0.0000  max mem: 32518
Train: data epoch: [2]  [ 950/2030]  eta: 0:23:05  lr: 0.000091  loss: 2.2527  time: 1.2822  data: 0.0000  max mem: 32518
Train: data epoch: [2]  [1000/2030]  eta: 0:22:00  lr: 0.000091  loss: 2.2891  time: 1.2796  data: 0.0000  max mem: 32518
Train: data epoch: [2]  [1050/2030]  eta: 0:20:56  lr: 0.000091  loss: 2.2530  time: 1.2792  data: 0.0000  max mem: 32518
Train: data epoch: [2]  [1100/2030]  eta: 0:19:52  lr: 0.000091  loss: 2.1727  time: 1.2820  data: 0.0000  max mem: 32518
Train: data epoch: [2]  [1150/2030]  eta: 0:18:48  lr: 0.000091  loss: 2.2488  time: 1.2751  data: 0.0000  max mem: 32518
Train: data epoch: [2]  [1200/2030]  eta: 0:17:44  lr: 0.000091  loss: 2.2585  time: 1.2791  data: 0.0000  max mem: 32518
Train: data epoch: [2]  [1250/2030]  eta: 0:16:39  lr: 0.000091  loss: 2.2732  time: 1.2792  data: 0.0000  max mem: 32518
Train: data epoch: [2]  [1300/2030]  eta: 0:15:35  lr: 0.000091  loss: 2.1960  time: 1.2815  data: 0.0000  max mem: 32518
Train: data epoch: [2]  [1350/2030]  eta: 0:14:31  lr: 0.000091  loss: 2.2497  time: 1.2789  data: 0.0000  max mem: 32518
Train: data epoch: [2]  [1400/2030]  eta: 0:13:27  lr: 0.000091  loss: 2.2144  time: 1.2745  data: 0.0000  max mem: 32518
Train: data epoch: [2]  [1450/2030]  eta: 0:12:23  lr: 0.000091  loss: 2.1787  time: 1.2813  data: 0.0000  max mem: 32518
Train: data epoch: [2]  [1500/2030]  eta: 0:11:19  lr: 0.000091  loss: 2.1839  time: 1.2805  data: 0.0000  max mem: 32518
Train: data epoch: [2]  [1550/2030]  eta: 0:10:15  lr: 0.000091  loss: 2.1190  time: 1.2771  data: 0.0000  max mem: 32518
Train: data epoch: [2]  [1600/2030]  eta: 0:09:11  lr: 0.000091  loss: 2.2401  time: 1.2792  data: 0.0000  max mem: 32518
Train: data epoch: [2]  [1650/2030]  eta: 0:08:06  lr: 0.000091  loss: 2.2587  time: 1.2817  data: 0.0000  max mem: 32518
Train: data epoch: [2]  [1700/2030]  eta: 0:07:02  lr: 0.000091  loss: 2.2469  time: 1.2816  data: 0.0000  max mem: 32518
Train: data epoch: [2]  [1750/2030]  eta: 0:05:58  lr: 0.000091  loss: 2.4268  time: 1.2765  data: 0.0000  max mem: 32518
Train: data epoch: [2]  [1800/2030]  eta: 0:04:54  lr: 0.000091  loss: 2.2712  time: 1.2777  data: 0.0000  max mem: 32518
Train: data epoch: [2]  [1850/2030]  eta: 0:03:50  lr: 0.000091  loss: 2.2181  time: 1.2760  data: 0.0000  max mem: 32518
Train: data epoch: [2]  [1900/2030]  eta: 0:02:46  lr: 0.000091  loss: 2.2990  time: 1.2729  data: 0.0000  max mem: 32518
Train: data epoch: [2]  [1950/2030]  eta: 0:01:42  lr: 0.000091  loss: 2.2080  time: 1.2715  data: 0.0000  max mem: 32518
Train: data epoch: [2]  [2000/2030]  eta: 0:00:38  lr: 0.000091  loss: 2.2170  time: 1.2791  data: 0.0000  max mem: 32518
Train: data epoch: [2]  [2029/2030]  eta: 0:00:01  lr: 0.000091  loss: 2.1344  time: 1.2891  data: 0.0000  max mem: 32518
Train: data epoch: [2] Total time: 0:43:20 (1.2809 s / it)
2023-05-11 03:38:10,987 [INFO] Averaged stats: lr: 0.0001  loss: 2.2580
2023-05-11 03:38:10,988 [INFO] Start training
2023-05-11 03:38:11,006 [INFO] Start training epoch 3, 2030 iters per inner epoch.
Train: data epoch: [3]  [   0/2030]  eta: 2:01:00  lr: 0.000081  loss: 2.1926  time: 3.5764  data: 0.0000  max mem: 32518
Train: data epoch: [3]  [  50/2030]  eta: 0:43:41  lr: 0.000081  loss: 2.1063  time: 1.2792  data: 0.0000  max mem: 32518
Train: data epoch: [3]  [ 100/2030]  eta: 0:41:49  lr: 0.000081  loss: 2.3076  time: 1.2815  data: 0.0000  max mem: 32518
Train: data epoch: [3]  [ 150/2030]  eta: 0:40:30  lr: 0.000081  loss: 2.1393  time: 1.2795  data: 0.0000  max mem: 32518
Train: data epoch: [3]  [ 200/2030]  eta: 0:39:20  lr: 0.000081  loss: 2.2408  time: 1.2804  data: 0.0000  max mem: 32518
Train: data epoch: [3]  [ 250/2030]  eta: 0:38:12  lr: 0.000081  loss: 2.2581  time: 1.2827  data: 0.0000  max mem: 32518
Train: data epoch: [3]  [ 300/2030]  eta: 0:37:05  lr: 0.000081  loss: 2.1796  time: 1.2773  data: 0.0000  max mem: 32518
Train: data epoch: [3]  [ 350/2030]  eta: 0:35:59  lr: 0.000081  loss: 2.0928  time: 1.2816  data: 0.0000  max mem: 32518
Train: data epoch: [3]  [ 400/2030]  eta: 0:34:54  lr: 0.000081  loss: 2.0946  time: 1.2782  data: 0.0000  max mem: 32518
Train: data epoch: [3]  [ 450/2030]  eta: 0:33:49  lr: 0.000081  loss: 2.1804  time: 1.2791  data: 0.0000  max mem: 32518
Train: data epoch: [3]  [ 500/2030]  eta: 0:32:44  lr: 0.000081  loss: 2.2190  time: 1.2762  data: 0.0000  max mem: 32518
Train: data epoch: [3]  [ 550/2030]  eta: 0:31:39  lr: 0.000081  loss: 2.1299  time: 1.2850  data: 0.0000  max mem: 32518
Train: data epoch: [3]  [ 600/2030]  eta: 0:30:34  lr: 0.000081  loss: 2.1449  time: 1.2785  data: 0.0000  max mem: 32518
Train: data epoch: [3]  [ 650/2030]  eta: 0:29:30  lr: 0.000081  loss: 2.2589  time: 1.2788  data: 0.0000  max mem: 32518
Train: data epoch: [3]  [ 700/2030]  eta: 0:28:25  lr: 0.000081  loss: 2.1318  time: 1.2798  data: 0.0000  max mem: 32518
Train: data epoch: [3]  [ 750/2030]  eta: 0:27:21  lr: 0.000081  loss: 2.1056  time: 1.2819  data: 0.0000  max mem: 32518
Train: data epoch: [3]  [ 800/2030]  eta: 0:26:16  lr: 0.000081  loss: 2.2259  time: 1.2794  data: 0.0000  max mem: 32518
Train: data epoch: [3]  [ 850/2030]  eta: 0:25:12  lr: 0.000081  loss: 2.1600  time: 1.2791  data: 0.0000  max mem: 32518
Train: data epoch: [3]  [ 900/2030]  eta: 0:24:08  lr: 0.000081  loss: 2.2023  time: 1.2764  data: 0.0000  max mem: 32518
Train: data epoch: [3]  [ 950/2030]  eta: 0:23:03  lr: 0.000081  loss: 2.2727  time: 1.2725  data: 0.0000  max mem: 32518
Train: data epoch: [3]  [1000/2030]  eta: 0:21:59  lr: 0.000081  loss: 2.2726  time: 1.2773  data: 0.0000  max mem: 32518
Train: data epoch: [3]  [1050/2030]  eta: 0:20:55  lr: 0.000081  loss: 2.2454  time: 1.2734  data: 0.0000  max mem: 32518
Train: data epoch: [3]  [1100/2030]  eta: 0:19:50  lr: 0.000081  loss: 2.1288  time: 1.2671  data: 0.0000  max mem: 32518
Train: data epoch: [3]  [1150/2030]  eta: 0:18:46  lr: 0.000081  loss: 2.1508  time: 1.2824  data: 0.0000  max mem: 32518
Train: data epoch: [3]  [1200/2030]  eta: 0:17:42  lr: 0.000081  loss: 2.0806  time: 1.2753  data: 0.0000  max mem: 32518
Train: data epoch: [3]  [1250/2030]  eta: 0:16:38  lr: 0.000081  loss: 2.1533  time: 1.2817  data: 0.0000  max mem: 32518
Train: data epoch: [3]  [1300/2030]  eta: 0:15:34  lr: 0.000081  loss: 2.2133  time: 1.2814  data: 0.0000  max mem: 32518
Train: data epoch: [3]  [1350/2030]  eta: 0:14:30  lr: 0.000081  loss: 2.0617  time: 1.2767  data: 0.0000  max mem: 32518
Train: data epoch: [3]  [1400/2030]  eta: 0:13:26  lr: 0.000081  loss: 2.1271  time: 1.2790  data: 0.0000  max mem: 32518
Train: data epoch: [3]  [1450/2030]  eta: 0:12:22  lr: 0.000081  loss: 2.2312  time: 1.2767  data: 0.0000  max mem: 32518
Train: data epoch: [3]  [1500/2030]  eta: 0:11:18  lr: 0.000081  loss: 2.1702  time: 1.2786  data: 0.0000  max mem: 32518
Train: data epoch: [3]  [1550/2030]  eta: 0:10:14  lr: 0.000081  loss: 2.0874  time: 1.2738  data: 0.0000  max mem: 32518
Train: data epoch: [3]  [1600/2030]  eta: 0:09:10  lr: 0.000081  loss: 2.2133  time: 1.2796  data: 0.0000  max mem: 32518
Train: data epoch: [3]  [1650/2030]  eta: 0:08:06  lr: 0.000081  loss: 2.1450  time: 1.2769  data: 0.0000  max mem: 32518
Train: data epoch: [3]  [1700/2030]  eta: 0:07:02  lr: 0.000081  loss: 2.2448  time: 1.2796  data: 0.0000  max mem: 32518
Train: data epoch: [3]  [1750/2030]  eta: 0:05:58  lr: 0.000081  loss: 2.1006  time: 1.2841  data: 0.0000  max mem: 32518
Train: data epoch: [3]  [1800/2030]  eta: 0:04:54  lr: 0.000081  loss: 2.1344  time: 1.2745  data: 0.0000  max mem: 32518
Train: data epoch: [3]  [1850/2030]  eta: 0:03:50  lr: 0.000081  loss: 2.2184  time: 1.2779  data: 0.0000  max mem: 32518
Train: data epoch: [3]  [1900/2030]  eta: 0:02:46  lr: 0.000081  loss: 2.1190  time: 1.2765  data: 0.0000  max mem: 32518
Train: data epoch: [3]  [1950/2030]  eta: 0:01:42  lr: 0.000081  loss: 2.2313  time: 1.2794  data: 0.0000  max mem: 32518
Train: data epoch: [3]  [2000/2030]  eta: 0:00:38  lr: 0.000081  loss: 2.2099  time: 1.2765  data: 0.0000  max mem: 32518
Train: data epoch: [3]  [2029/2030]  eta: 0:00:01  lr: 0.000081  loss: 2.1918  time: 1.2861  data: 0.0000  max mem: 32518
Train: data epoch: [3] Total time: 0:43:17 (1.2797 s / it)
2023-05-11 04:21:28,869 [INFO] Averaged stats: lr: 0.0001  loss: 2.1736
2023-05-11 04:21:28,871 [INFO] Start training
2023-05-11 04:21:28,888 [INFO] Start training epoch 4, 2030 iters per inner epoch.
Train: data epoch: [4]  [   0/2030]  eta: 2:01:01  lr: 0.000069  loss: 2.0771  time: 3.5770  data: 0.0000  max mem: 32518
Train: data epoch: [4]  [  50/2030]  eta: 0:43:44  lr: 0.000069  loss: 2.1495  time: 1.2790  data: 0.0000  max mem: 32518
Train: data epoch: [4]  [ 100/2030]  eta: 0:41:53  lr: 0.000069  loss: 2.0589  time: 1.2809  data: 0.0000  max mem: 32518
Train: data epoch: [4]  [ 150/2030]  eta: 0:40:36  lr: 0.000069  loss: 2.1251  time: 1.2843  data: 0.0000  max mem: 32518
Train: data epoch: [4]  [ 200/2030]  eta: 0:39:23  lr: 0.000069  loss: 2.0565  time: 1.2747  data: 0.0000  max mem: 32518
Train: data epoch: [4]  [ 250/2030]  eta: 0:38:14  lr: 0.000069  loss: 2.1066  time: 1.2776  data: 0.0000  max mem: 32518
Train: data epoch: [4]  [ 300/2030]  eta: 0:37:07  lr: 0.000069  loss: 2.0922  time: 1.2836  data: 0.0000  max mem: 32518
Train: data epoch: [4]  [ 350/2030]  eta: 0:36:00  lr: 0.000069  loss: 2.0468  time: 1.2804  data: 0.0000  max mem: 32518
Train: data epoch: [4]  [ 400/2030]  eta: 0:34:55  lr: 0.000069  loss: 2.1569  time: 1.2845  data: 0.0000  max mem: 32518
Train: data epoch: [4]  [ 450/2030]  eta: 0:33:50  lr: 0.000069  loss: 2.1499  time: 1.2803  data: 0.0000  max mem: 32518
Train: data epoch: [4]  [ 500/2030]  eta: 0:32:44  lr: 0.000069  loss: 2.0699  time: 1.2728  data: 0.0000  max mem: 32518
Train: data epoch: [4]  [ 550/2030]  eta: 0:31:39  lr: 0.000069  loss: 2.2092  time: 1.2735  data: 0.0000  max mem: 32518
Train: data epoch: [4]  [ 600/2030]  eta: 0:30:35  lr: 0.000069  loss: 2.1211  time: 1.2830  data: 0.0000  max mem: 32518
Train: data epoch: [4]  [ 650/2030]  eta: 0:29:30  lr: 0.000069  loss: 1.9938  time: 1.2709  data: 0.0000  max mem: 32518
Train: data epoch: [4]  [ 700/2030]  eta: 0:28:25  lr: 0.000069  loss: 2.0911  time: 1.2825  data: 0.0000  max mem: 32518
Train: data epoch: [4]  [ 750/2030]  eta: 0:27:21  lr: 0.000069  loss: 2.1461  time: 1.2778  data: 0.0000  max mem: 32518
Train: data epoch: [4]  [ 800/2030]  eta: 0:26:17  lr: 0.000069  loss: 2.1104  time: 1.2846  data: 0.0000  max mem: 32518
Train: data epoch: [4]  [ 850/2030]  eta: 0:25:13  lr: 0.000069  loss: 2.0493  time: 1.2802  data: 0.0000  max mem: 32518
Train: data epoch: [4]  [ 900/2030]  eta: 0:24:08  lr: 0.000069  loss: 2.0716  time: 1.2826  data: 0.0000  max mem: 32518
Train: data epoch: [4]  [ 950/2030]  eta: 0:23:04  lr: 0.000069  loss: 2.0736  time: 1.2794  data: 0.0000  max mem: 32518
Train: data epoch: [4]  [1000/2030]  eta: 0:22:00  lr: 0.000069  loss: 2.2075  time: 1.2737  data: 0.0000  max mem: 32518
Train: data epoch: [4]  [1050/2030]  eta: 0:20:56  lr: 0.000069  loss: 2.1223  time: 1.2820  data: 0.0000  max mem: 32518
Train: data epoch: [4]  [1100/2030]  eta: 0:19:51  lr: 0.000069  loss: 2.0368  time: 1.2797  data: 0.0000  max mem: 32518
Train: data epoch: [4]  [1150/2030]  eta: 0:18:47  lr: 0.000069  loss: 2.1875  time: 1.2829  data: 0.0000  max mem: 32518
Train: data epoch: [4]  [1200/2030]  eta: 0:17:43  lr: 0.000069  loss: 2.2009  time: 1.2827  data: 0.0000  max mem: 32518
Train: data epoch: [4]  [1250/2030]  eta: 0:16:39  lr: 0.000069  loss: 2.1162  time: 1.2813  data: 0.0000  max mem: 32518
Train: data epoch: [4]  [1300/2030]  eta: 0:15:35  lr: 0.000069  loss: 2.1273  time: 1.2827  data: 0.0000  max mem: 32518
Train: data epoch: [4]  [1350/2030]  eta: 0:14:31  lr: 0.000069  loss: 2.1470  time: 1.2823  data: 0.0000  max mem: 32518
Train: data epoch: [4]  [1400/2030]  eta: 0:13:27  lr: 0.000069  loss: 2.0633  time: 1.2758  data: 0.0000  max mem: 32518
Train: data epoch: [4]  [1450/2030]  eta: 0:12:23  lr: 0.000069  loss: 2.1041  time: 1.2800  data: 0.0000  max mem: 32518
Train: data epoch: [4]  [1500/2030]  eta: 0:11:19  lr: 0.000069  loss: 2.1609  time: 1.2801  data: 0.0000  max mem: 32518
Train: data epoch: [4]  [1550/2030]  eta: 0:10:15  lr: 0.000069  loss: 2.1632  time: 1.2798  data: 0.0000  max mem: 32518
Train: data epoch: [4]  [1600/2030]  eta: 0:09:11  lr: 0.000069  loss: 2.1705  time: 1.2845  data: 0.0000  max mem: 32518
Train: data epoch: [4]  [1650/2030]  eta: 0:08:06  lr: 0.000069  loss: 2.2009  time: 1.2777  data: 0.0000  max mem: 32518
Train: data epoch: [4]  [1700/2030]  eta: 0:07:02  lr: 0.000069  loss: 2.0778  time: 1.2774  data: 0.0000  max mem: 32518
Train: data epoch: [4]  [1750/2030]  eta: 0:05:58  lr: 0.000069  loss: 2.1293  time: 1.2825  data: 0.0000  max mem: 32518
Train: data epoch: [4]  [1800/2030]  eta: 0:04:54  lr: 0.000069  loss: 2.1418  time: 1.2846  data: 0.0000  max mem: 32518
Train: data epoch: [4]  [1850/2030]  eta: 0:03:50  lr: 0.000069  loss: 2.0816  time: 1.2827  data: 0.0000  max mem: 32518
Train: data epoch: [4]  [1900/2030]  eta: 0:02:46  lr: 0.000069  loss: 2.1017  time: 1.2857  data: 0.0000  max mem: 32518
Train: data epoch: [4]  [1950/2030]  eta: 0:01:42  lr: 0.000069  loss: 2.0269  time: 1.2821  data: 0.0000  max mem: 32518
Train: data epoch: [4]  [2000/2030]  eta: 0:00:38  lr: 0.000069  loss: 2.1542  time: 1.2752  data: 0.0000  max mem: 32518
Train: data epoch: [4]  [2029/2030]  eta: 0:00:01  lr: 0.000069  loss: 2.1024  time: 1.2860  data: 0.0000  max mem: 32518
Train: data epoch: [4] Total time: 0:43:20 (1.2813 s / it)
2023-05-11 05:04:49,882 [INFO] Averaged stats: lr: 0.0001  loss: 2.1121
2023-05-11 05:04:49,884 [INFO] Start training
2023-05-11 05:04:49,901 [INFO] Start training epoch 5, 2030 iters per inner epoch.
Train: data epoch: [5]  [   0/2030]  eta: 2:01:07  lr: 0.000055  loss: 1.9985  time: 3.5799  data: 0.0000  max mem: 32518
Train: data epoch: [5]  [  50/2030]  eta: 0:43:37  lr: 0.000055  loss: 2.0382  time: 1.2827  data: 0.0000  max mem: 32518
Train: data epoch: [5]  [ 100/2030]  eta: 0:41:50  lr: 0.000055  loss: 2.0299  time: 1.2784  data: 0.0000  max mem: 32518
Train: data epoch: [5]  [ 150/2030]  eta: 0:40:30  lr: 0.000055  loss: 1.9724  time: 1.2794  data: 0.0000  max mem: 32518
Train: data epoch: [5]  [ 200/2030]  eta: 0:39:20  lr: 0.000055  loss: 2.0592  time: 1.2802  data: 0.0000  max mem: 32518
Train: data epoch: [5]  [ 250/2030]  eta: 0:38:12  lr: 0.000055  loss: 1.9890  time: 1.2803  data: 0.0000  max mem: 32518
Train: data epoch: [5]  [ 300/2030]  eta: 0:37:05  lr: 0.000055  loss: 2.1878  time: 1.2794  data: 0.0000  max mem: 32518
Train: data epoch: [5]  [ 350/2030]  eta: 0:36:00  lr: 0.000055  loss: 2.0126  time: 1.2811  data: 0.0000  max mem: 32518
Train: data epoch: [5]  [ 400/2030]  eta: 0:34:54  lr: 0.000055  loss: 1.9710  time: 1.2808  data: 0.0000  max mem: 32518
Train: data epoch: [5]  [ 450/2030]  eta: 0:33:49  lr: 0.000055  loss: 1.9938  time: 1.2831  data: 0.0000  max mem: 32518
Train: data epoch: [5]  [ 500/2030]  eta: 0:32:44  lr: 0.000055  loss: 2.0658  time: 1.2829  data: 0.0000  max mem: 32518
Train: data epoch: [5]  [ 550/2030]  eta: 0:31:40  lr: 0.000055  loss: 2.0684  time: 1.2786  data: 0.0000  max mem: 32518
Train: data epoch: [5]  [ 600/2030]  eta: 0:30:35  lr: 0.000055  loss: 2.0354  time: 1.2834  data: 0.0000  max mem: 32518
Train: data epoch: [5]  [ 650/2030]  eta: 0:29:30  lr: 0.000055  loss: 2.0178  time: 1.2762  data: 0.0000  max mem: 32518
Train: data epoch: [5]  [ 700/2030]  eta: 0:28:26  lr: 0.000055  loss: 2.0883  time: 1.2819  data: 0.0000  max mem: 32518
Train: data epoch: [5]  [ 750/2030]  eta: 0:27:21  lr: 0.000055  loss: 2.0359  time: 1.2831  data: 0.0000  max mem: 32518
Train: data epoch: [5]  [ 800/2030]  eta: 0:26:17  lr: 0.000055  loss: 2.1697  time: 1.2857  data: 0.0000  max mem: 32518
Train: data epoch: [5]  [ 850/2030]  eta: 0:25:13  lr: 0.000055  loss: 2.1136  time: 1.2828  data: 0.0000  max mem: 32518
Train: data epoch: [5]  [ 900/2030]  eta: 0:24:09  lr: 0.000055  loss: 2.0064  time: 1.2852  data: 0.0000  max mem: 32518
Train: data epoch: [5]  [ 950/2030]  eta: 0:23:05  lr: 0.000055  loss: 2.0167  time: 1.2773  data: 0.0000  max mem: 32518
Train: data epoch: [5]  [1000/2030]  eta: 0:22:01  lr: 0.000055  loss: 2.0648  time: 1.2794  data: 0.0000  max mem: 32518
Train: data epoch: [5]  [1050/2030]  eta: 0:20:56  lr: 0.000055  loss: 2.1400  time: 1.2757  data: 0.0000  max mem: 32518
Train: data epoch: [5]  [1100/2030]  eta: 0:19:52  lr: 0.000055  loss: 2.0607  time: 1.2812  data: 0.0000  max mem: 32518
Train: data epoch: [5]  [1150/2030]  eta: 0:18:48  lr: 0.000055  loss: 2.0983  time: 1.2750  data: 0.0000  max mem: 32518
Train: data epoch: [5]  [1200/2030]  eta: 0:17:44  lr: 0.000055  loss: 2.0097  time: 1.2799  data: 0.0000  max mem: 32518
Train: data epoch: [5]  [1250/2030]  eta: 0:16:40  lr: 0.000055  loss: 2.2005  time: 1.2826  data: 0.0000  max mem: 32518
Train: data epoch: [5]  [1300/2030]  eta: 0:15:36  lr: 0.000055  loss: 2.0432  time: 1.2798  data: 0.0000  max mem: 32518
Train: data epoch: [5]  [1350/2030]  eta: 0:14:31  lr: 0.000055  loss: 2.0990  time: 1.2817  data: 0.0000  max mem: 32518
Train: data epoch: [5]  [1400/2030]  eta: 0:13:27  lr: 0.000055  loss: 2.0672  time: 1.2808  data: 0.0000  max mem: 32518
Train: data epoch: [5]  [1450/2030]  eta: 0:12:23  lr: 0.000055  loss: 2.0248  time: 1.2859  data: 0.0000  max mem: 32518
Train: data epoch: [5]  [1500/2030]  eta: 0:11:19  lr: 0.000055  loss: 2.0214  time: 1.2846  data: 0.0000  max mem: 32518
Train: data epoch: [5]  [1550/2030]  eta: 0:10:15  lr: 0.000055  loss: 2.0558  time: 1.2834  data: 0.0000  max mem: 32518
Train: data epoch: [5]  [1600/2030]  eta: 0:09:11  lr: 0.000055  loss: 1.9700  time: 1.2822  data: 0.0000  max mem: 32518
Train: data epoch: [5]  [1650/2030]  eta: 0:08:07  lr: 0.000055  loss: 2.0161  time: 1.2786  data: 0.0000  max mem: 32518
Train: data epoch: [5]  [1700/2030]  eta: 0:07:03  lr: 0.000055  loss: 1.9915  time: 1.2790  data: 0.0000  max mem: 32518
Train: data epoch: [5]  [1750/2030]  eta: 0:05:58  lr: 0.000055  loss: 2.0944  time: 1.2833  data: 0.0000  max mem: 32518
Train: data epoch: [5]  [1800/2030]  eta: 0:04:54  lr: 0.000055  loss: 2.0511  time: 1.2782  data: 0.0000  max mem: 32518
Train: data epoch: [5]  [1850/2030]  eta: 0:03:50  lr: 0.000055  loss: 2.2022  time: 1.2768  data: 0.0000  max mem: 32518
Train: data epoch: [5]  [1900/2030]  eta: 0:02:46  lr: 0.000055  loss: 2.1395  time: 1.2817  data: 0.0000  max mem: 32518
Train: data epoch: [5]  [1950/2030]  eta: 0:01:42  lr: 0.000055  loss: 2.0213  time: 1.2857  data: 0.0000  max mem: 32518
Train: data epoch: [5]  [2000/2030]  eta: 0:00:38  lr: 0.000055  loss: 2.0642  time: 1.2784  data: 0.0000  max mem: 32518
Train: data epoch: [5]  [2029/2030]  eta: 0:00:01  lr: 0.000055  loss: 2.0898  time: 1.2848  data: 0.0000  max mem: 32518
Train: data epoch: [5] Total time: 0:43:21 (1.2817 s / it)
2023-05-11 05:48:11,745 [INFO] Averaged stats: lr: 0.0001  loss: 2.0557
2023-05-11 05:48:11,747 [INFO] Start training
2023-05-11 05:48:11,764 [INFO] Start training epoch 6, 2030 iters per inner epoch.
Train: data epoch: [6]  [   0/2030]  eta: 2:00:59  lr: 0.000041  loss: 1.9821  time: 3.5761  data: 0.0000  max mem: 32518
Train: data epoch: [6]  [  50/2030]  eta: 0:43:49  lr: 0.000041  loss: 2.0594  time: 1.2834  data: 0.0000  max mem: 32518
Train: data epoch: [6]  [ 100/2030]  eta: 0:41:58  lr: 0.000041  loss: 1.9866  time: 1.2793  data: 0.0000  max mem: 32518
Train: data epoch: [6]  [ 150/2030]  eta: 0:40:38  lr: 0.000041  loss: 2.0107  time: 1.2836  data: 0.0000  max mem: 32518
Train: data epoch: [6]  [ 200/2030]  eta: 0:39:27  lr: 0.000041  loss: 2.0371  time: 1.2807  data: 0.0000  max mem: 32518
Train: data epoch: [6]  [ 250/2030]  eta: 0:38:18  lr: 0.000041  loss: 2.0110  time: 1.2836  data: 0.0000  max mem: 32518
Train: data epoch: [6]  [ 300/2030]  eta: 0:37:11  lr: 0.000041  loss: 1.9610  time: 1.2825  data: 0.0000  max mem: 32518
Train: data epoch: [6]  [ 350/2030]  eta: 0:36:03  lr: 0.000041  loss: 2.0348  time: 1.2689  data: 0.0000  max mem: 32518
Train: data epoch: [6]  [ 400/2030]  eta: 0:34:57  lr: 0.000041  loss: 1.9796  time: 1.2806  data: 0.0000  max mem: 32518
Train: data epoch: [6]  [ 450/2030]  eta: 0:33:51  lr: 0.000041  loss: 2.0887  time: 1.2793  data: 0.0000  max mem: 32518
Train: data epoch: [6]  [ 500/2030]  eta: 0:32:46  lr: 0.000041  loss: 2.0166  time: 1.2801  data: 0.0000  max mem: 32518
Train: data epoch: [6]  [ 550/2030]  eta: 0:31:41  lr: 0.000041  loss: 1.9517  time: 1.2834  data: 0.0000  max mem: 32518
Train: data epoch: [6]  [ 600/2030]  eta: 0:30:37  lr: 0.000041  loss: 2.0798  time: 1.2853  data: 0.0000  max mem: 32518
Train: data epoch: [6]  [ 650/2030]  eta: 0:29:31  lr: 0.000041  loss: 2.0490  time: 1.2732  data: 0.0000  max mem: 32518
Train: data epoch: [6]  [ 700/2030]  eta: 0:28:26  lr: 0.000041  loss: 2.0357  time: 1.2755  data: 0.0000  max mem: 32518
Train: data epoch: [6]  [ 750/2030]  eta: 0:27:22  lr: 0.000041  loss: 2.0697  time: 1.2795  data: 0.0000  max mem: 32518
Train: data epoch: [6]  [ 800/2030]  eta: 0:26:17  lr: 0.000041  loss: 2.0270  time: 1.2851  data: 0.0000  max mem: 32518
Train: data epoch: [6]  [ 850/2030]  eta: 0:25:13  lr: 0.000041  loss: 2.0478  time: 1.2810  data: 0.0000  max mem: 32518
Train: data epoch: [6]  [ 900/2030]  eta: 0:24:09  lr: 0.000041  loss: 1.9840  time: 1.2723  data: 0.0000  max mem: 32518
Train: data epoch: [6]  [ 950/2030]  eta: 0:23:04  lr: 0.000041  loss: 1.9891  time: 1.2741  data: 0.0000  max mem: 32518
Train: data epoch: [6]  [1000/2030]  eta: 0:22:00  lr: 0.000041  loss: 2.0788  time: 1.2753  data: 0.0000  max mem: 32518
Train: data epoch: [6]  [1050/2030]  eta: 0:20:55  lr: 0.000041  loss: 1.9331  time: 1.2793  data: 0.0000  max mem: 32518
Train: data epoch: [6]  [1100/2030]  eta: 0:19:51  lr: 0.000041  loss: 1.9368  time: 1.2717  data: 0.0000  max mem: 32518
Train: data epoch: [6]  [1150/2030]  eta: 0:18:47  lr: 0.000041  loss: 1.9854  time: 1.2805  data: 0.0000  max mem: 32518
Train: data epoch: [6]  [1200/2030]  eta: 0:17:43  lr: 0.000041  loss: 1.9826  time: 1.2824  data: 0.0000  max mem: 32518
Train: data epoch: [6]  [1250/2030]  eta: 0:16:39  lr: 0.000041  loss: 1.9972  time: 1.2727  data: 0.0000  max mem: 32518
Train: data epoch: [6]  [1300/2030]  eta: 0:15:34  lr: 0.000041  loss: 2.0223  time: 1.2815  data: 0.0000  max mem: 32518
Train: data epoch: [6]  [1350/2030]  eta: 0:14:30  lr: 0.000041  loss: 2.0562  time: 1.2828  data: 0.0000  max mem: 32518
Train: data epoch: [6]  [1400/2030]  eta: 0:13:26  lr: 0.000041  loss: 1.9869  time: 1.2786  data: 0.0000  max mem: 32518
Train: data epoch: [6]  [1450/2030]  eta: 0:12:22  lr: 0.000041  loss: 2.0117  time: 1.2747  data: 0.0000  max mem: 32518
Train: data epoch: [6]  [1500/2030]  eta: 0:11:18  lr: 0.000041  loss: 1.9827  time: 1.2807  data: 0.0000  max mem: 32518
Train: data epoch: [6]  [1550/2030]  eta: 0:10:14  lr: 0.000041  loss: 1.9565  time: 1.2774  data: 0.0000  max mem: 32518
Train: data epoch: [6]  [1600/2030]  eta: 0:09:10  lr: 0.000041  loss: 2.0019  time: 1.2762  data: 0.0000  max mem: 32518
Train: data epoch: [6]  [1650/2030]  eta: 0:08:06  lr: 0.000041  loss: 1.9668  time: 1.2721  data: 0.0000  max mem: 32518
Train: data epoch: [6]  [1700/2030]  eta: 0:07:02  lr: 0.000041  loss: 1.9967  time: 1.2810  data: 0.0000  max mem: 32518
Train: data epoch: [6]  [1750/2030]  eta: 0:05:58  lr: 0.000041  loss: 2.0695  time: 1.2746  data: 0.0000  max mem: 32518
Train: data epoch: [6]  [1800/2030]  eta: 0:04:54  lr: 0.000041  loss: 1.9262  time: 1.2816  data: 0.0000  max mem: 32518
Train: data epoch: [6]  [1850/2030]  eta: 0:03:50  lr: 0.000041  loss: 2.0073  time: 1.2795  data: 0.0000  max mem: 32518
Train: data epoch: [6]  [1900/2030]  eta: 0:02:46  lr: 0.000041  loss: 2.0136  time: 1.2803  data: 0.0000  max mem: 32518
Train: data epoch: [6]  [1950/2030]  eta: 0:01:42  lr: 0.000041  loss: 2.0379  time: 1.2725  data: 0.0000  max mem: 32518
Train: data epoch: [6]  [2000/2030]  eta: 0:00:38  lr: 0.000041  loss: 2.1225  time: 1.2788  data: 0.0000  max mem: 32518
Train: data epoch: [6]  [2029/2030]  eta: 0:00:01  lr: 0.000041  loss: 2.0293  time: 1.2858  data: 0.0000  max mem: 32518
Train: data epoch: [6] Total time: 0:43:18 (1.2801 s / it)
2023-05-11 06:31:30,320 [INFO] Averaged stats: lr: 0.0000  loss: 2.0035
2023-05-11 06:31:30,322 [INFO] Start training
2023-05-11 06:31:30,339 [INFO] Start training epoch 7, 2030 iters per inner epoch.
Train: data epoch: [7]  [   0/2030]  eta: 2:00:24  lr: 0.000029  loss: 1.8769  time: 3.5591  data: 0.0000  max mem: 32518
Train: data epoch: [7]  [  50/2030]  eta: 0:43:41  lr: 0.000029  loss: 1.8833  time: 1.2772  data: 0.0000  max mem: 32518
Train: data epoch: [7]  [ 100/2030]  eta: 0:41:47  lr: 0.000029  loss: 1.9264  time: 1.2768  data: 0.0000  max mem: 32518
Train: data epoch: [7]  [ 150/2030]  eta: 0:40:30  lr: 0.000029  loss: 1.9468  time: 1.2805  data: 0.0000  max mem: 32518
Train: data epoch: [7]  [ 200/2030]  eta: 0:39:17  lr: 0.000029  loss: 1.9075  time: 1.2759  data: 0.0000  max mem: 32518
Train: data epoch: [7]  [ 250/2030]  eta: 0:38:10  lr: 0.000029  loss: 1.9627  time: 1.2761  data: 0.0000  max mem: 32518
Train: data epoch: [7]  [ 300/2030]  eta: 0:37:03  lr: 0.000029  loss: 1.9508  time: 1.2809  data: 0.0000  max mem: 32518
Train: data epoch: [7]  [ 350/2030]  eta: 0:35:58  lr: 0.000029  loss: 1.9701  time: 1.2781  data: 0.0000  max mem: 32518
Train: data epoch: [7]  [ 400/2030]  eta: 0:34:52  lr: 0.000029  loss: 1.9537  time: 1.2787  data: 0.0000  max mem: 32518
Train: data epoch: [7]  [ 450/2030]  eta: 0:33:46  lr: 0.000029  loss: 1.9953  time: 1.2750  data: 0.0000  max mem: 32518
Train: data epoch: [7]  [ 500/2030]  eta: 0:32:41  lr: 0.000029  loss: 1.8705  time: 1.2757  data: 0.0000  max mem: 32518
Train: data epoch: [7]  [ 550/2030]  eta: 0:31:37  lr: 0.000029  loss: 1.9643  time: 1.2810  data: 0.0000  max mem: 32518
Train: data epoch: [7]  [ 600/2030]  eta: 0:30:32  lr: 0.000029  loss: 1.8471  time: 1.2767  data: 0.0000  max mem: 32518
Train: data epoch: [7]  [ 650/2030]  eta: 0:29:28  lr: 0.000029  loss: 1.9956  time: 1.2835  data: 0.0000  max mem: 32518
Train: data epoch: [7]  [ 700/2030]  eta: 0:28:23  lr: 0.000029  loss: 2.0526  time: 1.2800  data: 0.0000  max mem: 32518
Train: data epoch: [7]  [ 750/2030]  eta: 0:27:19  lr: 0.000029  loss: 2.0039  time: 1.2780  data: 0.0000  max mem: 32518
Train: data epoch: [7]  [ 800/2030]  eta: 0:26:15  lr: 0.000029  loss: 1.8898  time: 1.2780  data: 0.0000  max mem: 32518
Train: data epoch: [7]  [ 850/2030]  eta: 0:25:10  lr: 0.000029  loss: 1.9852  time: 1.2768  data: 0.0000  max mem: 32518
Train: data epoch: [7]  [ 900/2030]  eta: 0:24:06  lr: 0.000029  loss: 1.8862  time: 1.2762  data: 0.0000  max mem: 32518
Train: data epoch: [7]  [ 950/2030]  eta: 0:23:02  lr: 0.000029  loss: 1.8613  time: 1.2756  data: 0.0000  max mem: 32518
Train: data epoch: [7]  [1000/2030]  eta: 0:21:58  lr: 0.000029  loss: 1.9646  time: 1.2835  data: 0.0000  max mem: 32518
Train: data epoch: [7]  [1050/2030]  eta: 0:20:54  lr: 0.000029  loss: 1.9395  time: 1.2784  data: 0.0000  max mem: 32518
Train: data epoch: [7]  [1100/2030]  eta: 0:19:50  lr: 0.000029  loss: 1.9164  time: 1.2805  data: 0.0000  max mem: 32518
Train: data epoch: [7]  [1150/2030]  eta: 0:18:46  lr: 0.000029  loss: 1.9414  time: 1.2772  data: 0.0000  max mem: 32518
Train: data epoch: [7]  [1200/2030]  eta: 0:17:42  lr: 0.000029  loss: 1.9856  time: 1.2786  data: 0.0000  max mem: 32518
Train: data epoch: [7]  [1250/2030]  eta: 0:16:38  lr: 0.000029  loss: 1.9508  time: 1.2809  data: 0.0000  max mem: 32518
Train: data epoch: [7]  [1300/2030]  eta: 0:15:34  lr: 0.000029  loss: 2.0477  time: 1.2757  data: 0.0000  max mem: 32518
Train: data epoch: [7]  [1350/2030]  eta: 0:14:30  lr: 0.000029  loss: 1.9332  time: 1.2782  data: 0.0000  max mem: 32518
Train: data epoch: [7]  [1400/2030]  eta: 0:13:25  lr: 0.000029  loss: 2.0288  time: 1.2679  data: 0.0000  max mem: 32518
Train: data epoch: [7]  [1450/2030]  eta: 0:12:22  lr: 0.000029  loss: 1.9201  time: 1.2843  data: 0.0000  max mem: 32518
Train: data epoch: [7]  [1500/2030]  eta: 0:11:18  lr: 0.000029  loss: 1.9897  time: 1.2808  data: 0.0000  max mem: 32518
Train: data epoch: [7]  [1550/2030]  eta: 0:10:14  lr: 0.000029  loss: 1.8748  time: 1.2781  data: 0.0000  max mem: 32518
Train: data epoch: [7]  [1600/2030]  eta: 0:09:10  lr: 0.000029  loss: 1.9633  time: 1.2841  data: 0.0000  max mem: 32518
Train: data epoch: [7]  [1650/2030]  eta: 0:08:06  lr: 0.000029  loss: 1.9585  time: 1.2742  data: 0.0000  max mem: 32518
Train: data epoch: [7]  [1700/2030]  eta: 0:07:02  lr: 0.000029  loss: 2.0098  time: 1.2785  data: 0.0000  max mem: 32518
Train: data epoch: [7]  [1750/2030]  eta: 0:05:58  lr: 0.000029  loss: 2.0071  time: 1.2800  data: 0.0000  max mem: 32518
Train: data epoch: [7]  [1800/2030]  eta: 0:04:54  lr: 0.000029  loss: 1.9458  time: 1.2762  data: 0.0000  max mem: 32518
Train: data epoch: [7]  [1850/2030]  eta: 0:03:50  lr: 0.000029  loss: 1.9184  time: 1.2816  data: 0.0000  max mem: 32518
Train: data epoch: [7]  [1900/2030]  eta: 0:02:46  lr: 0.000029  loss: 1.8324  time: 1.2805  data: 0.0000  max mem: 32518
Train: data epoch: [7]  [1950/2030]  eta: 0:01:42  lr: 0.000029  loss: 1.8753  time: 1.2783  data: 0.0000  max mem: 32518
Train: data epoch: [7]  [2000/2030]  eta: 0:00:38  lr: 0.000029  loss: 1.9401  time: 1.2816  data: 0.0000  max mem: 32518
Train: data epoch: [7]  [2029/2030]  eta: 0:00:01  lr: 0.000029  loss: 1.9863  time: 1.2838  data: 0.0000  max mem: 32518
Train: data epoch: [7] Total time: 0:43:16 (1.2791 s / it)
2023-05-11 07:14:46,849 [INFO] Averaged stats: lr: 0.0000  loss: 1.9571
2023-05-11 07:14:46,851 [INFO] Start training
2023-05-11 07:14:46,868 [INFO] Start training epoch 8, 2030 iters per inner epoch.
Train: data epoch: [8]  [   0/2030]  eta: 2:00:18  lr: 0.000019  loss: 1.9903  time: 3.5559  data: 0.0000  max mem: 32518
Train: data epoch: [8]  [  50/2030]  eta: 0:43:34  lr: 0.000019  loss: 1.9857  time: 1.2704  data: 0.0000  max mem: 32518
Train: data epoch: [8]  [ 100/2030]  eta: 0:41:49  lr: 0.000019  loss: 1.8286  time: 1.2767  data: 0.0000  max mem: 32518
Train: data epoch: [8]  [ 150/2030]  eta: 0:40:30  lr: 0.000019  loss: 1.9194  time: 1.2800  data: 0.0000  max mem: 32518
Train: data epoch: [8]  [ 200/2030]  eta: 0:39:20  lr: 0.000019  loss: 1.8765  time: 1.2771  data: 0.0000  max mem: 32518
Train: data epoch: [8]  [ 250/2030]  eta: 0:38:12  lr: 0.000019  loss: 1.9557  time: 1.2823  data: 0.0000  max mem: 32518
Train: data epoch: [8]  [ 300/2030]  eta: 0:37:05  lr: 0.000019  loss: 1.9911  time: 1.2753  data: 0.0000  max mem: 32518
Train: data epoch: [8]  [ 350/2030]  eta: 0:35:58  lr: 0.000019  loss: 1.9738  time: 1.2759  data: 0.0000  max mem: 32518
Train: data epoch: [8]  [ 400/2030]  eta: 0:34:53  lr: 0.000019  loss: 1.9152  time: 1.2789  data: 0.0000  max mem: 32518
Train: data epoch: [8]  [ 450/2030]  eta: 0:33:47  lr: 0.000019  loss: 1.8676  time: 1.2743  data: 0.0000  max mem: 32518
Train: data epoch: [8]  [ 500/2030]  eta: 0:32:43  lr: 0.000019  loss: 1.9267  time: 1.2806  data: 0.0000  max mem: 32518
Train: data epoch: [8]  [ 550/2030]  eta: 0:31:39  lr: 0.000019  loss: 2.0101  time: 1.2814  data: 0.0000  max mem: 32518
Train: data epoch: [8]  [ 600/2030]  eta: 0:30:34  lr: 0.000019  loss: 1.9328  time: 1.2776  data: 0.0000  max mem: 32518
Train: data epoch: [8]  [ 650/2030]  eta: 0:29:29  lr: 0.000019  loss: 1.8998  time: 1.2761  data: 0.0000  max mem: 32518
Train: data epoch: [8]  [ 700/2030]  eta: 0:28:24  lr: 0.000019  loss: 1.8258  time: 1.2761  data: 0.0000  max mem: 32518
Train: data epoch: [8]  [ 750/2030]  eta: 0:27:20  lr: 0.000019  loss: 1.8963  time: 1.2790  data: 0.0000  max mem: 32518
Train: data epoch: [8]  [ 800/2030]  eta: 0:26:16  lr: 0.000019  loss: 1.9578  time: 1.2833  data: 0.0000  max mem: 32518
Train: data epoch: [8]  [ 850/2030]  eta: 0:25:11  lr: 0.000019  loss: 1.9223  time: 1.2755  data: 0.0000  max mem: 32518
Train: data epoch: [8]  [ 900/2030]  eta: 0:24:07  lr: 0.000019  loss: 1.9618  time: 1.2760  data: 0.0000  max mem: 32518
Train: data epoch: [8]  [ 950/2030]  eta: 0:23:03  lr: 0.000019  loss: 1.9412  time: 1.2806  data: 0.0000  max mem: 32518
Train: data epoch: [8]  [1000/2030]  eta: 0:21:59  lr: 0.000019  loss: 1.9139  time: 1.2806  data: 0.0000  max mem: 32518
Train: data epoch: [8]  [1050/2030]  eta: 0:20:55  lr: 0.000019  loss: 1.9021  time: 1.2799  data: 0.0000  max mem: 32518
Train: data epoch: [8]  [1100/2030]  eta: 0:19:50  lr: 0.000019  loss: 1.9218  time: 1.2812  data: 0.0000  max mem: 32518
Train: data epoch: [8]  [1150/2030]  eta: 0:18:46  lr: 0.000019  loss: 1.8958  time: 1.2780  data: 0.0000  max mem: 32518
Train: data epoch: [8]  [1200/2030]  eta: 0:17:42  lr: 0.000019  loss: 1.9653  time: 1.2822  data: 0.0000  max mem: 32518
Train: data epoch: [8]  [1250/2030]  eta: 0:16:38  lr: 0.000019  loss: 1.9637  time: 1.2814  data: 0.0000  max mem: 32518
Train: data epoch: [8]  [1300/2030]  eta: 0:15:34  lr: 0.000019  loss: 1.8883  time: 1.2766  data: 0.0000  max mem: 32518
Train: data epoch: [8]  [1350/2030]  eta: 0:14:30  lr: 0.000019  loss: 1.9823  time: 1.2794  data: 0.0000  max mem: 32518
Train: data epoch: [8]  [1400/2030]  eta: 0:13:26  lr: 0.000019  loss: 2.0067  time: 1.2731  data: 0.0000  max mem: 32518
Train: data epoch: [8]  [1450/2030]  eta: 0:12:22  lr: 0.000019  loss: 1.8804  time: 1.2796  data: 0.0000  max mem: 32518
Train: data epoch: [8]  [1500/2030]  eta: 0:11:18  lr: 0.000019  loss: 1.9402  time: 1.2793  data: 0.0000  max mem: 32518
Train: data epoch: [8]  [1550/2030]  eta: 0:10:14  lr: 0.000019  loss: 1.8271  time: 1.2810  data: 0.0000  max mem: 32518
Train: data epoch: [8]  [1600/2030]  eta: 0:09:10  lr: 0.000019  loss: 1.8694  time: 1.2766  data: 0.0000  max mem: 32518
Train: data epoch: [8]  [1650/2030]  eta: 0:08:06  lr: 0.000019  loss: 1.8595  time: 1.2784  data: 0.0000  max mem: 32518
Train: data epoch: [8]  [1700/2030]  eta: 0:07:02  lr: 0.000019  loss: 2.0138  time: 1.2838  data: 0.0000  max mem: 32518
Train: data epoch: [8]  [1750/2030]  eta: 0:05:58  lr: 0.000019  loss: 1.8935  time: 1.2776  data: 0.0000  max mem: 32518
Train: data epoch: [8]  [1800/2030]  eta: 0:04:54  lr: 0.000019  loss: 2.0106  time: 1.2788  data: 0.0000  max mem: 32518
Train: data epoch: [8]  [1850/2030]  eta: 0:03:50  lr: 0.000019  loss: 1.8595  time: 1.2840  data: 0.0000  max mem: 32518
Train: data epoch: [8]  [1900/2030]  eta: 0:02:46  lr: 0.000019  loss: 1.7754  time: 1.2720  data: 0.0000  max mem: 32518
Train: data epoch: [8]  [1950/2030]  eta: 0:01:42  lr: 0.000019  loss: 1.8731  time: 1.2764  data: 0.0000  max mem: 32518
Train: data epoch: [8]  [2000/2030]  eta: 0:00:38  lr: 0.000019  loss: 1.9093  time: 1.2792  data: 0.0000  max mem: 32518
Train: data epoch: [8]  [2029/2030]  eta: 0:00:01  lr: 0.000019  loss: 2.0005  time: 1.2809  data: 0.0000  max mem: 32518
Train: data epoch: [8] Total time: 0:43:17 (1.2796 s / it)
2023-05-11 07:58:04,508 [INFO] Averaged stats: lr: 0.0000  loss: 1.9186
2023-05-11 07:58:04,509 [INFO] Start training
2023-05-11 07:58:04,527 [INFO] Start training epoch 9, 2030 iters per inner epoch.
Train: data epoch: [9]  [   0/2030]  eta: 2:01:11  lr: 0.000012  loss: 1.9335  time: 3.5819  data: 0.0000  max mem: 32518
Train: data epoch: [9]  [  50/2030]  eta: 0:43:43  lr: 0.000012  loss: 1.8028  time: 1.2840  data: 0.0000  max mem: 32518
Train: data epoch: [9]  [ 100/2030]  eta: 0:41:50  lr: 0.000012  loss: 1.9452  time: 1.2723  data: 0.0000  max mem: 32518
Train: data epoch: [9]  [ 150/2030]  eta: 0:40:32  lr: 0.000012  loss: 1.8747  time: 1.2798  data: 0.0000  max mem: 32518
Train: data epoch: [9]  [ 200/2030]  eta: 0:39:20  lr: 0.000012  loss: 1.8159  time: 1.2762  data: 0.0000  max mem: 32518
Train: data epoch: [9]  [ 250/2030]  eta: 0:38:12  lr: 0.000012  loss: 1.9203  time: 1.2820  data: 0.0000  max mem: 32518
Train: data epoch: [9]  [ 300/2030]  eta: 0:37:06  lr: 0.000012  loss: 1.9269  time: 1.2816  data: 0.0000  max mem: 32518
Train: data epoch: [9]  [ 350/2030]  eta: 0:35:58  lr: 0.000012  loss: 1.8179  time: 1.2749  data: 0.0000  max mem: 32518
Train: data epoch: [9]  [ 400/2030]  eta: 0:34:52  lr: 0.000012  loss: 1.8130  time: 1.2790  data: 0.0000  max mem: 32518
Train: data epoch: [9]  [ 450/2030]  eta: 0:33:47  lr: 0.000012  loss: 1.8523  time: 1.2791  data: 0.0000  max mem: 32518
Train: data epoch: [9]  [ 500/2030]  eta: 0:32:41  lr: 0.000012  loss: 1.9370  time: 1.2780  data: 0.0000  max mem: 32518
Train: data epoch: [9]  [ 550/2030]  eta: 0:31:37  lr: 0.000012  loss: 1.8716  time: 1.2768  data: 0.0000  max mem: 32518
Train: data epoch: [9]  [ 600/2030]  eta: 0:30:33  lr: 0.000012  loss: 1.8848  time: 1.2820  data: 0.0000  max mem: 32518
Train: data epoch: [9]  [ 650/2030]  eta: 0:29:28  lr: 0.000012  loss: 1.8177  time: 1.2821  data: 0.0000  max mem: 32518
Train: data epoch: [9]  [ 700/2030]  eta: 0:28:23  lr: 0.000012  loss: 1.8456  time: 1.2721  data: 0.0000  max mem: 32518
Train: data epoch: [9]  [ 750/2030]  eta: 0:27:19  lr: 0.000012  loss: 1.8408  time: 1.2839  data: 0.0000  max mem: 32518
Train: data epoch: [9]  [ 800/2030]  eta: 0:26:15  lr: 0.000012  loss: 1.8614  time: 1.2841  data: 0.0000  max mem: 32518
Train: data epoch: [9]  [ 850/2030]  eta: 0:25:11  lr: 0.000012  loss: 1.9309  time: 1.2769  data: 0.0000  max mem: 32518
Train: data epoch: [9]  [ 900/2030]  eta: 0:24:07  lr: 0.000012  loss: 1.8467  time: 1.2785  data: 0.0000  max mem: 32518
Train: data epoch: [9]  [ 950/2030]  eta: 0:23:03  lr: 0.000012  loss: 1.9342  time: 1.2774  data: 0.0000  max mem: 32518
Train: data epoch: [9]  [1000/2030]  eta: 0:21:59  lr: 0.000012  loss: 1.7949  time: 1.2767  data: 0.0000  max mem: 32518
Train: data epoch: [9]  [1050/2030]  eta: 0:20:54  lr: 0.000012  loss: 1.8678  time: 1.2777  data: 0.0000  max mem: 32518
Train: data epoch: [9]  [1100/2030]  eta: 0:19:50  lr: 0.000012  loss: 1.8717  time: 1.2792  data: 0.0000  max mem: 32518
Train: data epoch: [9]  [1150/2030]  eta: 0:18:47  lr: 0.000012  loss: 1.8907  time: 1.2853  data: 0.0000  max mem: 32518
Train: data epoch: [9]  [1200/2030]  eta: 0:17:42  lr: 0.000012  loss: 1.8512  time: 1.2795  data: 0.0000  max mem: 32518
Train: data epoch: [9]  [1250/2030]  eta: 0:16:38  lr: 0.000012  loss: 1.8718  time: 1.2766  data: 0.0000  max mem: 32518
Train: data epoch: [9]  [1300/2030]  eta: 0:15:34  lr: 0.000012  loss: 1.9273  time: 1.2747  data: 0.0000  max mem: 32518
Train: data epoch: [9]  [1350/2030]  eta: 0:14:30  lr: 0.000012  loss: 1.9551  time: 1.2793  data: 0.0000  max mem: 32518
Train: data epoch: [9]  [1400/2030]  eta: 0:13:26  lr: 0.000012  loss: 1.8144  time: 1.2780  data: 0.0000  max mem: 32518
Train: data epoch: [9]  [1450/2030]  eta: 0:12:22  lr: 0.000012  loss: 1.9434  time: 1.2741  data: 0.0000  max mem: 32518
Train: data epoch: [9]  [1500/2030]  eta: 0:11:18  lr: 0.000012  loss: 1.8814  time: 1.2825  data: 0.0000  max mem: 32518
Train: data epoch: [9]  [1550/2030]  eta: 0:10:14  lr: 0.000012  loss: 1.9972  time: 1.2771  data: 0.0000  max mem: 32518
Train: data epoch: [9]  [1600/2030]  eta: 0:09:10  lr: 0.000012  loss: 1.9333  time: 1.2819  data: 0.0000  max mem: 32518
Train: data epoch: [9]  [1650/2030]  eta: 0:08:06  lr: 0.000012  loss: 1.8980  time: 1.2825  data: 0.0000  max mem: 32518
Train: data epoch: [9]  [1700/2030]  eta: 0:07:02  lr: 0.000012  loss: 1.9599  time: 1.2791  data: 0.0000  max mem: 32518
Train: data epoch: [9]  [1750/2030]  eta: 0:05:58  lr: 0.000012  loss: 1.8675  time: 1.2720  data: 0.0000  max mem: 32518
Train: data epoch: [9]  [1800/2030]  eta: 0:04:54  lr: 0.000012  loss: 1.9537  time: 1.2782  data: 0.0000  max mem: 32518
Train: data epoch: [9]  [1850/2030]  eta: 0:03:50  lr: 0.000012  loss: 1.9253  time: 1.2769  data: 0.0000  max mem: 32518
Train: data epoch: [9]  [1900/2030]  eta: 0:02:46  lr: 0.000012  loss: 1.8560  time: 1.2824  data: 0.0000  max mem: 32518
Train: data epoch: [9]  [1950/2030]  eta: 0:01:42  lr: 0.000012  loss: 1.7861  time: 1.2735  data: 0.0000  max mem: 32518
Train: data epoch: [9]  [2000/2030]  eta: 0:00:38  lr: 0.000012  loss: 1.8464  time: 1.2799  data: 0.0000  max mem: 32518
Train: data epoch: [9]  [2029/2030]  eta: 0:00:01  lr: 0.000012  loss: 1.8740  time: 1.2860  data: 0.0000  max mem: 32518
Train: data epoch: [9] Total time: 0:43:18 (1.2800 s / it)
2023-05-11 08:41:22,873 [INFO] Averaged stats: lr: 0.0000  loss: 1.8907
2023-05-11 08:41:22,890 [INFO] Saving checkpoint at epoch 9 to /home/yiren/VATEX/lavis/output/BLIP-T/Caption_vatex_stage2/20230511012/checkpoint_9.pth.
2023-05-11 08:41:23,989 [INFO] Evaluating on val.
Evaluation  [ 0/47]  eta: 0:24:22    time: 31.1152  data: 0.2424  max mem: 32518
Evaluation  [10/47]  eta: 0:18:08    time: 29.4286  data: 0.0230  max mem: 32518
Evaluation  [20/47]  eta: 0:13:01    time: 28.8533  data: 0.0011  max mem: 32518
Evaluation  [30/47]  eta: 0:08:28    time: 30.1842  data: 0.0011  max mem: 32518
Evaluation  [40/47]  eta: 0:03:28    time: 30.5983  data: 0.0010  max mem: 32518
Evaluation  [46/47]  eta: 0:00:29    time: 28.8266  data: 0.0051  max mem: 32518
Evaluation Total time: 0:22:58 (29.3272 s / it)
2023-05-11 09:04:22,389 [WARNING] rank 0 starts merging results.
result file saved to /home/yiren/VATEX/lavis/output/BLIP-T/Caption_vatex_stage2/20230511012/result/val_epoch9.json
2023-05-11 09:04:22,448 [INFO] Training time 7:36:06
(lavis) xxxx@xxxx:~/VATEX$ conda activate m2release
(m2release) xxxx@xxxx:~/VATEX$ cd
(m2release) xxxx@xxxx:~$ cd clipscore/
(m2release) xxxx@xxxx:~/clipscore$ python clipscore.py
100%|| 30000/30000 [00:00<00:00, 46980.58it/s]
3000
100%|| 30000/30000 [00:00<00:00, 1726832.72it/s]
3000
3000
PTBTokenizer tokenized 486507 tokens at 1792171.67 tokens per second.
PTBTokenizer tokenized 42713 tokens at 391738.46 tokens per second.
{'testlen': 39693, 'reflen': 39183, 'guess': [39693, 36693, 33693, 30693], 'correct': [29335, 15950, 8054, 3652]}
ratio: 1.013015848709874
PTBTokenizer tokenized 486507 tokens at 1858865.95 tokens per second.
PTBTokenizer tokenized 42713 tokens at 451920.82 tokens per second.
PTBTokenizer tokenized 486507 tokens at 2037308.95 tokens per second.
PTBTokenizer tokenized 42713 tokens at 488879.50 tokens per second.
PTBTokenizer tokenized 486507 tokens at 2011861.53 tokens per second.
PTBTokenizer tokenized 42713 tokens at 450251.77 tokens per second.
PTBTokenizer tokenized 486507 tokens at 1994130.23 tokens per second.
PTBTokenizer tokenized 42713 tokens at 454256.40 tokens per second.
Parsing reference captions
Parsing test captions
SPICE evaluation took: 5.975 s
BLEU-1: 0.7390
BLEU-2: 0.5668
BLEU-3: 0.4251
BLEU-4: 0.3092
METEOR: 0.2364
ROUGE: 0.4910
CIDER: 0.6099
SPICE: 0.1102
(m2release) xxxx@xxxx:~/clipscore$ cd
